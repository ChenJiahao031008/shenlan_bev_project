[
    {
        "label": "random",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "random",
        "description": "random",
        "detail": "random",
        "documentation": {}
    },
    {
        "label": "warnings",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "warnings",
        "description": "warnings",
        "detail": "warnings",
        "documentation": {}
    },
    {
        "label": "numpy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "numpy",
        "description": "numpy",
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "random",
        "importPath": "numpy",
        "description": "numpy",
        "isExtraImport": true,
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "torch",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch",
        "description": "torch",
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "nn",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "nn",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "nn",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "nn",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "nn",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "nn",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "device",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "nn",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "torch.distributed",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch.distributed",
        "description": "torch.distributed",
        "detail": "torch.distributed",
        "documentation": {}
    },
    {
        "label": "MMDataParallel",
        "importPath": "mmcv.parallel",
        "description": "mmcv.parallel",
        "isExtraImport": true,
        "detail": "mmcv.parallel",
        "documentation": {}
    },
    {
        "label": "MMDistributedDataParallel",
        "importPath": "mmcv.parallel",
        "description": "mmcv.parallel",
        "isExtraImport": true,
        "detail": "mmcv.parallel",
        "documentation": {}
    },
    {
        "label": "DataContainer",
        "importPath": "mmcv.parallel",
        "description": "mmcv.parallel",
        "isExtraImport": true,
        "detail": "mmcv.parallel",
        "documentation": {}
    },
    {
        "label": "DataContainer",
        "importPath": "mmcv.parallel",
        "description": "mmcv.parallel",
        "isExtraImport": true,
        "detail": "mmcv.parallel",
        "documentation": {}
    },
    {
        "label": "collate",
        "importPath": "mmcv.parallel",
        "description": "mmcv.parallel",
        "isExtraImport": true,
        "detail": "mmcv.parallel",
        "documentation": {}
    },
    {
        "label": "DataContainer",
        "importPath": "mmcv.parallel",
        "description": "mmcv.parallel",
        "isExtraImport": true,
        "detail": "mmcv.parallel",
        "documentation": {}
    },
    {
        "label": "DataContainer",
        "importPath": "mmcv.parallel",
        "description": "mmcv.parallel",
        "isExtraImport": true,
        "detail": "mmcv.parallel",
        "documentation": {}
    },
    {
        "label": "MMDataParallel",
        "importPath": "mmcv.parallel",
        "description": "mmcv.parallel",
        "isExtraImport": true,
        "detail": "mmcv.parallel",
        "documentation": {}
    },
    {
        "label": "MMDataParallel",
        "importPath": "mmcv.parallel",
        "description": "mmcv.parallel",
        "isExtraImport": true,
        "detail": "mmcv.parallel",
        "documentation": {}
    },
    {
        "label": "MMDistributedDataParallel",
        "importPath": "mmcv.parallel",
        "description": "mmcv.parallel",
        "isExtraImport": true,
        "detail": "mmcv.parallel",
        "documentation": {}
    },
    {
        "label": "HOOKS",
        "importPath": "mmcv.runner",
        "description": "mmcv.runner",
        "isExtraImport": true,
        "detail": "mmcv.runner",
        "documentation": {}
    },
    {
        "label": "DistSamplerSeedHook",
        "importPath": "mmcv.runner",
        "description": "mmcv.runner",
        "isExtraImport": true,
        "detail": "mmcv.runner",
        "documentation": {}
    },
    {
        "label": "EpochBasedRunner",
        "importPath": "mmcv.runner",
        "description": "mmcv.runner",
        "isExtraImport": true,
        "detail": "mmcv.runner",
        "documentation": {}
    },
    {
        "label": "Fp16OptimizerHook",
        "importPath": "mmcv.runner",
        "description": "mmcv.runner",
        "isExtraImport": true,
        "detail": "mmcv.runner",
        "documentation": {}
    },
    {
        "label": "OptimizerHook",
        "importPath": "mmcv.runner",
        "description": "mmcv.runner",
        "isExtraImport": true,
        "detail": "mmcv.runner",
        "documentation": {}
    },
    {
        "label": "build_optimizer",
        "importPath": "mmcv.runner",
        "description": "mmcv.runner",
        "isExtraImport": true,
        "detail": "mmcv.runner",
        "documentation": {}
    },
    {
        "label": "build_runner",
        "importPath": "mmcv.runner",
        "description": "mmcv.runner",
        "isExtraImport": true,
        "detail": "mmcv.runner",
        "documentation": {}
    },
    {
        "label": "get_dist_info",
        "importPath": "mmcv.runner",
        "description": "mmcv.runner",
        "isExtraImport": true,
        "detail": "mmcv.runner",
        "documentation": {}
    },
    {
        "label": "get_dist_info",
        "importPath": "mmcv.runner",
        "description": "mmcv.runner",
        "isExtraImport": true,
        "detail": "mmcv.runner",
        "documentation": {}
    },
    {
        "label": "BaseModule",
        "importPath": "mmcv.runner",
        "description": "mmcv.runner",
        "isExtraImport": true,
        "detail": "mmcv.runner",
        "documentation": {}
    },
    {
        "label": "force_fp32",
        "importPath": "mmcv.runner",
        "description": "mmcv.runner",
        "isExtraImport": true,
        "detail": "mmcv.runner",
        "documentation": {}
    },
    {
        "label": "force_fp32",
        "importPath": "mmcv.runner",
        "description": "mmcv.runner",
        "isExtraImport": true,
        "detail": "mmcv.runner",
        "documentation": {}
    },
    {
        "label": "auto_fp16",
        "importPath": "mmcv.runner",
        "description": "mmcv.runner",
        "isExtraImport": true,
        "detail": "mmcv.runner",
        "documentation": {}
    },
    {
        "label": "force_fp32",
        "importPath": "mmcv.runner",
        "description": "mmcv.runner",
        "isExtraImport": true,
        "detail": "mmcv.runner",
        "documentation": {}
    },
    {
        "label": "auto_fp16",
        "importPath": "mmcv.runner",
        "description": "mmcv.runner",
        "isExtraImport": true,
        "detail": "mmcv.runner",
        "documentation": {}
    },
    {
        "label": "force_fp32",
        "importPath": "mmcv.runner",
        "description": "mmcv.runner",
        "isExtraImport": true,
        "detail": "mmcv.runner",
        "documentation": {}
    },
    {
        "label": "auto_fp16",
        "importPath": "mmcv.runner",
        "description": "mmcv.runner",
        "isExtraImport": true,
        "detail": "mmcv.runner",
        "documentation": {}
    },
    {
        "label": "force_fp32",
        "importPath": "mmcv.runner",
        "description": "mmcv.runner",
        "isExtraImport": true,
        "detail": "mmcv.runner",
        "documentation": {}
    },
    {
        "label": "auto_fp16",
        "importPath": "mmcv.runner",
        "description": "mmcv.runner",
        "isExtraImport": true,
        "detail": "mmcv.runner",
        "documentation": {}
    },
    {
        "label": "force_fp32",
        "importPath": "mmcv.runner",
        "description": "mmcv.runner",
        "isExtraImport": true,
        "detail": "mmcv.runner",
        "documentation": {}
    },
    {
        "label": "auto_fp16",
        "importPath": "mmcv.runner",
        "description": "mmcv.runner",
        "isExtraImport": true,
        "detail": "mmcv.runner",
        "documentation": {}
    },
    {
        "label": "force_fp32",
        "importPath": "mmcv.runner",
        "description": "mmcv.runner",
        "isExtraImport": true,
        "detail": "mmcv.runner",
        "documentation": {}
    },
    {
        "label": "auto_fp16",
        "importPath": "mmcv.runner",
        "description": "mmcv.runner",
        "isExtraImport": true,
        "detail": "mmcv.runner",
        "documentation": {}
    },
    {
        "label": "DistEvalHook",
        "importPath": "mmcv.runner",
        "description": "mmcv.runner",
        "isExtraImport": true,
        "detail": "mmcv.runner",
        "documentation": {}
    },
    {
        "label": "EvalHook",
        "importPath": "mmcv.runner",
        "description": "mmcv.runner",
        "isExtraImport": true,
        "detail": "mmcv.runner",
        "documentation": {}
    },
    {
        "label": "get_dist_info",
        "importPath": "mmcv.runner",
        "description": "mmcv.runner",
        "isExtraImport": true,
        "detail": "mmcv.runner",
        "documentation": {}
    },
    {
        "label": "get_dist_info",
        "importPath": "mmcv.runner",
        "description": "mmcv.runner",
        "isExtraImport": true,
        "detail": "mmcv.runner",
        "documentation": {}
    },
    {
        "label": "force_fp32",
        "importPath": "mmcv.runner",
        "description": "mmcv.runner",
        "isExtraImport": true,
        "detail": "mmcv.runner",
        "documentation": {}
    },
    {
        "label": "force_fp32",
        "importPath": "mmcv.runner",
        "description": "mmcv.runner",
        "isExtraImport": true,
        "detail": "mmcv.runner",
        "documentation": {}
    },
    {
        "label": "force_fp32",
        "importPath": "mmcv.runner",
        "description": "mmcv.runner",
        "isExtraImport": true,
        "detail": "mmcv.runner",
        "documentation": {}
    },
    {
        "label": "force_fp32",
        "importPath": "mmcv.runner",
        "description": "mmcv.runner",
        "isExtraImport": true,
        "detail": "mmcv.runner",
        "documentation": {}
    },
    {
        "label": "BaseModule",
        "importPath": "mmcv.runner",
        "description": "mmcv.runner",
        "isExtraImport": true,
        "detail": "mmcv.runner",
        "documentation": {}
    },
    {
        "label": "force_fp32",
        "importPath": "mmcv.runner",
        "description": "mmcv.runner",
        "isExtraImport": true,
        "detail": "mmcv.runner",
        "documentation": {}
    },
    {
        "label": "auto_fp16",
        "importPath": "mmcv.runner",
        "description": "mmcv.runner",
        "isExtraImport": true,
        "detail": "mmcv.runner",
        "documentation": {}
    },
    {
        "label": "load_checkpoint",
        "importPath": "mmcv.runner",
        "description": "mmcv.runner",
        "isExtraImport": true,
        "detail": "mmcv.runner",
        "documentation": {}
    },
    {
        "label": "wrap_fp16_model",
        "importPath": "mmcv.runner",
        "description": "mmcv.runner",
        "isExtraImport": true,
        "detail": "mmcv.runner",
        "documentation": {}
    },
    {
        "label": "get_dist_info",
        "importPath": "mmcv.runner",
        "description": "mmcv.runner",
        "isExtraImport": true,
        "detail": "mmcv.runner",
        "documentation": {}
    },
    {
        "label": "init_dist",
        "importPath": "mmcv.runner",
        "description": "mmcv.runner",
        "isExtraImport": true,
        "detail": "mmcv.runner",
        "documentation": {}
    },
    {
        "label": "wrap_fp16_model",
        "importPath": "mmcv.runner",
        "description": "mmcv.runner",
        "isExtraImport": true,
        "detail": "mmcv.runner",
        "documentation": {}
    },
    {
        "label": "save_checkpoint",
        "importPath": "mmcv.runner",
        "description": "mmcv.runner",
        "isExtraImport": true,
        "detail": "mmcv.runner",
        "documentation": {}
    },
    {
        "label": "load_state_dict",
        "importPath": "mmcv.runner",
        "description": "mmcv.runner",
        "isExtraImport": true,
        "detail": "mmcv.runner",
        "documentation": {}
    },
    {
        "label": "get_dist_info",
        "importPath": "mmcv.runner",
        "description": "mmcv.runner",
        "isExtraImport": true,
        "detail": "mmcv.runner",
        "documentation": {}
    },
    {
        "label": "init_dist",
        "importPath": "mmcv.runner",
        "description": "mmcv.runner",
        "isExtraImport": true,
        "detail": "mmcv.runner",
        "documentation": {}
    },
    {
        "label": "load_checkpoint",
        "importPath": "mmcv.runner",
        "description": "mmcv.runner",
        "isExtraImport": true,
        "detail": "mmcv.runner",
        "documentation": {}
    },
    {
        "label": "wrap_fp16_model",
        "importPath": "mmcv.runner",
        "description": "mmcv.runner",
        "isExtraImport": true,
        "detail": "mmcv.runner",
        "documentation": {}
    },
    {
        "label": "get_dist_info",
        "importPath": "mmcv.runner",
        "description": "mmcv.runner",
        "isExtraImport": true,
        "detail": "mmcv.runner",
        "documentation": {}
    },
    {
        "label": "init_dist",
        "importPath": "mmcv.runner",
        "description": "mmcv.runner",
        "isExtraImport": true,
        "detail": "mmcv.runner",
        "documentation": {}
    },
    {
        "label": "build_from_cfg",
        "importPath": "mmcv.utils",
        "description": "mmcv.utils",
        "isExtraImport": true,
        "detail": "mmcv.utils",
        "documentation": {}
    },
    {
        "label": "TORCH_VERSION",
        "importPath": "mmcv.utils",
        "description": "mmcv.utils",
        "isExtraImport": true,
        "detail": "mmcv.utils",
        "documentation": {}
    },
    {
        "label": "digit_version",
        "importPath": "mmcv.utils",
        "description": "mmcv.utils",
        "isExtraImport": true,
        "detail": "mmcv.utils",
        "documentation": {}
    },
    {
        "label": "TORCH_VERSION",
        "importPath": "mmcv.utils",
        "description": "mmcv.utils",
        "isExtraImport": true,
        "detail": "mmcv.utils",
        "documentation": {}
    },
    {
        "label": "digit_version",
        "importPath": "mmcv.utils",
        "description": "mmcv.utils",
        "isExtraImport": true,
        "detail": "mmcv.utils",
        "documentation": {}
    },
    {
        "label": "ConfigDict",
        "importPath": "mmcv.utils",
        "description": "mmcv.utils",
        "isExtraImport": true,
        "detail": "mmcv.utils",
        "documentation": {}
    },
    {
        "label": "build_from_cfg",
        "importPath": "mmcv.utils",
        "description": "mmcv.utils",
        "isExtraImport": true,
        "detail": "mmcv.utils",
        "documentation": {}
    },
    {
        "label": "deprecated_api_warning",
        "importPath": "mmcv.utils",
        "description": "mmcv.utils",
        "isExtraImport": true,
        "detail": "mmcv.utils",
        "documentation": {}
    },
    {
        "label": "to_2tuple",
        "importPath": "mmcv.utils",
        "description": "mmcv.utils",
        "isExtraImport": true,
        "detail": "mmcv.utils",
        "documentation": {}
    },
    {
        "label": "ext_loader",
        "importPath": "mmcv.utils",
        "description": "mmcv.utils",
        "isExtraImport": true,
        "detail": "mmcv.utils",
        "documentation": {}
    },
    {
        "label": "TORCH_VERSION",
        "importPath": "mmcv.utils",
        "description": "mmcv.utils",
        "isExtraImport": true,
        "detail": "mmcv.utils",
        "documentation": {}
    },
    {
        "label": "digit_version",
        "importPath": "mmcv.utils",
        "description": "mmcv.utils",
        "isExtraImport": true,
        "detail": "mmcv.utils",
        "documentation": {}
    },
    {
        "label": "ext_loader",
        "importPath": "mmcv.utils",
        "description": "mmcv.utils",
        "isExtraImport": true,
        "detail": "mmcv.utils",
        "documentation": {}
    },
    {
        "label": "ConfigDict",
        "importPath": "mmcv.utils",
        "description": "mmcv.utils",
        "isExtraImport": true,
        "detail": "mmcv.utils",
        "documentation": {}
    },
    {
        "label": "build_from_cfg",
        "importPath": "mmcv.utils",
        "description": "mmcv.utils",
        "isExtraImport": true,
        "detail": "mmcv.utils",
        "documentation": {}
    },
    {
        "label": "deprecated_api_warning",
        "importPath": "mmcv.utils",
        "description": "mmcv.utils",
        "isExtraImport": true,
        "detail": "mmcv.utils",
        "documentation": {}
    },
    {
        "label": "to_2tuple",
        "importPath": "mmcv.utils",
        "description": "mmcv.utils",
        "isExtraImport": true,
        "detail": "mmcv.utils",
        "documentation": {}
    },
    {
        "label": "ext_loader",
        "importPath": "mmcv.utils",
        "description": "mmcv.utils",
        "isExtraImport": true,
        "detail": "mmcv.utils",
        "documentation": {}
    },
    {
        "label": "ext_loader",
        "importPath": "mmcv.utils",
        "description": "mmcv.utils",
        "isExtraImport": true,
        "detail": "mmcv.utils",
        "documentation": {}
    },
    {
        "label": "ConfigDict",
        "importPath": "mmcv.utils",
        "description": "mmcv.utils",
        "isExtraImport": true,
        "detail": "mmcv.utils",
        "documentation": {}
    },
    {
        "label": "build_from_cfg",
        "importPath": "mmcv.utils",
        "description": "mmcv.utils",
        "isExtraImport": true,
        "detail": "mmcv.utils",
        "documentation": {}
    },
    {
        "label": "deprecated_api_warning",
        "importPath": "mmcv.utils",
        "description": "mmcv.utils",
        "isExtraImport": true,
        "detail": "mmcv.utils",
        "documentation": {}
    },
    {
        "label": "to_2tuple",
        "importPath": "mmcv.utils",
        "description": "mmcv.utils",
        "isExtraImport": true,
        "detail": "mmcv.utils",
        "documentation": {}
    },
    {
        "label": "ext_loader",
        "importPath": "mmcv.utils",
        "description": "mmcv.utils",
        "isExtraImport": true,
        "detail": "mmcv.utils",
        "documentation": {}
    },
    {
        "label": "Registry",
        "importPath": "mmcv.utils",
        "description": "mmcv.utils",
        "isExtraImport": true,
        "detail": "mmcv.utils",
        "documentation": {}
    },
    {
        "label": "build_from_cfg",
        "importPath": "mmcv.utils",
        "description": "mmcv.utils",
        "isExtraImport": true,
        "detail": "mmcv.utils",
        "documentation": {}
    },
    {
        "label": "Registry",
        "importPath": "mmcv.utils",
        "description": "mmcv.utils",
        "isExtraImport": true,
        "detail": "mmcv.utils",
        "documentation": {}
    },
    {
        "label": "build_from_cfg",
        "importPath": "mmcv.utils",
        "description": "mmcv.utils",
        "isExtraImport": true,
        "detail": "mmcv.utils",
        "documentation": {}
    },
    {
        "label": "TORCH_VERSION",
        "importPath": "mmcv.utils",
        "description": "mmcv.utils",
        "isExtraImport": true,
        "detail": "mmcv.utils",
        "documentation": {}
    },
    {
        "label": "digit_version",
        "importPath": "mmcv.utils",
        "description": "mmcv.utils",
        "isExtraImport": true,
        "detail": "mmcv.utils",
        "documentation": {}
    },
    {
        "label": "TORCH_VERSION",
        "importPath": "mmcv.utils",
        "description": "mmcv.utils",
        "isExtraImport": true,
        "detail": "mmcv.utils",
        "documentation": {}
    },
    {
        "label": "digit_version",
        "importPath": "mmcv.utils",
        "description": "mmcv.utils",
        "isExtraImport": true,
        "detail": "mmcv.utils",
        "documentation": {}
    },
    {
        "label": "EvalHook",
        "importPath": "mmdet.core",
        "description": "mmdet.core",
        "isExtraImport": true,
        "detail": "mmdet.core",
        "documentation": {}
    },
    {
        "label": "encode_mask_results",
        "importPath": "mmdet.core",
        "description": "mmdet.core",
        "isExtraImport": true,
        "detail": "mmdet.core",
        "documentation": {}
    },
    {
        "label": "multi_apply",
        "importPath": "mmdet.core",
        "description": "mmdet.core",
        "isExtraImport": true,
        "detail": "mmdet.core",
        "documentation": {}
    },
    {
        "label": "multi_apply",
        "importPath": "mmdet.core",
        "description": "mmdet.core",
        "isExtraImport": true,
        "detail": "mmdet.core",
        "documentation": {}
    },
    {
        "label": "reduce_mean",
        "importPath": "mmdet.core",
        "description": "mmdet.core",
        "isExtraImport": true,
        "detail": "mmdet.core",
        "documentation": {}
    },
    {
        "label": "multi_apply",
        "importPath": "mmdet.core",
        "description": "mmdet.core",
        "isExtraImport": true,
        "detail": "mmdet.core",
        "documentation": {}
    },
    {
        "label": "multi_apply",
        "importPath": "mmdet.core",
        "description": "mmdet.core",
        "isExtraImport": true,
        "detail": "mmdet.core",
        "documentation": {}
    },
    {
        "label": "reduce_mean",
        "importPath": "mmdet.core",
        "description": "mmdet.core",
        "isExtraImport": true,
        "detail": "mmdet.core",
        "documentation": {}
    },
    {
        "label": "build_dataset",
        "importPath": "mmdet.datasets",
        "description": "mmdet.datasets",
        "isExtraImport": true,
        "detail": "mmdet.datasets",
        "documentation": {}
    },
    {
        "label": "replace_ImageToTensor",
        "importPath": "mmdet.datasets",
        "description": "mmdet.datasets",
        "isExtraImport": true,
        "detail": "mmdet.datasets",
        "documentation": {}
    },
    {
        "label": "DATASETS",
        "importPath": "mmdet.datasets",
        "description": "mmdet.datasets",
        "isExtraImport": true,
        "detail": "mmdet.datasets",
        "documentation": {}
    },
    {
        "label": "DATASETS",
        "importPath": "mmdet.datasets",
        "description": "mmdet.datasets",
        "isExtraImport": true,
        "detail": "mmdet.datasets",
        "documentation": {}
    },
    {
        "label": "DATASETS",
        "importPath": "mmdet.datasets",
        "description": "mmdet.datasets",
        "isExtraImport": true,
        "detail": "mmdet.datasets",
        "documentation": {}
    },
    {
        "label": "DATASETS",
        "importPath": "mmdet.datasets",
        "description": "mmdet.datasets",
        "isExtraImport": true,
        "detail": "mmdet.datasets",
        "documentation": {}
    },
    {
        "label": "DATASETS",
        "importPath": "mmdet.datasets",
        "description": "mmdet.datasets",
        "isExtraImport": true,
        "detail": "mmdet.datasets",
        "documentation": {}
    },
    {
        "label": "CocoDataset",
        "importPath": "mmdet.datasets",
        "description": "mmdet.datasets",
        "isExtraImport": true,
        "detail": "mmdet.datasets",
        "documentation": {}
    },
    {
        "label": "replace_ImageToTensor",
        "importPath": "mmdet.datasets",
        "description": "mmdet.datasets",
        "isExtraImport": true,
        "detail": "mmdet.datasets",
        "documentation": {}
    },
    {
        "label": "get_root_logger",
        "importPath": "mmdet.utils",
        "description": "mmdet.utils",
        "isExtraImport": true,
        "detail": "mmdet.utils",
        "documentation": {}
    },
    {
        "label": "time",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "time",
        "description": "time",
        "detail": "time",
        "documentation": {}
    },
    {
        "label": "os.path",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os.path",
        "description": "os.path",
        "detail": "os.path",
        "documentation": {}
    },
    {
        "label": "join",
        "importPath": "os.path",
        "description": "os.path",
        "isExtraImport": true,
        "detail": "os.path",
        "documentation": {}
    },
    {
        "label": "build_dataloader",
        "importPath": "projects.mmdet3d_plugin.datasets.builder",
        "description": "projects.mmdet3d_plugin.datasets.builder",
        "isExtraImport": true,
        "detail": "projects.mmdet3d_plugin.datasets.builder",
        "documentation": {}
    },
    {
        "label": "build_dataloader",
        "importPath": "projects.mmdet3d_plugin.datasets.builder",
        "description": "projects.mmdet3d_plugin.datasets.builder",
        "isExtraImport": true,
        "detail": "projects.mmdet3d_plugin.datasets.builder",
        "documentation": {}
    },
    {
        "label": "build_dataloader",
        "importPath": "projects.mmdet3d_plugin.datasets.builder",
        "description": "projects.mmdet3d_plugin.datasets.builder",
        "isExtraImport": true,
        "detail": "projects.mmdet3d_plugin.datasets.builder",
        "documentation": {}
    },
    {
        "label": "CustomDistEvalHook",
        "importPath": "projects.mmdet3d_plugin.core.evaluation.eval_hooks",
        "description": "projects.mmdet3d_plugin.core.evaluation.eval_hooks",
        "isExtraImport": true,
        "detail": "projects.mmdet3d_plugin.core.evaluation.eval_hooks",
        "documentation": {}
    },
    {
        "label": "custom_build_dataset",
        "importPath": "projects.mmdet3d_plugin.datasets",
        "description": "projects.mmdet3d_plugin.datasets",
        "isExtraImport": true,
        "detail": "projects.mmdet3d_plugin.datasets",
        "documentation": {}
    },
    {
        "label": "custom_build_dataset",
        "importPath": "projects.mmdet3d_plugin.datasets",
        "description": "projects.mmdet3d_plugin.datasets",
        "isExtraImport": true,
        "detail": "projects.mmdet3d_plugin.datasets",
        "documentation": {}
    },
    {
        "label": "pickle",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pickle",
        "description": "pickle",
        "detail": "pickle",
        "documentation": {}
    },
    {
        "label": "shutil",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "shutil",
        "description": "shutil",
        "detail": "shutil",
        "documentation": {}
    },
    {
        "label": "tempfile",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "tempfile",
        "description": "tempfile",
        "detail": "tempfile",
        "documentation": {}
    },
    {
        "label": "mmcv",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "mmcv",
        "description": "mmcv",
        "detail": "mmcv",
        "documentation": {}
    },
    {
        "label": "ConfigDict",
        "importPath": "mmcv",
        "description": "mmcv",
        "isExtraImport": true,
        "detail": "mmcv",
        "documentation": {}
    },
    {
        "label": "deprecated_api_warning",
        "importPath": "mmcv",
        "description": "mmcv",
        "isExtraImport": true,
        "detail": "mmcv",
        "documentation": {}
    },
    {
        "label": "Config",
        "importPath": "mmcv",
        "description": "mmcv",
        "isExtraImport": true,
        "detail": "mmcv",
        "documentation": {}
    },
    {
        "label": "track_iter_progress",
        "importPath": "mmcv",
        "description": "mmcv",
        "isExtraImport": true,
        "detail": "mmcv",
        "documentation": {}
    },
    {
        "label": "Config",
        "importPath": "mmcv",
        "description": "mmcv",
        "isExtraImport": true,
        "detail": "mmcv",
        "documentation": {}
    },
    {
        "label": "DictAction",
        "importPath": "mmcv",
        "description": "mmcv",
        "isExtraImport": true,
        "detail": "mmcv",
        "documentation": {}
    },
    {
        "label": "Config",
        "importPath": "mmcv",
        "description": "mmcv",
        "isExtraImport": true,
        "detail": "mmcv",
        "documentation": {}
    },
    {
        "label": "DictAction",
        "importPath": "mmcv",
        "description": "mmcv",
        "isExtraImport": true,
        "detail": "mmcv",
        "documentation": {}
    },
    {
        "label": "mkdir_or_exist",
        "importPath": "mmcv",
        "description": "mmcv",
        "isExtraImport": true,
        "detail": "mmcv",
        "documentation": {}
    },
    {
        "label": "track_iter_progress",
        "importPath": "mmcv",
        "description": "mmcv",
        "isExtraImport": true,
        "detail": "mmcv",
        "documentation": {}
    },
    {
        "label": "Config",
        "importPath": "mmcv",
        "description": "mmcv",
        "isExtraImport": true,
        "detail": "mmcv",
        "documentation": {}
    },
    {
        "label": "DictAction",
        "importPath": "mmcv",
        "description": "mmcv",
        "isExtraImport": true,
        "detail": "mmcv",
        "documentation": {}
    },
    {
        "label": "Config",
        "importPath": "mmcv",
        "description": "mmcv",
        "isExtraImport": true,
        "detail": "mmcv",
        "documentation": {}
    },
    {
        "label": "Config",
        "importPath": "mmcv",
        "description": "mmcv",
        "isExtraImport": true,
        "detail": "mmcv",
        "documentation": {}
    },
    {
        "label": "Config",
        "importPath": "mmcv",
        "description": "mmcv",
        "isExtraImport": true,
        "detail": "mmcv",
        "documentation": {}
    },
    {
        "label": "DictAction",
        "importPath": "mmcv",
        "description": "mmcv",
        "isExtraImport": true,
        "detail": "mmcv",
        "documentation": {}
    },
    {
        "label": "Config",
        "importPath": "mmcv",
        "description": "mmcv",
        "isExtraImport": true,
        "detail": "mmcv",
        "documentation": {}
    },
    {
        "label": "DictAction",
        "importPath": "mmcv",
        "description": "mmcv",
        "isExtraImport": true,
        "detail": "mmcv",
        "documentation": {}
    },
    {
        "label": "tensor2imgs",
        "importPath": "mmcv.image",
        "description": "mmcv.image",
        "isExtraImport": true,
        "detail": "mmcv.image",
        "documentation": {}
    },
    {
        "label": "pycocotools.mask",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pycocotools.mask",
        "description": "pycocotools.mask",
        "detail": "pycocotools.mask",
        "documentation": {}
    },
    {
        "label": "train_segmentor",
        "importPath": "mmseg.apis",
        "description": "mmseg.apis",
        "isExtraImport": true,
        "detail": "mmseg.apis",
        "documentation": {}
    },
    {
        "label": "train_detector",
        "importPath": "mmdet.apis",
        "description": "mmdet.apis",
        "isExtraImport": true,
        "detail": "mmdet.apis",
        "documentation": {}
    },
    {
        "label": "set_random_seed",
        "importPath": "mmdet.apis",
        "description": "mmdet.apis",
        "isExtraImport": true,
        "detail": "mmdet.apis",
        "documentation": {}
    },
    {
        "label": "init_model",
        "importPath": "mmdet.apis",
        "description": "mmdet.apis",
        "isExtraImport": true,
        "detail": "mmdet.apis",
        "documentation": {}
    },
    {
        "label": "set_random_seed",
        "importPath": "mmdet.apis",
        "description": "mmdet.apis",
        "isExtraImport": true,
        "detail": "mmdet.apis",
        "documentation": {}
    },
    {
        "label": "set_random_seed",
        "importPath": "mmdet.apis",
        "description": "mmdet.apis",
        "isExtraImport": true,
        "detail": "mmdet.apis",
        "documentation": {}
    },
    {
        "label": "copy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "copy",
        "description": "copy",
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "I",
        "importPath": "re",
        "description": "re",
        "isExtraImport": true,
        "detail": "re",
        "documentation": {}
    },
    {
        "label": "torch.nn",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch.nn",
        "description": "torch.nn",
        "detail": "torch.nn",
        "documentation": {}
    },
    {
        "label": "functional",
        "importPath": "torch.nn",
        "description": "torch.nn",
        "isExtraImport": true,
        "detail": "torch.nn",
        "documentation": {}
    },
    {
        "label": "functional",
        "importPath": "torch.nn",
        "description": "torch.nn",
        "isExtraImport": true,
        "detail": "torch.nn",
        "documentation": {}
    },
    {
        "label": "torch.nn.functional",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch.nn.functional",
        "description": "torch.nn.functional",
        "detail": "torch.nn.functional",
        "documentation": {}
    },
    {
        "label": "Linear",
        "importPath": "mmcv.cnn",
        "description": "mmcv.cnn",
        "isExtraImport": true,
        "detail": "mmcv.cnn",
        "documentation": {}
    },
    {
        "label": "bias_init_with_prob",
        "importPath": "mmcv.cnn",
        "description": "mmcv.cnn",
        "isExtraImport": true,
        "detail": "mmcv.cnn",
        "documentation": {}
    },
    {
        "label": "Linear",
        "importPath": "mmcv.cnn",
        "description": "mmcv.cnn",
        "isExtraImport": true,
        "detail": "mmcv.cnn",
        "documentation": {}
    },
    {
        "label": "bias_init_with_prob",
        "importPath": "mmcv.cnn",
        "description": "mmcv.cnn",
        "isExtraImport": true,
        "detail": "mmcv.cnn",
        "documentation": {}
    },
    {
        "label": "Linear",
        "importPath": "mmcv.cnn",
        "description": "mmcv.cnn",
        "isExtraImport": true,
        "detail": "mmcv.cnn",
        "documentation": {}
    },
    {
        "label": "build_activation_layer",
        "importPath": "mmcv.cnn",
        "description": "mmcv.cnn",
        "isExtraImport": true,
        "detail": "mmcv.cnn",
        "documentation": {}
    },
    {
        "label": "build_norm_layer",
        "importPath": "mmcv.cnn",
        "description": "mmcv.cnn",
        "isExtraImport": true,
        "detail": "mmcv.cnn",
        "documentation": {}
    },
    {
        "label": "xavier_init",
        "importPath": "mmcv.cnn",
        "description": "mmcv.cnn",
        "isExtraImport": true,
        "detail": "mmcv.cnn",
        "documentation": {}
    },
    {
        "label": "constant_init",
        "importPath": "mmcv.cnn",
        "description": "mmcv.cnn",
        "isExtraImport": true,
        "detail": "mmcv.cnn",
        "documentation": {}
    },
    {
        "label": "Linear",
        "importPath": "mmcv.cnn",
        "description": "mmcv.cnn",
        "isExtraImport": true,
        "detail": "mmcv.cnn",
        "documentation": {}
    },
    {
        "label": "build_activation_layer",
        "importPath": "mmcv.cnn",
        "description": "mmcv.cnn",
        "isExtraImport": true,
        "detail": "mmcv.cnn",
        "documentation": {}
    },
    {
        "label": "build_conv_layer",
        "importPath": "mmcv.cnn",
        "description": "mmcv.cnn",
        "isExtraImport": true,
        "detail": "mmcv.cnn",
        "documentation": {}
    },
    {
        "label": "build_norm_layer",
        "importPath": "mmcv.cnn",
        "description": "mmcv.cnn",
        "isExtraImport": true,
        "detail": "mmcv.cnn",
        "documentation": {}
    },
    {
        "label": "xavier_init",
        "importPath": "mmcv.cnn",
        "description": "mmcv.cnn",
        "isExtraImport": true,
        "detail": "mmcv.cnn",
        "documentation": {}
    },
    {
        "label": "constant_init",
        "importPath": "mmcv.cnn",
        "description": "mmcv.cnn",
        "isExtraImport": true,
        "detail": "mmcv.cnn",
        "documentation": {}
    },
    {
        "label": "xavier_init",
        "importPath": "mmcv.cnn",
        "description": "mmcv.cnn",
        "isExtraImport": true,
        "detail": "mmcv.cnn",
        "documentation": {}
    },
    {
        "label": "constant_init",
        "importPath": "mmcv.cnn",
        "description": "mmcv.cnn",
        "isExtraImport": true,
        "detail": "mmcv.cnn",
        "documentation": {}
    },
    {
        "label": "xavier_init",
        "importPath": "mmcv.cnn",
        "description": "mmcv.cnn",
        "isExtraImport": true,
        "detail": "mmcv.cnn",
        "documentation": {}
    },
    {
        "label": "xavier_init",
        "importPath": "mmcv.cnn",
        "description": "mmcv.cnn",
        "isExtraImport": true,
        "detail": "mmcv.cnn",
        "documentation": {}
    },
    {
        "label": "build_norm_layer",
        "importPath": "mmcv.cnn",
        "description": "mmcv.cnn",
        "isExtraImport": true,
        "detail": "mmcv.cnn",
        "documentation": {}
    },
    {
        "label": "build_conv_layer",
        "importPath": "mmcv.cnn",
        "description": "mmcv.cnn",
        "isExtraImport": true,
        "detail": "mmcv.cnn",
        "documentation": {}
    },
    {
        "label": "fuse_conv_bn",
        "importPath": "mmcv.cnn",
        "description": "mmcv.cnn",
        "isExtraImport": true,
        "detail": "mmcv.cnn",
        "documentation": {}
    },
    {
        "label": "inverse_sigmoid",
        "importPath": "mmdet.models.utils.transformer",
        "description": "mmdet.models.utils.transformer",
        "isExtraImport": true,
        "detail": "mmdet.models.utils.transformer",
        "documentation": {}
    },
    {
        "label": "inverse_sigmoid",
        "importPath": "mmdet.models.utils.transformer",
        "description": "mmdet.models.utils.transformer",
        "isExtraImport": true,
        "detail": "mmdet.models.utils.transformer",
        "documentation": {}
    },
    {
        "label": "inverse_sigmoid",
        "importPath": "mmdet.models.utils.transformer",
        "description": "mmdet.models.utils.transformer",
        "isExtraImport": true,
        "detail": "mmdet.models.utils.transformer",
        "documentation": {}
    },
    {
        "label": "HEADS",
        "importPath": "mmdet.models",
        "description": "mmdet.models",
        "isExtraImport": true,
        "detail": "mmdet.models",
        "documentation": {}
    },
    {
        "label": "HEADS",
        "importPath": "mmdet.models",
        "description": "mmdet.models",
        "isExtraImport": true,
        "detail": "mmdet.models",
        "documentation": {}
    },
    {
        "label": "DETECTORS",
        "importPath": "mmdet.models",
        "description": "mmdet.models",
        "isExtraImport": true,
        "detail": "mmdet.models",
        "documentation": {}
    },
    {
        "label": "DETECTORS",
        "importPath": "mmdet.models",
        "description": "mmdet.models",
        "isExtraImport": true,
        "detail": "mmdet.models",
        "documentation": {}
    },
    {
        "label": "DETECTORS",
        "importPath": "mmdet.models",
        "description": "mmdet.models",
        "isExtraImport": true,
        "detail": "mmdet.models",
        "documentation": {}
    },
    {
        "label": "DETRHead",
        "importPath": "mmdet.models.dense_heads",
        "description": "mmdet.models.dense_heads",
        "isExtraImport": true,
        "detail": "mmdet.models.dense_heads",
        "documentation": {}
    },
    {
        "label": "DETRHead",
        "importPath": "mmdet.models.dense_heads",
        "description": "mmdet.models.dense_heads",
        "isExtraImport": true,
        "detail": "mmdet.models.dense_heads",
        "documentation": {}
    },
    {
        "label": "build_bbox_coder",
        "importPath": "mmdet3d.core.bbox.coders",
        "description": "mmdet3d.core.bbox.coders",
        "isExtraImport": true,
        "detail": "mmdet3d.core.bbox.coders",
        "documentation": {}
    },
    {
        "label": "build_bbox_coder",
        "importPath": "mmdet3d.core.bbox.coders",
        "description": "mmdet3d.core.bbox.coders",
        "isExtraImport": true,
        "detail": "mmdet3d.core.bbox.coders",
        "documentation": {}
    },
    {
        "label": "import_item",
        "importPath": "traitlets",
        "description": "traitlets",
        "isExtraImport": true,
        "detail": "traitlets",
        "documentation": {}
    },
    {
        "label": "normalize_bbox",
        "importPath": "projects.mmdet3d_plugin.core.bbox.util",
        "description": "projects.mmdet3d_plugin.core.bbox.util",
        "isExtraImport": true,
        "detail": "projects.mmdet3d_plugin.core.bbox.util",
        "documentation": {}
    },
    {
        "label": "normalize_bbox",
        "importPath": "projects.mmdet3d_plugin.core.bbox.util",
        "description": "projects.mmdet3d_plugin.core.bbox.util",
        "isExtraImport": true,
        "detail": "projects.mmdet3d_plugin.core.bbox.util",
        "documentation": {}
    },
    {
        "label": "normalize_bbox",
        "importPath": "projects.mmdet3d_plugin.core.bbox.util",
        "description": "projects.mmdet3d_plugin.core.bbox.util",
        "isExtraImport": true,
        "detail": "projects.mmdet3d_plugin.core.bbox.util",
        "documentation": {}
    },
    {
        "label": "denormalize_bbox",
        "importPath": "projects.mmdet3d_plugin.core.bbox.util",
        "description": "projects.mmdet3d_plugin.core.bbox.util",
        "isExtraImport": true,
        "detail": "projects.mmdet3d_plugin.core.bbox.util",
        "documentation": {}
    },
    {
        "label": "build_positional_encoding",
        "importPath": "mmcv.cnn.bricks.transformer",
        "description": "mmcv.cnn.bricks.transformer",
        "isExtraImport": true,
        "detail": "mmcv.cnn.bricks.transformer",
        "documentation": {}
    },
    {
        "label": "build_feedforward_network",
        "importPath": "mmcv.cnn.bricks.transformer",
        "description": "mmcv.cnn.bricks.transformer",
        "isExtraImport": true,
        "detail": "mmcv.cnn.bricks.transformer",
        "documentation": {}
    },
    {
        "label": "build_attention",
        "importPath": "mmcv.cnn.bricks.transformer",
        "description": "mmcv.cnn.bricks.transformer",
        "isExtraImport": true,
        "detail": "mmcv.cnn.bricks.transformer",
        "documentation": {}
    },
    {
        "label": "TransformerLayerSequence",
        "importPath": "mmcv.cnn.bricks.transformer",
        "description": "mmcv.cnn.bricks.transformer",
        "isExtraImport": true,
        "detail": "mmcv.cnn.bricks.transformer",
        "documentation": {}
    },
    {
        "label": "TransformerLayerSequence",
        "importPath": "mmcv.cnn.bricks.transformer",
        "description": "mmcv.cnn.bricks.transformer",
        "isExtraImport": true,
        "detail": "mmcv.cnn.bricks.transformer",
        "documentation": {}
    },
    {
        "label": "build_feedforward_network",
        "importPath": "mmcv.cnn.bricks.transformer",
        "description": "mmcv.cnn.bricks.transformer",
        "isExtraImport": true,
        "detail": "mmcv.cnn.bricks.transformer",
        "documentation": {}
    },
    {
        "label": "build_attention",
        "importPath": "mmcv.cnn.bricks.transformer",
        "description": "mmcv.cnn.bricks.transformer",
        "isExtraImport": true,
        "detail": "mmcv.cnn.bricks.transformer",
        "documentation": {}
    },
    {
        "label": "build_attention",
        "importPath": "mmcv.cnn.bricks.transformer",
        "description": "mmcv.cnn.bricks.transformer",
        "isExtraImport": true,
        "detail": "mmcv.cnn.bricks.transformer",
        "documentation": {}
    },
    {
        "label": "build_transformer_layer_sequence",
        "importPath": "mmcv.cnn.bricks.transformer",
        "description": "mmcv.cnn.bricks.transformer",
        "isExtraImport": true,
        "detail": "mmcv.cnn.bricks.transformer",
        "documentation": {}
    },
    {
        "label": "build_transformer_layer_sequence",
        "importPath": "mmcv.cnn.bricks.transformer",
        "description": "mmcv.cnn.bricks.transformer",
        "isExtraImport": true,
        "detail": "mmcv.cnn.bricks.transformer",
        "documentation": {}
    },
    {
        "label": "run_time",
        "importPath": "projects.mmdet3d_plugin.models.utils.bricks",
        "description": "projects.mmdet3d_plugin.models.utils.bricks",
        "isExtraImport": true,
        "detail": "projects.mmdet3d_plugin.models.utils.bricks",
        "documentation": {}
    },
    {
        "label": "run_time",
        "importPath": "projects.mmdet3d_plugin.models.utils.bricks",
        "description": "projects.mmdet3d_plugin.models.utils.bricks",
        "isExtraImport": true,
        "detail": "projects.mmdet3d_plugin.models.utils.bricks",
        "documentation": {}
    },
    {
        "label": "run_time",
        "importPath": "projects.mmdet3d_plugin.models.utils.bricks",
        "description": "projects.mmdet3d_plugin.models.utils.bricks",
        "isExtraImport": true,
        "detail": "projects.mmdet3d_plugin.models.utils.bricks",
        "documentation": {}
    },
    {
        "label": "run_time",
        "importPath": "projects.mmdet3d_plugin.models.utils.bricks",
        "description": "projects.mmdet3d_plugin.models.utils.bricks",
        "isExtraImport": true,
        "detail": "projects.mmdet3d_plugin.models.utils.bricks",
        "documentation": {}
    },
    {
        "label": "run_time",
        "importPath": "projects.mmdet3d_plugin.models.utils.bricks",
        "description": "projects.mmdet3d_plugin.models.utils.bricks",
        "isExtraImport": true,
        "detail": "projects.mmdet3d_plugin.models.utils.bricks",
        "documentation": {}
    },
    {
        "label": "run_time",
        "importPath": "projects.mmdet3d_plugin.models.utils.bricks",
        "description": "projects.mmdet3d_plugin.models.utils.bricks",
        "isExtraImport": true,
        "detail": "projects.mmdet3d_plugin.models.utils.bricks",
        "documentation": {}
    },
    {
        "label": "cv2",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "cv2",
        "description": "cv2",
        "detail": "cv2",
        "documentation": {}
    },
    {
        "label": "PerceptionTransformerBEVEncoder",
        "importPath": "projects.mmdet3d_plugin.bevformer.modules",
        "description": "projects.mmdet3d_plugin.bevformer.modules",
        "isExtraImport": true,
        "detail": "projects.mmdet3d_plugin.bevformer.modules",
        "documentation": {}
    },
    {
        "label": "build_transformer",
        "importPath": "mmdet.models.utils",
        "description": "mmdet.models.utils",
        "isExtraImport": true,
        "detail": "mmdet.models.utils",
        "documentation": {}
    },
    {
        "label": "build_head",
        "importPath": "mmdet3d.models.builder",
        "description": "mmdet3d.models.builder",
        "isExtraImport": true,
        "detail": "mmdet3d.models.builder",
        "documentation": {}
    },
    {
        "label": "build_head",
        "importPath": "mmdet3d.models.builder",
        "description": "mmdet3d.models.builder",
        "isExtraImport": true,
        "detail": "mmdet3d.models.builder",
        "documentation": {}
    },
    {
        "label": "FreeAnchor3DHead",
        "importPath": "mmdet3d.models.dense_heads.free_anchor3d_head",
        "description": "mmdet3d.models.dense_heads.free_anchor3d_head",
        "isExtraImport": true,
        "detail": "mmdet3d.models.dense_heads.free_anchor3d_head",
        "documentation": {}
    },
    {
        "label": "bbox3d2result",
        "importPath": "mmdet3d.core",
        "description": "mmdet3d.core",
        "isExtraImport": true,
        "detail": "mmdet3d.core",
        "documentation": {}
    },
    {
        "label": "bbox3d2result",
        "importPath": "mmdet3d.core",
        "description": "mmdet3d.core",
        "isExtraImport": true,
        "detail": "mmdet3d.core",
        "documentation": {}
    },
    {
        "label": "bbox3d2result",
        "importPath": "mmdet3d.core",
        "description": "mmdet3d.core",
        "isExtraImport": true,
        "detail": "mmdet3d.core",
        "documentation": {}
    },
    {
        "label": "bbox3d2result",
        "importPath": "mmdet3d.core",
        "description": "mmdet3d.core",
        "isExtraImport": true,
        "detail": "mmdet3d.core",
        "documentation": {}
    },
    {
        "label": "box3d_multiclass_nms",
        "importPath": "mmdet3d.core",
        "description": "mmdet3d.core",
        "isExtraImport": true,
        "detail": "mmdet3d.core",
        "documentation": {}
    },
    {
        "label": "xywhr2xyxyr",
        "importPath": "mmdet3d.core",
        "description": "mmdet3d.core",
        "isExtraImport": true,
        "detail": "mmdet3d.core",
        "documentation": {}
    },
    {
        "label": "show_multi_modality_result",
        "importPath": "mmdet3d.core",
        "description": "mmdet3d.core",
        "isExtraImport": true,
        "detail": "mmdet3d.core",
        "documentation": {}
    },
    {
        "label": "MVXTwoStageDetector",
        "importPath": "mmdet3d.models.detectors.mvx_two_stage",
        "description": "mmdet3d.models.detectors.mvx_two_stage",
        "isExtraImport": true,
        "detail": "mmdet3d.models.detectors.mvx_two_stage",
        "documentation": {}
    },
    {
        "label": "MVXTwoStageDetector",
        "importPath": "mmdet3d.models.detectors.mvx_two_stage",
        "description": "mmdet3d.models.detectors.mvx_two_stage",
        "isExtraImport": true,
        "detail": "mmdet3d.models.detectors.mvx_two_stage",
        "documentation": {}
    },
    {
        "label": "MVXTwoStageDetector",
        "importPath": "mmdet3d.models.detectors.mvx_two_stage",
        "description": "mmdet3d.models.detectors.mvx_two_stage",
        "isExtraImport": true,
        "detail": "mmdet3d.models.detectors.mvx_two_stage",
        "documentation": {}
    },
    {
        "label": "GridMask",
        "importPath": "projects.mmdet3d_plugin.models.utils.grid_mask",
        "description": "projects.mmdet3d_plugin.models.utils.grid_mask",
        "isExtraImport": true,
        "detail": "projects.mmdet3d_plugin.models.utils.grid_mask",
        "documentation": {}
    },
    {
        "label": "GridMask",
        "importPath": "projects.mmdet3d_plugin.models.utils.grid_mask",
        "description": "projects.mmdet3d_plugin.models.utils.grid_mask",
        "isExtraImport": true,
        "detail": "projects.mmdet3d_plugin.models.utils.grid_mask",
        "documentation": {}
    },
    {
        "label": "GridMask",
        "importPath": "projects.mmdet3d_plugin.models.utils.grid_mask",
        "description": "projects.mmdet3d_plugin.models.utils.grid_mask",
        "isExtraImport": true,
        "detail": "projects.mmdet3d_plugin.models.utils.grid_mask",
        "documentation": {}
    },
    {
        "label": "mmdet3d",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "mmdet3d",
        "description": "mmdet3d",
        "detail": "mmdet3d",
        "documentation": {}
    },
    {
        "label": "__version__",
        "importPath": "mmdet3d",
        "description": "mmdet3d",
        "isExtraImport": true,
        "detail": "mmdet3d",
        "documentation": {}
    },
    {
        "label": "__version__",
        "importPath": "mmdet3d",
        "description": "mmdet3d",
        "isExtraImport": true,
        "detail": "mmdet3d",
        "documentation": {}
    },
    {
        "label": "OrderedDict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "defaultdict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "OrderedDict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "OrderedDict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "OrderedDict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "OrderedDict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "defaultdict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "defaultdict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "OrderedDict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "OrderedDict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "OrderedDict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "OrderedDict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "NO",
        "importPath": "tkinter.messagebox",
        "description": "tkinter.messagebox",
        "isExtraImport": true,
        "detail": "tkinter.messagebox",
        "documentation": {}
    },
    {
        "label": "BEVFormer",
        "importPath": "projects.mmdet3d_plugin.bevformer.detectors.bevformer",
        "description": "projects.mmdet3d_plugin.bevformer.detectors.bevformer",
        "isExtraImport": true,
        "detail": "projects.mmdet3d_plugin.bevformer.detectors.bevformer",
        "documentation": {}
    },
    {
        "label": "HOOKS",
        "importPath": "mmcv.runner.hooks.hook",
        "description": "mmcv.runner.hooks.hook",
        "isExtraImport": true,
        "detail": "mmcv.runner.hooks.hook",
        "documentation": {}
    },
    {
        "label": "Hook",
        "importPath": "mmcv.runner.hooks.hook",
        "description": "mmcv.runner.hooks.hook",
        "isExtraImport": true,
        "detail": "mmcv.runner.hooks.hook",
        "documentation": {}
    },
    {
        "label": "HOOKS",
        "importPath": "mmcv.runner.hooks.hook",
        "description": "mmcv.runner.hooks.hook",
        "isExtraImport": true,
        "detail": "mmcv.runner.hooks.hook",
        "documentation": {}
    },
    {
        "label": "Hook",
        "importPath": "mmcv.runner.hooks.hook",
        "description": "mmcv.runner.hooks.hook",
        "isExtraImport": true,
        "detail": "mmcv.runner.hooks.hook",
        "documentation": {}
    },
    {
        "label": "run_time",
        "importPath": "projects.mmdet3d_plugin.models.utils",
        "description": "projects.mmdet3d_plugin.models.utils",
        "isExtraImport": true,
        "detail": "projects.mmdet3d_plugin.models.utils",
        "documentation": {}
    },
    {
        "label": "run_time",
        "importPath": "projects.mmdet3d_plugin.models.utils",
        "description": "projects.mmdet3d_plugin.models.utils",
        "isExtraImport": true,
        "detail": "projects.mmdet3d_plugin.models.utils",
        "documentation": {}
    },
    {
        "label": "BaseModule",
        "importPath": "mmcv.runner.base_module",
        "description": "mmcv.runner.base_module",
        "isExtraImport": true,
        "detail": "mmcv.runner.base_module",
        "documentation": {}
    },
    {
        "label": "ModuleList",
        "importPath": "mmcv.runner.base_module",
        "description": "mmcv.runner.base_module",
        "isExtraImport": true,
        "detail": "mmcv.runner.base_module",
        "documentation": {}
    },
    {
        "label": "Sequential",
        "importPath": "mmcv.runner.base_module",
        "description": "mmcv.runner.base_module",
        "isExtraImport": true,
        "detail": "mmcv.runner.base_module",
        "documentation": {}
    },
    {
        "label": "BaseModule",
        "importPath": "mmcv.runner.base_module",
        "description": "mmcv.runner.base_module",
        "isExtraImport": true,
        "detail": "mmcv.runner.base_module",
        "documentation": {}
    },
    {
        "label": "ModuleList",
        "importPath": "mmcv.runner.base_module",
        "description": "mmcv.runner.base_module",
        "isExtraImport": true,
        "detail": "mmcv.runner.base_module",
        "documentation": {}
    },
    {
        "label": "Sequential",
        "importPath": "mmcv.runner.base_module",
        "description": "mmcv.runner.base_module",
        "isExtraImport": true,
        "detail": "mmcv.runner.base_module",
        "documentation": {}
    },
    {
        "label": "BaseModule",
        "importPath": "mmcv.runner.base_module",
        "description": "mmcv.runner.base_module",
        "isExtraImport": true,
        "detail": "mmcv.runner.base_module",
        "documentation": {}
    },
    {
        "label": "ModuleList",
        "importPath": "mmcv.runner.base_module",
        "description": "mmcv.runner.base_module",
        "isExtraImport": true,
        "detail": "mmcv.runner.base_module",
        "documentation": {}
    },
    {
        "label": "Sequential",
        "importPath": "mmcv.runner.base_module",
        "description": "mmcv.runner.base_module",
        "isExtraImport": true,
        "detail": "mmcv.runner.base_module",
        "documentation": {}
    },
    {
        "label": "BaseModule",
        "importPath": "mmcv.runner.base_module",
        "description": "mmcv.runner.base_module",
        "isExtraImport": true,
        "detail": "mmcv.runner.base_module",
        "documentation": {}
    },
    {
        "label": "ModuleList",
        "importPath": "mmcv.runner.base_module",
        "description": "mmcv.runner.base_module",
        "isExtraImport": true,
        "detail": "mmcv.runner.base_module",
        "documentation": {}
    },
    {
        "label": "Sequential",
        "importPath": "mmcv.runner.base_module",
        "description": "mmcv.runner.base_module",
        "isExtraImport": true,
        "detail": "mmcv.runner.base_module",
        "documentation": {}
    },
    {
        "label": "BaseModule",
        "importPath": "mmcv.runner.base_module",
        "description": "mmcv.runner.base_module",
        "isExtraImport": true,
        "detail": "mmcv.runner.base_module",
        "documentation": {}
    },
    {
        "label": "ModuleList",
        "importPath": "mmcv.runner.base_module",
        "description": "mmcv.runner.base_module",
        "isExtraImport": true,
        "detail": "mmcv.runner.base_module",
        "documentation": {}
    },
    {
        "label": "Sequential",
        "importPath": "mmcv.runner.base_module",
        "description": "mmcv.runner.base_module",
        "isExtraImport": true,
        "detail": "mmcv.runner.base_module",
        "documentation": {}
    },
    {
        "label": "BaseModule",
        "importPath": "mmcv.runner.base_module",
        "description": "mmcv.runner.base_module",
        "isExtraImport": true,
        "detail": "mmcv.runner.base_module",
        "documentation": {}
    },
    {
        "label": "BaseModule",
        "importPath": "mmcv.runner.base_module",
        "description": "mmcv.runner.base_module",
        "isExtraImport": true,
        "detail": "mmcv.runner.base_module",
        "documentation": {}
    },
    {
        "label": "BaseModule",
        "importPath": "mmcv.runner.base_module",
        "description": "mmcv.runner.base_module",
        "isExtraImport": true,
        "detail": "mmcv.runner.base_module",
        "documentation": {}
    },
    {
        "label": "ATTENTION",
        "importPath": "mmcv.cnn.bricks.registry",
        "description": "mmcv.cnn.bricks.registry",
        "isExtraImport": true,
        "detail": "mmcv.cnn.bricks.registry",
        "documentation": {}
    },
    {
        "label": "FEEDFORWARD_NETWORK",
        "importPath": "mmcv.cnn.bricks.registry",
        "description": "mmcv.cnn.bricks.registry",
        "isExtraImport": true,
        "detail": "mmcv.cnn.bricks.registry",
        "documentation": {}
    },
    {
        "label": "POSITIONAL_ENCODING",
        "importPath": "mmcv.cnn.bricks.registry",
        "description": "mmcv.cnn.bricks.registry",
        "isExtraImport": true,
        "detail": "mmcv.cnn.bricks.registry",
        "documentation": {}
    },
    {
        "label": "TRANSFORMER_LAYER",
        "importPath": "mmcv.cnn.bricks.registry",
        "description": "mmcv.cnn.bricks.registry",
        "isExtraImport": true,
        "detail": "mmcv.cnn.bricks.registry",
        "documentation": {}
    },
    {
        "label": "TRANSFORMER_LAYER_SEQUENCE",
        "importPath": "mmcv.cnn.bricks.registry",
        "description": "mmcv.cnn.bricks.registry",
        "isExtraImport": true,
        "detail": "mmcv.cnn.bricks.registry",
        "documentation": {}
    },
    {
        "label": "ATTENTION",
        "importPath": "mmcv.cnn.bricks.registry",
        "description": "mmcv.cnn.bricks.registry",
        "isExtraImport": true,
        "detail": "mmcv.cnn.bricks.registry",
        "documentation": {}
    },
    {
        "label": "TRANSFORMER_LAYER_SEQUENCE",
        "importPath": "mmcv.cnn.bricks.registry",
        "description": "mmcv.cnn.bricks.registry",
        "isExtraImport": true,
        "detail": "mmcv.cnn.bricks.registry",
        "documentation": {}
    },
    {
        "label": "ATTENTION",
        "importPath": "mmcv.cnn.bricks.registry",
        "description": "mmcv.cnn.bricks.registry",
        "isExtraImport": true,
        "detail": "mmcv.cnn.bricks.registry",
        "documentation": {}
    },
    {
        "label": "TRANSFORMER_LAYER",
        "importPath": "mmcv.cnn.bricks.registry",
        "description": "mmcv.cnn.bricks.registry",
        "isExtraImport": true,
        "detail": "mmcv.cnn.bricks.registry",
        "documentation": {}
    },
    {
        "label": "TRANSFORMER_LAYER_SEQUENCE",
        "importPath": "mmcv.cnn.bricks.registry",
        "description": "mmcv.cnn.bricks.registry",
        "isExtraImport": true,
        "detail": "mmcv.cnn.bricks.registry",
        "documentation": {}
    },
    {
        "label": "ATTENTION",
        "importPath": "mmcv.cnn.bricks.registry",
        "description": "mmcv.cnn.bricks.registry",
        "isExtraImport": true,
        "detail": "mmcv.cnn.bricks.registry",
        "documentation": {}
    },
    {
        "label": "FEEDFORWARD_NETWORK",
        "importPath": "mmcv.cnn.bricks.registry",
        "description": "mmcv.cnn.bricks.registry",
        "isExtraImport": true,
        "detail": "mmcv.cnn.bricks.registry",
        "documentation": {}
    },
    {
        "label": "POSITIONAL_ENCODING",
        "importPath": "mmcv.cnn.bricks.registry",
        "description": "mmcv.cnn.bricks.registry",
        "isExtraImport": true,
        "detail": "mmcv.cnn.bricks.registry",
        "documentation": {}
    },
    {
        "label": "TRANSFORMER_LAYER",
        "importPath": "mmcv.cnn.bricks.registry",
        "description": "mmcv.cnn.bricks.registry",
        "isExtraImport": true,
        "detail": "mmcv.cnn.bricks.registry",
        "documentation": {}
    },
    {
        "label": "TRANSFORMER_LAYER_SEQUENCE",
        "importPath": "mmcv.cnn.bricks.registry",
        "description": "mmcv.cnn.bricks.registry",
        "isExtraImport": true,
        "detail": "mmcv.cnn.bricks.registry",
        "documentation": {}
    },
    {
        "label": "ATTENTION",
        "importPath": "mmcv.cnn.bricks.registry",
        "description": "mmcv.cnn.bricks.registry",
        "isExtraImport": true,
        "detail": "mmcv.cnn.bricks.registry",
        "documentation": {}
    },
    {
        "label": "TRANSFORMER_LAYER",
        "importPath": "mmcv.cnn.bricks.registry",
        "description": "mmcv.cnn.bricks.registry",
        "isExtraImport": true,
        "detail": "mmcv.cnn.bricks.registry",
        "documentation": {}
    },
    {
        "label": "TRANSFORMER_LAYER_SEQUENCE",
        "importPath": "mmcv.cnn.bricks.registry",
        "description": "mmcv.cnn.bricks.registry",
        "isExtraImport": true,
        "detail": "mmcv.cnn.bricks.registry",
        "documentation": {}
    },
    {
        "label": "ATTENTION",
        "importPath": "mmcv.cnn.bricks.registry",
        "description": "mmcv.cnn.bricks.registry",
        "isExtraImport": true,
        "detail": "mmcv.cnn.bricks.registry",
        "documentation": {}
    },
    {
        "label": "multi_scale_deformable_attn_pytorch",
        "importPath": "mmcv.ops.multi_scale_deform_attn",
        "description": "mmcv.ops.multi_scale_deform_attn",
        "isExtraImport": true,
        "detail": "mmcv.ops.multi_scale_deform_attn",
        "documentation": {}
    },
    {
        "label": "multi_scale_deformable_attn_pytorch",
        "importPath": "mmcv.ops.multi_scale_deform_attn",
        "description": "mmcv.ops.multi_scale_deform_attn",
        "isExtraImport": true,
        "detail": "mmcv.ops.multi_scale_deform_attn",
        "documentation": {}
    },
    {
        "label": "multi_scale_deformable_attn_pytorch",
        "importPath": "mmcv.ops.multi_scale_deform_attn",
        "description": "mmcv.ops.multi_scale_deform_attn",
        "isExtraImport": true,
        "detail": "mmcv.ops.multi_scale_deform_attn",
        "documentation": {}
    },
    {
        "label": "pyplot",
        "importPath": "matplotlib",
        "description": "matplotlib",
        "isExtraImport": true,
        "detail": "matplotlib",
        "documentation": {}
    },
    {
        "label": "pyplot",
        "importPath": "matplotlib",
        "description": "matplotlib",
        "isExtraImport": true,
        "detail": "matplotlib",
        "documentation": {}
    },
    {
        "label": "pyplot",
        "importPath": "matplotlib",
        "description": "matplotlib",
        "isExtraImport": true,
        "detail": "matplotlib",
        "documentation": {}
    },
    {
        "label": "rcParams",
        "importPath": "matplotlib",
        "description": "matplotlib",
        "isExtraImport": true,
        "detail": "matplotlib",
        "documentation": {}
    },
    {
        "label": "rcParams",
        "importPath": "matplotlib",
        "description": "matplotlib",
        "isExtraImport": true,
        "detail": "matplotlib",
        "documentation": {}
    },
    {
        "label": "rcParams",
        "importPath": "matplotlib",
        "description": "matplotlib",
        "isExtraImport": true,
        "detail": "matplotlib",
        "documentation": {}
    },
    {
        "label": "math",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "math",
        "description": "math",
        "detail": "math",
        "documentation": {}
    },
    {
        "label": "Sequence",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Sequence",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Iterable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "build_dropout",
        "importPath": "mmcv.cnn.bricks.drop",
        "description": "mmcv.cnn.bricks.drop",
        "isExtraImport": true,
        "detail": "mmcv.cnn.bricks.drop",
        "documentation": {}
    },
    {
        "label": "custom_bwd",
        "importPath": "torch.cuda.amp",
        "description": "torch.cuda.amp",
        "isExtraImport": true,
        "detail": "torch.cuda.amp",
        "documentation": {}
    },
    {
        "label": "custom_fwd",
        "importPath": "torch.cuda.amp",
        "description": "torch.cuda.amp",
        "isExtraImport": true,
        "detail": "torch.cuda.amp",
        "documentation": {}
    },
    {
        "label": "Function",
        "importPath": "torch.autograd.function",
        "description": "torch.autograd.function",
        "isExtraImport": true,
        "detail": "torch.autograd.function",
        "documentation": {}
    },
    {
        "label": "once_differentiable",
        "importPath": "torch.autograd.function",
        "description": "torch.autograd.function",
        "isExtraImport": true,
        "detail": "torch.autograd.function",
        "documentation": {}
    },
    {
        "label": "TRANSFORMER",
        "importPath": "mmdet.models.utils.builder",
        "description": "mmdet.models.utils.builder",
        "isExtraImport": true,
        "detail": "mmdet.models.utils.builder",
        "documentation": {}
    },
    {
        "label": "TRANSFORMER",
        "importPath": "mmdet.models.utils.builder",
        "description": "mmdet.models.utils.builder",
        "isExtraImport": true,
        "detail": "mmdet.models.utils.builder",
        "documentation": {}
    },
    {
        "label": "normal_",
        "importPath": "torch.nn.init",
        "description": "torch.nn.init",
        "isExtraImport": true,
        "detail": "torch.nn.init",
        "documentation": {}
    },
    {
        "label": "normal_",
        "importPath": "torch.nn.init",
        "description": "torch.nn.init",
        "isExtraImport": true,
        "detail": "torch.nn.init",
        "documentation": {}
    },
    {
        "label": "save_tensor",
        "importPath": "projects.mmdet3d_plugin.models.utils.visual",
        "description": "projects.mmdet3d_plugin.models.utils.visual",
        "isExtraImport": true,
        "detail": "projects.mmdet3d_plugin.models.utils.visual",
        "documentation": {}
    },
    {
        "label": "save_tensor",
        "importPath": "projects.mmdet3d_plugin.models.utils.visual",
        "description": "projects.mmdet3d_plugin.models.utils.visual",
        "isExtraImport": true,
        "detail": "projects.mmdet3d_plugin.models.utils.visual",
        "documentation": {}
    },
    {
        "label": "rotate",
        "importPath": "torchvision.transforms.functional",
        "description": "torchvision.transforms.functional",
        "isExtraImport": true,
        "detail": "torchvision.transforms.functional",
        "documentation": {}
    },
    {
        "label": "rotate",
        "importPath": "torchvision.transforms.functional",
        "description": "torchvision.transforms.functional",
        "isExtraImport": true,
        "detail": "torchvision.transforms.functional",
        "documentation": {}
    },
    {
        "label": "rotate",
        "importPath": "torchvision.transforms.functional",
        "description": "torchvision.transforms.functional",
        "isExtraImport": true,
        "detail": "torchvision.transforms.functional",
        "documentation": {}
    },
    {
        "label": "torch.utils.checkpoint",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch.utils.checkpoint",
        "description": "torch.utils.checkpoint",
        "detail": "torch.utils.checkpoint",
        "documentation": {}
    },
    {
        "label": "Bottleneck",
        "importPath": "mmdet.models.backbones.resnet",
        "description": "mmdet.models.backbones.resnet",
        "isExtraImport": true,
        "detail": "mmdet.models.backbones.resnet",
        "documentation": {}
    },
    {
        "label": "BasicBlock",
        "importPath": "mmdet.models.backbones.resnet",
        "description": "mmdet.models.backbones.resnet",
        "isExtraImport": true,
        "detail": "mmdet.models.backbones.resnet",
        "documentation": {}
    },
    {
        "label": "BaseRunner",
        "importPath": "mmcv.runner.base_runner",
        "description": "mmcv.runner.base_runner",
        "isExtraImport": true,
        "detail": "mmcv.runner.base_runner",
        "documentation": {}
    },
    {
        "label": "EpochBasedRunner",
        "importPath": "mmcv.runner.epoch_based_runner",
        "description": "mmcv.runner.epoch_based_runner",
        "isExtraImport": true,
        "detail": "mmcv.runner.epoch_based_runner",
        "documentation": {}
    },
    {
        "label": "RUNNERS",
        "importPath": "mmcv.runner.builder",
        "description": "mmcv.runner.builder",
        "isExtraImport": true,
        "detail": "mmcv.runner.builder",
        "documentation": {}
    },
    {
        "label": "save_checkpoint",
        "importPath": "mmcv.runner.checkpoint",
        "description": "mmcv.runner.checkpoint",
        "isExtraImport": true,
        "detail": "mmcv.runner.checkpoint",
        "documentation": {}
    },
    {
        "label": "get_host_info",
        "importPath": "mmcv.runner.utils",
        "description": "mmcv.runner.utils",
        "isExtraImport": true,
        "detail": "mmcv.runner.utils",
        "documentation": {}
    },
    {
        "label": "pprint",
        "importPath": "pprint",
        "description": "pprint",
        "isExtraImport": true,
        "detail": "pprint",
        "documentation": {}
    },
    {
        "label": "DataContainer",
        "importPath": "mmcv.parallel.data_container",
        "description": "mmcv.parallel.data_container",
        "isExtraImport": true,
        "detail": "mmcv.parallel.data_container",
        "documentation": {}
    },
    {
        "label": "DataContainer",
        "importPath": "mmcv.parallel.data_container",
        "description": "mmcv.parallel.data_container",
        "isExtraImport": true,
        "detail": "mmcv.parallel.data_container",
        "documentation": {}
    },
    {
        "label": "BBOX_ASSIGNERS",
        "importPath": "mmdet.core.bbox.builder",
        "description": "mmdet.core.bbox.builder",
        "isExtraImport": true,
        "detail": "mmdet.core.bbox.builder",
        "documentation": {}
    },
    {
        "label": "BBOX_CODERS",
        "importPath": "mmdet.core.bbox.builder",
        "description": "mmdet.core.bbox.builder",
        "isExtraImport": true,
        "detail": "mmdet.core.bbox.builder",
        "documentation": {}
    },
    {
        "label": "AssignResult",
        "importPath": "mmdet.core.bbox.assigners",
        "description": "mmdet.core.bbox.assigners",
        "isExtraImport": true,
        "detail": "mmdet.core.bbox.assigners",
        "documentation": {}
    },
    {
        "label": "BaseAssigner",
        "importPath": "mmdet.core.bbox.assigners",
        "description": "mmdet.core.bbox.assigners",
        "isExtraImport": true,
        "detail": "mmdet.core.bbox.assigners",
        "documentation": {}
    },
    {
        "label": "build_match_cost",
        "importPath": "mmdet.core.bbox.match_costs",
        "description": "mmdet.core.bbox.match_costs",
        "isExtraImport": true,
        "detail": "mmdet.core.bbox.match_costs",
        "documentation": {}
    },
    {
        "label": "BaseBBoxCoder",
        "importPath": "mmdet.core.bbox",
        "description": "mmdet.core.bbox",
        "isExtraImport": true,
        "detail": "mmdet.core.bbox",
        "documentation": {}
    },
    {
        "label": "MATCH_COST",
        "importPath": "mmdet.core.bbox.match_costs.builder",
        "description": "mmdet.core.bbox.match_costs.builder",
        "isExtraImport": true,
        "detail": "mmdet.core.bbox.match_costs.builder",
        "documentation": {}
    },
    {
        "label": "bisect",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "bisect",
        "description": "bisect",
        "detail": "bisect",
        "documentation": {}
    },
    {
        "label": "_BatchNorm",
        "importPath": "torch.nn.modules.batchnorm",
        "description": "torch.nn.modules.batchnorm",
        "isExtraImport": true,
        "detail": "torch.nn.modules.batchnorm",
        "documentation": {}
    },
    {
        "label": "_BatchNorm",
        "importPath": "torch.nn.modules.batchnorm",
        "description": "torch.nn.modules.batchnorm",
        "isExtraImport": true,
        "detail": "torch.nn.modules.batchnorm",
        "documentation": {}
    },
    {
        "label": "DistEvalHook",
        "importPath": "mmdet.core.evaluation.eval_hooks",
        "description": "mmdet.core.evaluation.eval_hooks",
        "isExtraImport": true,
        "detail": "mmdet.core.evaluation.eval_hooks",
        "documentation": {}
    },
    {
        "label": "PIPELINES",
        "importPath": "mmdet.datasets.builder",
        "description": "mmdet.datasets.builder",
        "isExtraImport": true,
        "detail": "mmdet.datasets.builder",
        "documentation": {}
    },
    {
        "label": "PIPELINES",
        "importPath": "mmdet.datasets.builder",
        "description": "mmdet.datasets.builder",
        "isExtraImport": true,
        "detail": "mmdet.datasets.builder",
        "documentation": {}
    },
    {
        "label": "PIPELINES",
        "importPath": "mmdet.datasets.builder",
        "description": "mmdet.datasets.builder",
        "isExtraImport": true,
        "detail": "mmdet.datasets.builder",
        "documentation": {}
    },
    {
        "label": "PIPELINES",
        "importPath": "mmdet.datasets.builder",
        "description": "mmdet.datasets.builder",
        "isExtraImport": true,
        "detail": "mmdet.datasets.builder",
        "documentation": {}
    },
    {
        "label": "_concat_dataset",
        "importPath": "mmdet.datasets.builder",
        "description": "mmdet.datasets.builder",
        "isExtraImport": true,
        "detail": "mmdet.datasets.builder",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "ImageDraw",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "annotations_to_instances",
        "importPath": "projects.mmdet3d_plugin.dd3d.datasets.transform_utils",
        "description": "projects.mmdet3d_plugin.dd3d.datasets.transform_utils",
        "isExtraImport": true,
        "detail": "projects.mmdet3d_plugin.dd3d.datasets.transform_utils",
        "documentation": {}
    },
    {
        "label": "Pose",
        "importPath": "projects.mmdet3d_plugin.dd3d.structures.pose",
        "description": "projects.mmdet3d_plugin.dd3d.structures.pose",
        "isExtraImport": true,
        "detail": "projects.mmdet3d_plugin.dd3d.structures.pose",
        "documentation": {}
    },
    {
        "label": "Pose",
        "importPath": "projects.mmdet3d_plugin.dd3d.structures.pose",
        "description": "projects.mmdet3d_plugin.dd3d.structures.pose",
        "isExtraImport": true,
        "detail": "projects.mmdet3d_plugin.dd3d.structures.pose",
        "documentation": {}
    },
    {
        "label": "TaskManager",
        "importPath": "projects.mmdet3d_plugin.dd3d.utils.tasks",
        "description": "projects.mmdet3d_plugin.dd3d.utils.tasks",
        "isExtraImport": true,
        "detail": "projects.mmdet3d_plugin.dd3d.utils.tasks",
        "documentation": {}
    },
    {
        "label": "BaseInstance3DBoxes",
        "importPath": "mmdet3d.core.bbox",
        "description": "mmdet3d.core.bbox",
        "isExtraImport": true,
        "detail": "mmdet3d.core.bbox",
        "documentation": {}
    },
    {
        "label": "CameraInstance3DBoxes",
        "importPath": "mmdet3d.core.bbox",
        "description": "mmdet3d.core.bbox",
        "isExtraImport": true,
        "detail": "mmdet3d.core.bbox",
        "documentation": {}
    },
    {
        "label": "get_box_type",
        "importPath": "mmdet3d.core.bbox",
        "description": "mmdet3d.core.bbox",
        "isExtraImport": true,
        "detail": "mmdet3d.core.bbox",
        "documentation": {}
    },
    {
        "label": "box_np_ops",
        "importPath": "mmdet3d.core.bbox",
        "description": "mmdet3d.core.bbox",
        "isExtraImport": true,
        "detail": "mmdet3d.core.bbox",
        "documentation": {}
    },
    {
        "label": "box_np_ops",
        "importPath": "mmdet3d.core.bbox",
        "description": "mmdet3d.core.bbox",
        "isExtraImport": true,
        "detail": "mmdet3d.core.bbox",
        "documentation": {}
    },
    {
        "label": "Box3DMode",
        "importPath": "mmdet3d.core.bbox",
        "description": "mmdet3d.core.bbox",
        "isExtraImport": true,
        "detail": "mmdet3d.core.bbox",
        "documentation": {}
    },
    {
        "label": "CameraInstance3DBoxes",
        "importPath": "mmdet3d.core.bbox",
        "description": "mmdet3d.core.bbox",
        "isExtraImport": true,
        "detail": "mmdet3d.core.bbox",
        "documentation": {}
    },
    {
        "label": "Coord3DMode",
        "importPath": "mmdet3d.core.bbox",
        "description": "mmdet3d.core.bbox",
        "isExtraImport": true,
        "detail": "mmdet3d.core.bbox",
        "documentation": {}
    },
    {
        "label": "DepthInstance3DBoxes",
        "importPath": "mmdet3d.core.bbox",
        "description": "mmdet3d.core.bbox",
        "isExtraImport": true,
        "detail": "mmdet3d.core.bbox",
        "documentation": {}
    },
    {
        "label": "LiDARInstance3DBoxes",
        "importPath": "mmdet3d.core.bbox",
        "description": "mmdet3d.core.bbox",
        "isExtraImport": true,
        "detail": "mmdet3d.core.bbox",
        "documentation": {}
    },
    {
        "label": "BasePoints",
        "importPath": "mmdet3d.core.points",
        "description": "mmdet3d.core.points",
        "isExtraImport": true,
        "detail": "mmdet3d.core.points",
        "documentation": {}
    },
    {
        "label": "to_tensor",
        "importPath": "mmdet.datasets.pipelines",
        "description": "mmdet.datasets.pipelines",
        "isExtraImport": true,
        "detail": "mmdet.datasets.pipelines",
        "documentation": {}
    },
    {
        "label": "DefaultFormatBundle3D",
        "importPath": "mmdet3d.datasets.pipelines",
        "description": "mmdet3d.datasets.pipelines",
        "isExtraImport": true,
        "detail": "mmdet3d.datasets.pipelines",
        "documentation": {}
    },
    {
        "label": "Compose",
        "importPath": "mmdet3d.datasets.pipelines",
        "description": "mmdet3d.datasets.pipelines",
        "isExtraImport": true,
        "detail": "mmdet3d.datasets.pipelines",
        "documentation": {}
    },
    {
        "label": "DistributedSampler",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "Sampler",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "DataLoader",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "Dataset",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "embed",
        "importPath": "IPython",
        "description": "IPython",
        "isExtraImport": true,
        "detail": "IPython",
        "documentation": {}
    },
    {
        "label": "embed",
        "importPath": "IPython",
        "description": "IPython",
        "isExtraImport": true,
        "detail": "IPython",
        "documentation": {}
    },
    {
        "label": "Registry",
        "importPath": "mmcv.utils.registry",
        "description": "mmcv.utils.registry",
        "isExtraImport": true,
        "detail": "mmcv.utils.registry",
        "documentation": {}
    },
    {
        "label": "build_from_cfg",
        "importPath": "mmcv.utils.registry",
        "description": "mmcv.utils.registry",
        "isExtraImport": true,
        "detail": "mmcv.utils.registry",
        "documentation": {}
    },
    {
        "label": "platform",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "platform",
        "description": "platform",
        "detail": "platform",
        "documentation": {}
    },
    {
        "label": "functools",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "functools",
        "description": "functools",
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "partial",
        "importPath": "functools",
        "description": "functools",
        "isExtraImport": true,
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "wraps",
        "importPath": "functools",
        "description": "functools",
        "isExtraImport": true,
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "GroupSampler",
        "importPath": "mmdet.datasets.samplers",
        "description": "mmdet.datasets.samplers",
        "isExtraImport": true,
        "detail": "mmdet.datasets.samplers",
        "documentation": {}
    },
    {
        "label": "DistributedGroupSampler",
        "importPath": "projects.mmdet3d_plugin.datasets.samplers.group_sampler",
        "description": "projects.mmdet3d_plugin.datasets.samplers.group_sampler",
        "isExtraImport": true,
        "detail": "projects.mmdet3d_plugin.datasets.samplers.group_sampler",
        "documentation": {}
    },
    {
        "label": "DistributedSampler",
        "importPath": "projects.mmdet3d_plugin.datasets.samplers.distributed_sampler",
        "description": "projects.mmdet3d_plugin.datasets.samplers.distributed_sampler",
        "isExtraImport": true,
        "detail": "projects.mmdet3d_plugin.datasets.samplers.distributed_sampler",
        "documentation": {}
    },
    {
        "label": "build_sampler",
        "importPath": "projects.mmdet3d_plugin.datasets.samplers.sampler",
        "description": "projects.mmdet3d_plugin.datasets.samplers.sampler",
        "isExtraImport": true,
        "detail": "projects.mmdet3d_plugin.datasets.samplers.sampler",
        "documentation": {}
    },
    {
        "label": "NuScenesDataset",
        "importPath": "mmdet3d.datasets",
        "description": "mmdet3d.datasets",
        "isExtraImport": true,
        "detail": "mmdet3d.datasets",
        "documentation": {}
    },
    {
        "label": "NuScenesDataset",
        "importPath": "mmdet3d.datasets",
        "description": "mmdet3d.datasets",
        "isExtraImport": true,
        "detail": "mmdet3d.datasets",
        "documentation": {}
    },
    {
        "label": "build_dataset",
        "importPath": "mmdet3d.datasets",
        "description": "mmdet3d.datasets",
        "isExtraImport": true,
        "detail": "mmdet3d.datasets",
        "documentation": {}
    },
    {
        "label": "LyftDataset",
        "importPath": "mmdet3d.datasets",
        "description": "mmdet3d.datasets",
        "isExtraImport": true,
        "detail": "mmdet3d.datasets",
        "documentation": {}
    },
    {
        "label": "NuScenesDataset",
        "importPath": "mmdet3d.datasets",
        "description": "mmdet3d.datasets",
        "isExtraImport": true,
        "detail": "mmdet3d.datasets",
        "documentation": {}
    },
    {
        "label": "build_dataset",
        "importPath": "mmdet3d.datasets",
        "description": "mmdet3d.datasets",
        "isExtraImport": true,
        "detail": "mmdet3d.datasets",
        "documentation": {}
    },
    {
        "label": "build_dataset",
        "importPath": "mmdet3d.datasets",
        "description": "mmdet3d.datasets",
        "isExtraImport": true,
        "detail": "mmdet3d.datasets",
        "documentation": {}
    },
    {
        "label": "build_dataset",
        "importPath": "mmdet3d.datasets",
        "description": "mmdet3d.datasets",
        "isExtraImport": true,
        "detail": "mmdet3d.datasets",
        "documentation": {}
    },
    {
        "label": "build_dataset",
        "importPath": "mmdet3d.datasets",
        "description": "mmdet3d.datasets",
        "isExtraImport": true,
        "detail": "mmdet3d.datasets",
        "documentation": {}
    },
    {
        "label": "build_dataset",
        "importPath": "mmdet3d.datasets",
        "description": "mmdet3d.datasets",
        "isExtraImport": true,
        "detail": "mmdet3d.datasets",
        "documentation": {}
    },
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "path",
        "importPath": "os",
        "description": "os",
        "isExtraImport": true,
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "path",
        "importPath": "os",
        "description": "os",
        "isExtraImport": true,
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "path",
        "importPath": "os",
        "description": "os",
        "isExtraImport": true,
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "path",
        "importPath": "os",
        "description": "os",
        "isExtraImport": true,
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "path",
        "importPath": "os",
        "description": "os",
        "isExtraImport": true,
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "path",
        "importPath": "os",
        "description": "os",
        "isExtraImport": true,
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "path",
        "importPath": "os",
        "description": "os",
        "isExtraImport": true,
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "path",
        "importPath": "os",
        "description": "os",
        "isExtraImport": true,
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "path",
        "importPath": "os",
        "description": "os",
        "isExtraImport": true,
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "path",
        "importPath": "os",
        "description": "os",
        "isExtraImport": true,
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "path",
        "importPath": "os",
        "description": "os",
        "isExtraImport": true,
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "path",
        "importPath": "os",
        "description": "os",
        "isExtraImport": true,
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "path",
        "importPath": "os",
        "description": "os",
        "isExtraImport": true,
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "path",
        "importPath": "os",
        "description": "os",
        "isExtraImport": true,
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "path",
        "importPath": "os",
        "description": "os",
        "isExtraImport": true,
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "quaternion_yaw",
        "importPath": "nuscenes.eval.common.utils",
        "description": "nuscenes.eval.common.utils",
        "isExtraImport": true,
        "detail": "nuscenes.eval.common.utils",
        "documentation": {}
    },
    {
        "label": "Quaternion",
        "importPath": "nuscenes.eval.common.utils",
        "description": "nuscenes.eval.common.utils",
        "isExtraImport": true,
        "detail": "nuscenes.eval.common.utils",
        "documentation": {}
    },
    {
        "label": "quaternion_yaw",
        "importPath": "nuscenes.eval.common.utils",
        "description": "nuscenes.eval.common.utils",
        "isExtraImport": true,
        "detail": "nuscenes.eval.common.utils",
        "documentation": {}
    },
    {
        "label": "Quaternion",
        "importPath": "nuscenes.eval.common.utils",
        "description": "nuscenes.eval.common.utils",
        "isExtraImport": true,
        "detail": "nuscenes.eval.common.utils",
        "documentation": {}
    },
    {
        "label": "quaternion_yaw",
        "importPath": "nuscenes.eval.common.utils",
        "description": "nuscenes.eval.common.utils",
        "isExtraImport": true,
        "detail": "nuscenes.eval.common.utils",
        "documentation": {}
    },
    {
        "label": "Quaternion",
        "importPath": "nuscenes.eval.common.utils",
        "description": "nuscenes.eval.common.utils",
        "isExtraImport": true,
        "detail": "nuscenes.eval.common.utils",
        "documentation": {}
    },
    {
        "label": "boxes_to_sensor",
        "importPath": "nuscenes.eval.common.utils",
        "description": "nuscenes.eval.common.utils",
        "isExtraImport": true,
        "detail": "nuscenes.eval.common.utils",
        "documentation": {}
    },
    {
        "label": "NuscenesDataset",
        "importPath": "projects.mmdet3d_plugin.dd3d.datasets.nuscenes",
        "description": "projects.mmdet3d_plugin.dd3d.datasets.nuscenes",
        "isExtraImport": true,
        "detail": "projects.mmdet3d_plugin.dd3d.datasets.nuscenes",
        "documentation": {}
    },
    {
        "label": "MAX_NUM_ATTRIBUTES",
        "importPath": "projects.mmdet3d_plugin.dd3d.datasets.nuscenes",
        "description": "projects.mmdet3d_plugin.dd3d.datasets.nuscenes",
        "isExtraImport": true,
        "detail": "projects.mmdet3d_plugin.dd3d.datasets.nuscenes",
        "documentation": {}
    },
    {
        "label": "pyquaternion",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pyquaternion",
        "description": "pyquaternion",
        "detail": "pyquaternion",
        "documentation": {}
    },
    {
        "label": "Quaternion",
        "importPath": "pyquaternion",
        "description": "pyquaternion",
        "isExtraImport": true,
        "detail": "pyquaternion",
        "documentation": {}
    },
    {
        "label": "Quaternion",
        "importPath": "pyquaternion",
        "description": "pyquaternion",
        "isExtraImport": true,
        "detail": "pyquaternion",
        "documentation": {}
    },
    {
        "label": "Quaternion",
        "importPath": "pyquaternion",
        "description": "pyquaternion",
        "isExtraImport": true,
        "detail": "pyquaternion",
        "documentation": {}
    },
    {
        "label": "Quaternion",
        "importPath": "pyquaternion",
        "description": "pyquaternion",
        "isExtraImport": true,
        "detail": "pyquaternion",
        "documentation": {}
    },
    {
        "label": "Quaternion",
        "importPath": "pyquaternion",
        "description": "pyquaternion",
        "isExtraImport": true,
        "detail": "pyquaternion",
        "documentation": {}
    },
    {
        "label": "Quaternion",
        "importPath": "pyquaternion",
        "description": "pyquaternion",
        "isExtraImport": true,
        "detail": "pyquaternion",
        "documentation": {}
    },
    {
        "label": "Quaternion",
        "importPath": "pyquaternion",
        "description": "pyquaternion",
        "isExtraImport": true,
        "detail": "pyquaternion",
        "documentation": {}
    },
    {
        "label": "Box",
        "importPath": "nuscenes.utils.data_classes",
        "description": "nuscenes.utils.data_classes",
        "isExtraImport": true,
        "detail": "nuscenes.utils.data_classes",
        "documentation": {}
    },
    {
        "label": "Box",
        "importPath": "nuscenes.utils.data_classes",
        "description": "nuscenes.utils.data_classes",
        "isExtraImport": true,
        "detail": "nuscenes.utils.data_classes",
        "documentation": {}
    },
    {
        "label": "LidarPointCloud",
        "importPath": "nuscenes.utils.data_classes",
        "description": "nuscenes.utils.data_classes",
        "isExtraImport": true,
        "detail": "nuscenes.utils.data_classes",
        "documentation": {}
    },
    {
        "label": "LidarPointCloud",
        "importPath": "nuscenes.utils.data_classes",
        "description": "nuscenes.utils.data_classes",
        "isExtraImport": true,
        "detail": "nuscenes.utils.data_classes",
        "documentation": {}
    },
    {
        "label": "RadarPointCloud",
        "importPath": "nuscenes.utils.data_classes",
        "description": "nuscenes.utils.data_classes",
        "isExtraImport": true,
        "detail": "nuscenes.utils.data_classes",
        "documentation": {}
    },
    {
        "label": "Box",
        "importPath": "nuscenes.utils.data_classes",
        "description": "nuscenes.utils.data_classes",
        "isExtraImport": true,
        "detail": "nuscenes.utils.data_classes",
        "documentation": {}
    },
    {
        "label": "LidarPointCloud",
        "importPath": "nuscenes.utils.data_classes",
        "description": "nuscenes.utils.data_classes",
        "isExtraImport": true,
        "detail": "nuscenes.utils.data_classes",
        "documentation": {}
    },
    {
        "label": "RadarPointCloud",
        "importPath": "nuscenes.utils.data_classes",
        "description": "nuscenes.utils.data_classes",
        "isExtraImport": true,
        "detail": "nuscenes.utils.data_classes",
        "documentation": {}
    },
    {
        "label": "Box",
        "importPath": "nuscenes.utils.data_classes",
        "description": "nuscenes.utils.data_classes",
        "isExtraImport": true,
        "detail": "nuscenes.utils.data_classes",
        "documentation": {}
    },
    {
        "label": "extract_result_dict",
        "importPath": "mmdet3d.datasets.utils",
        "description": "mmdet3d.datasets.utils",
        "isExtraImport": true,
        "detail": "mmdet3d.datasets.utils",
        "documentation": {}
    },
    {
        "label": "get_loading_pipeline",
        "importPath": "mmdet3d.datasets.utils",
        "description": "mmdet3d.datasets.utils",
        "isExtraImport": true,
        "detail": "mmdet3d.datasets.utils",
        "documentation": {}
    },
    {
        "label": "argparse",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "argparse",
        "description": "argparse",
        "detail": "argparse",
        "documentation": {}
    },
    {
        "label": "json",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "json",
        "description": "json",
        "detail": "json",
        "documentation": {}
    },
    {
        "label": "NuScenes",
        "importPath": "nuscenes",
        "description": "nuscenes",
        "isExtraImport": true,
        "detail": "nuscenes",
        "documentation": {}
    },
    {
        "label": "NuScenes",
        "importPath": "nuscenes",
        "description": "nuscenes",
        "isExtraImport": true,
        "detail": "nuscenes",
        "documentation": {}
    },
    {
        "label": "NuScenes",
        "importPath": "nuscenes",
        "description": "nuscenes",
        "isExtraImport": true,
        "detail": "nuscenes",
        "documentation": {}
    },
    {
        "label": "NuScenes",
        "importPath": "nuscenes",
        "description": "nuscenes",
        "isExtraImport": true,
        "detail": "nuscenes",
        "documentation": {}
    },
    {
        "label": "config_factory",
        "importPath": "nuscenes.eval.common.config",
        "description": "nuscenes.eval.common.config",
        "isExtraImport": true,
        "detail": "nuscenes.eval.common.config",
        "documentation": {}
    },
    {
        "label": "config_factory",
        "importPath": "nuscenes.eval.common.config",
        "description": "nuscenes.eval.common.config",
        "isExtraImport": true,
        "detail": "nuscenes.eval.common.config",
        "documentation": {}
    },
    {
        "label": "EvalBoxes",
        "importPath": "nuscenes.eval.common.data_classes",
        "description": "nuscenes.eval.common.data_classes",
        "isExtraImport": true,
        "detail": "nuscenes.eval.common.data_classes",
        "documentation": {}
    },
    {
        "label": "EvalBoxes",
        "importPath": "nuscenes.eval.common.data_classes",
        "description": "nuscenes.eval.common.data_classes",
        "isExtraImport": true,
        "detail": "nuscenes.eval.common.data_classes",
        "documentation": {}
    },
    {
        "label": "EvalBoxes",
        "importPath": "nuscenes.eval.common.data_classes",
        "description": "nuscenes.eval.common.data_classes",
        "isExtraImport": true,
        "detail": "nuscenes.eval.common.data_classes",
        "documentation": {}
    },
    {
        "label": "EvalBoxes",
        "importPath": "nuscenes.eval.common.data_classes",
        "description": "nuscenes.eval.common.data_classes",
        "isExtraImport": true,
        "detail": "nuscenes.eval.common.data_classes",
        "documentation": {}
    },
    {
        "label": "EvalBoxes",
        "importPath": "nuscenes.eval.common.data_classes",
        "description": "nuscenes.eval.common.data_classes",
        "isExtraImport": true,
        "detail": "nuscenes.eval.common.data_classes",
        "documentation": {}
    },
    {
        "label": "EvalBox",
        "importPath": "nuscenes.eval.common.data_classes",
        "description": "nuscenes.eval.common.data_classes",
        "isExtraImport": true,
        "detail": "nuscenes.eval.common.data_classes",
        "documentation": {}
    },
    {
        "label": "DetectionConfig",
        "importPath": "nuscenes.eval.detection.data_classes",
        "description": "nuscenes.eval.detection.data_classes",
        "isExtraImport": true,
        "detail": "nuscenes.eval.detection.data_classes",
        "documentation": {}
    },
    {
        "label": "DetectionBox",
        "importPath": "nuscenes.eval.detection.data_classes",
        "description": "nuscenes.eval.detection.data_classes",
        "isExtraImport": true,
        "detail": "nuscenes.eval.detection.data_classes",
        "documentation": {}
    },
    {
        "label": "DetectionConfig",
        "importPath": "nuscenes.eval.detection.data_classes",
        "description": "nuscenes.eval.detection.data_classes",
        "isExtraImport": true,
        "detail": "nuscenes.eval.detection.data_classes",
        "documentation": {}
    },
    {
        "label": "DetectionMetrics",
        "importPath": "nuscenes.eval.detection.data_classes",
        "description": "nuscenes.eval.detection.data_classes",
        "isExtraImport": true,
        "detail": "nuscenes.eval.detection.data_classes",
        "documentation": {}
    },
    {
        "label": "DetectionBox",
        "importPath": "nuscenes.eval.detection.data_classes",
        "description": "nuscenes.eval.detection.data_classes",
        "isExtraImport": true,
        "detail": "nuscenes.eval.detection.data_classes",
        "documentation": {}
    },
    {
        "label": "\\",
        "importPath": "nuscenes.eval.detection.data_classes",
        "description": "nuscenes.eval.detection.data_classes",
        "isExtraImport": true,
        "detail": "nuscenes.eval.detection.data_classes",
        "documentation": {}
    },
    {
        "label": "DetectionMetrics",
        "importPath": "nuscenes.eval.detection.data_classes",
        "description": "nuscenes.eval.detection.data_classes",
        "isExtraImport": true,
        "detail": "nuscenes.eval.detection.data_classes",
        "documentation": {}
    },
    {
        "label": "DetectionMetricData",
        "importPath": "nuscenes.eval.detection.data_classes",
        "description": "nuscenes.eval.detection.data_classes",
        "isExtraImport": true,
        "detail": "nuscenes.eval.detection.data_classes",
        "documentation": {}
    },
    {
        "label": "DetectionMetricDataList",
        "importPath": "nuscenes.eval.detection.data_classes",
        "description": "nuscenes.eval.detection.data_classes",
        "isExtraImport": true,
        "detail": "nuscenes.eval.detection.data_classes",
        "documentation": {}
    },
    {
        "label": "DetectionBox",
        "importPath": "nuscenes.eval.detection.data_classes",
        "description": "nuscenes.eval.detection.data_classes",
        "isExtraImport": true,
        "detail": "nuscenes.eval.detection.data_classes",
        "documentation": {}
    },
    {
        "label": "NuScenesEval",
        "importPath": "nuscenes.eval.detection.evaluate",
        "description": "nuscenes.eval.detection.evaluate",
        "isExtraImport": true,
        "detail": "nuscenes.eval.detection.evaluate",
        "documentation": {}
    },
    {
        "label": "category_to_detection_name",
        "importPath": "nuscenes.eval.detection.utils",
        "description": "nuscenes.eval.detection.utils",
        "isExtraImport": true,
        "detail": "nuscenes.eval.detection.utils",
        "documentation": {}
    },
    {
        "label": "category_to_detection_name",
        "importPath": "nuscenes.eval.detection.utils",
        "description": "nuscenes.eval.detection.utils",
        "isExtraImport": true,
        "detail": "nuscenes.eval.detection.utils",
        "documentation": {}
    },
    {
        "label": "category_to_detection_name",
        "importPath": "nuscenes.eval.detection.utils",
        "description": "nuscenes.eval.detection.utils",
        "isExtraImport": true,
        "detail": "nuscenes.eval.detection.utils",
        "documentation": {}
    },
    {
        "label": "TrackingBox",
        "importPath": "nuscenes.eval.tracking.data_classes",
        "description": "nuscenes.eval.tracking.data_classes",
        "isExtraImport": true,
        "detail": "nuscenes.eval.tracking.data_classes",
        "documentation": {}
    },
    {
        "label": "points_in_box",
        "importPath": "nuscenes.utils.geometry_utils",
        "description": "nuscenes.utils.geometry_utils",
        "isExtraImport": true,
        "detail": "nuscenes.utils.geometry_utils",
        "documentation": {}
    },
    {
        "label": "view_points",
        "importPath": "nuscenes.utils.geometry_utils",
        "description": "nuscenes.utils.geometry_utils",
        "isExtraImport": true,
        "detail": "nuscenes.utils.geometry_utils",
        "documentation": {}
    },
    {
        "label": "box_in_image",
        "importPath": "nuscenes.utils.geometry_utils",
        "description": "nuscenes.utils.geometry_utils",
        "isExtraImport": true,
        "detail": "nuscenes.utils.geometry_utils",
        "documentation": {}
    },
    {
        "label": "BoxVisibility",
        "importPath": "nuscenes.utils.geometry_utils",
        "description": "nuscenes.utils.geometry_utils",
        "isExtraImport": true,
        "detail": "nuscenes.utils.geometry_utils",
        "documentation": {}
    },
    {
        "label": "transform_matrix",
        "importPath": "nuscenes.utils.geometry_utils",
        "description": "nuscenes.utils.geometry_utils",
        "isExtraImport": true,
        "detail": "nuscenes.utils.geometry_utils",
        "documentation": {}
    },
    {
        "label": "view_points",
        "importPath": "nuscenes.utils.geometry_utils",
        "description": "nuscenes.utils.geometry_utils",
        "isExtraImport": true,
        "detail": "nuscenes.utils.geometry_utils",
        "documentation": {}
    },
    {
        "label": "view_points",
        "importPath": "nuscenes.utils.geometry_utils",
        "description": "nuscenes.utils.geometry_utils",
        "isExtraImport": true,
        "detail": "nuscenes.utils.geometry_utils",
        "documentation": {}
    },
    {
        "label": "box_in_image",
        "importPath": "nuscenes.utils.geometry_utils",
        "description": "nuscenes.utils.geometry_utils",
        "isExtraImport": true,
        "detail": "nuscenes.utils.geometry_utils",
        "documentation": {}
    },
    {
        "label": "BoxVisibility",
        "importPath": "nuscenes.utils.geometry_utils",
        "description": "nuscenes.utils.geometry_utils",
        "isExtraImport": true,
        "detail": "nuscenes.utils.geometry_utils",
        "documentation": {}
    },
    {
        "label": "transform_matrix",
        "importPath": "nuscenes.utils.geometry_utils",
        "description": "nuscenes.utils.geometry_utils",
        "isExtraImport": true,
        "detail": "nuscenes.utils.geometry_utils",
        "documentation": {}
    },
    {
        "label": "view_points",
        "importPath": "nuscenes.utils.geometry_utils",
        "description": "nuscenes.utils.geometry_utils",
        "isExtraImport": true,
        "detail": "nuscenes.utils.geometry_utils",
        "documentation": {}
    },
    {
        "label": "box_in_image",
        "importPath": "nuscenes.utils.geometry_utils",
        "description": "nuscenes.utils.geometry_utils",
        "isExtraImport": true,
        "detail": "nuscenes.utils.geometry_utils",
        "documentation": {}
    },
    {
        "label": "BoxVisibility",
        "importPath": "nuscenes.utils.geometry_utils",
        "description": "nuscenes.utils.geometry_utils",
        "isExtraImport": true,
        "detail": "nuscenes.utils.geometry_utils",
        "documentation": {}
    },
    {
        "label": "transform_matrix",
        "importPath": "nuscenes.utils.geometry_utils",
        "description": "nuscenes.utils.geometry_utils",
        "isExtraImport": true,
        "detail": "nuscenes.utils.geometry_utils",
        "documentation": {}
    },
    {
        "label": "view_points",
        "importPath": "nuscenes.utils.geometry_utils",
        "description": "nuscenes.utils.geometry_utils",
        "isExtraImport": true,
        "detail": "nuscenes.utils.geometry_utils",
        "documentation": {}
    },
    {
        "label": "view_points",
        "importPath": "nuscenes.utils.geometry_utils",
        "description": "nuscenes.utils.geometry_utils",
        "isExtraImport": true,
        "detail": "nuscenes.utils.geometry_utils",
        "documentation": {}
    },
    {
        "label": "create_splits_scenes",
        "importPath": "nuscenes.utils.splits",
        "description": "nuscenes.utils.splits",
        "isExtraImport": true,
        "detail": "nuscenes.utils.splits",
        "documentation": {}
    },
    {
        "label": "create_splits_scenes",
        "importPath": "nuscenes.utils.splits",
        "description": "nuscenes.utils.splits",
        "isExtraImport": true,
        "detail": "nuscenes.utils.splits",
        "documentation": {}
    },
    {
        "label": "load_prediction",
        "importPath": "nuscenes.eval.common.loaders",
        "description": "nuscenes.eval.common.loaders",
        "isExtraImport": true,
        "detail": "nuscenes.eval.common.loaders",
        "documentation": {}
    },
    {
        "label": "add_center_dist",
        "importPath": "nuscenes.eval.common.loaders",
        "description": "nuscenes.eval.common.loaders",
        "isExtraImport": true,
        "detail": "nuscenes.eval.common.loaders",
        "documentation": {}
    },
    {
        "label": "filter_eval_boxes",
        "importPath": "nuscenes.eval.common.loaders",
        "description": "nuscenes.eval.common.loaders",
        "isExtraImport": true,
        "detail": "nuscenes.eval.common.loaders",
        "documentation": {}
    },
    {
        "label": "load_prediction",
        "importPath": "nuscenes.eval.common.loaders",
        "description": "nuscenes.eval.common.loaders",
        "isExtraImport": true,
        "detail": "nuscenes.eval.common.loaders",
        "documentation": {}
    },
    {
        "label": "load_gt",
        "importPath": "nuscenes.eval.common.loaders",
        "description": "nuscenes.eval.common.loaders",
        "isExtraImport": true,
        "detail": "nuscenes.eval.common.loaders",
        "documentation": {}
    },
    {
        "label": "add_center_dist",
        "importPath": "nuscenes.eval.common.loaders",
        "description": "nuscenes.eval.common.loaders",
        "isExtraImport": true,
        "detail": "nuscenes.eval.common.loaders",
        "documentation": {}
    },
    {
        "label": "filter_eval_boxes",
        "importPath": "nuscenes.eval.common.loaders",
        "description": "nuscenes.eval.common.loaders",
        "isExtraImport": true,
        "detail": "nuscenes.eval.common.loaders",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "tqdm",
        "description": "tqdm",
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "accumulate",
        "importPath": "nuscenes.eval.detection.algo",
        "description": "nuscenes.eval.detection.algo",
        "isExtraImport": true,
        "detail": "nuscenes.eval.detection.algo",
        "documentation": {}
    },
    {
        "label": "calc_ap",
        "importPath": "nuscenes.eval.detection.algo",
        "description": "nuscenes.eval.detection.algo",
        "isExtraImport": true,
        "detail": "nuscenes.eval.detection.algo",
        "documentation": {}
    },
    {
        "label": "calc_tp",
        "importPath": "nuscenes.eval.detection.algo",
        "description": "nuscenes.eval.detection.algo",
        "isExtraImport": true,
        "detail": "nuscenes.eval.detection.algo",
        "documentation": {}
    },
    {
        "label": "TP_METRICS",
        "importPath": "nuscenes.eval.detection.constants",
        "description": "nuscenes.eval.detection.constants",
        "isExtraImport": true,
        "detail": "nuscenes.eval.detection.constants",
        "documentation": {}
    },
    {
        "label": "TP_METRICS",
        "importPath": "nuscenes.eval.detection.constants",
        "description": "nuscenes.eval.detection.constants",
        "isExtraImport": true,
        "detail": "nuscenes.eval.detection.constants",
        "documentation": {}
    },
    {
        "label": "DETECTION_NAMES",
        "importPath": "nuscenes.eval.detection.constants",
        "description": "nuscenes.eval.detection.constants",
        "isExtraImport": true,
        "detail": "nuscenes.eval.detection.constants",
        "documentation": {}
    },
    {
        "label": "DETECTION_COLORS",
        "importPath": "nuscenes.eval.detection.constants",
        "description": "nuscenes.eval.detection.constants",
        "isExtraImport": true,
        "detail": "nuscenes.eval.detection.constants",
        "documentation": {}
    },
    {
        "label": "TP_METRICS_UNITS",
        "importPath": "nuscenes.eval.detection.constants",
        "description": "nuscenes.eval.detection.constants",
        "isExtraImport": true,
        "detail": "nuscenes.eval.detection.constants",
        "documentation": {}
    },
    {
        "label": "\\",
        "importPath": "nuscenes.eval.detection.constants",
        "description": "nuscenes.eval.detection.constants",
        "isExtraImport": true,
        "detail": "nuscenes.eval.detection.constants",
        "documentation": {}
    },
    {
        "label": "summary_plot",
        "importPath": "nuscenes.eval.detection.render",
        "description": "nuscenes.eval.detection.render",
        "isExtraImport": true,
        "detail": "nuscenes.eval.detection.render",
        "documentation": {}
    },
    {
        "label": "class_pr_curve",
        "importPath": "nuscenes.eval.detection.render",
        "description": "nuscenes.eval.detection.render",
        "isExtraImport": true,
        "detail": "nuscenes.eval.detection.render",
        "documentation": {}
    },
    {
        "label": "dist_pr_curve",
        "importPath": "nuscenes.eval.detection.render",
        "description": "nuscenes.eval.detection.render",
        "isExtraImport": true,
        "detail": "nuscenes.eval.detection.render",
        "documentation": {}
    },
    {
        "label": "visualize_sample",
        "importPath": "nuscenes.eval.detection.render",
        "description": "nuscenes.eval.detection.render",
        "isExtraImport": true,
        "detail": "nuscenes.eval.detection.render",
        "documentation": {}
    },
    {
        "label": "visualize_sample",
        "importPath": "nuscenes.eval.detection.render",
        "description": "nuscenes.eval.detection.render",
        "isExtraImport": true,
        "detail": "nuscenes.eval.detection.render",
        "documentation": {}
    },
    {
        "label": "BboxOverlaps3D",
        "importPath": "mmdet3d.core.bbox.iou_calculators",
        "description": "mmdet3d.core.bbox.iou_calculators",
        "isExtraImport": true,
        "detail": "mmdet3d.core.bbox.iou_calculators",
        "documentation": {}
    },
    {
        "label": "setup_axis",
        "importPath": "nuscenes.eval.common.render",
        "description": "nuscenes.eval.common.render",
        "isExtraImport": true,
        "detail": "nuscenes.eval.common.render",
        "documentation": {}
    },
    {
        "label": "seaborn",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "seaborn",
        "description": "seaborn",
        "detail": "seaborn",
        "documentation": {}
    },
    {
        "label": "BoxMode",
        "importPath": "detectron2.structures.boxes",
        "description": "detectron2.structures.boxes",
        "isExtraImport": true,
        "detail": "detectron2.structures.boxes",
        "documentation": {}
    },
    {
        "label": "NuScenes",
        "importPath": "nuscenes.nuscenes",
        "description": "nuscenes.nuscenes",
        "isExtraImport": true,
        "detail": "nuscenes.nuscenes",
        "documentation": {}
    },
    {
        "label": "NuScenes",
        "importPath": "nuscenes.nuscenes",
        "description": "nuscenes.nuscenes",
        "isExtraImport": true,
        "detail": "nuscenes.nuscenes",
        "documentation": {}
    },
    {
        "label": "NuScenes",
        "importPath": "nuscenes.nuscenes",
        "description": "nuscenes.nuscenes",
        "isExtraImport": true,
        "detail": "nuscenes.nuscenes",
        "documentation": {}
    },
    {
        "label": "GenericBoxes3D",
        "importPath": "projects.mmdet3d_plugin.dd3d.structures.boxes3d",
        "description": "projects.mmdet3d_plugin.dd3d.structures.boxes3d",
        "isExtraImport": true,
        "detail": "projects.mmdet3d_plugin.dd3d.structures.boxes3d",
        "documentation": {}
    },
    {
        "label": "Boxes3D",
        "importPath": "projects.mmdet3d_plugin.dd3d.structures.boxes3d",
        "description": "projects.mmdet3d_plugin.dd3d.structures.boxes3d",
        "isExtraImport": true,
        "detail": "projects.mmdet3d_plugin.dd3d.structures.boxes3d",
        "documentation": {}
    },
    {
        "label": "Boxes3D",
        "importPath": "projects.mmdet3d_plugin.dd3d.structures.boxes3d",
        "description": "projects.mmdet3d_plugin.dd3d.structures.boxes3d",
        "isExtraImport": true,
        "detail": "projects.mmdet3d_plugin.dd3d.structures.boxes3d",
        "documentation": {}
    },
    {
        "label": "Boxes3D",
        "importPath": "projects.mmdet3d_plugin.dd3d.structures.boxes3d",
        "description": "projects.mmdet3d_plugin.dd3d.structures.boxes3d",
        "isExtraImport": true,
        "detail": "projects.mmdet3d_plugin.dd3d.structures.boxes3d",
        "documentation": {}
    },
    {
        "label": "Boxes3D",
        "importPath": "projects.mmdet3d_plugin.dd3d.structures.boxes3d",
        "description": "projects.mmdet3d_plugin.dd3d.structures.boxes3d",
        "isExtraImport": true,
        "detail": "projects.mmdet3d_plugin.dd3d.structures.boxes3d",
        "documentation": {}
    },
    {
        "label": "project_points3d",
        "importPath": "projects.mmdet3d_plugin.dd3d.utils.geometry",
        "description": "projects.mmdet3d_plugin.dd3d.utils.geometry",
        "isExtraImport": true,
        "detail": "projects.mmdet3d_plugin.dd3d.utils.geometry",
        "documentation": {}
    },
    {
        "label": "allocentric_to_egocentric",
        "importPath": "projects.mmdet3d_plugin.dd3d.utils.geometry",
        "description": "projects.mmdet3d_plugin.dd3d.utils.geometry",
        "isExtraImport": true,
        "detail": "projects.mmdet3d_plugin.dd3d.utils.geometry",
        "documentation": {}
    },
    {
        "label": "unproject_points2d",
        "importPath": "projects.mmdet3d_plugin.dd3d.utils.geometry",
        "description": "projects.mmdet3d_plugin.dd3d.utils.geometry",
        "isExtraImport": true,
        "detail": "projects.mmdet3d_plugin.dd3d.utils.geometry",
        "documentation": {}
    },
    {
        "label": "unproject_points2d",
        "importPath": "projects.mmdet3d_plugin.dd3d.utils.geometry",
        "description": "projects.mmdet3d_plugin.dd3d.utils.geometry",
        "isExtraImport": true,
        "detail": "projects.mmdet3d_plugin.dd3d.utils.geometry",
        "documentation": {}
    },
    {
        "label": "float_to_uint8_color",
        "importPath": "projects.mmdet3d_plugin.dd3d.utils.visualization",
        "description": "projects.mmdet3d_plugin.dd3d.utils.visualization",
        "isExtraImport": true,
        "detail": "projects.mmdet3d_plugin.dd3d.utils.visualization",
        "documentation": {}
    },
    {
        "label": "transforms",
        "importPath": "detectron2.data",
        "description": "detectron2.data",
        "isExtraImport": true,
        "detail": "detectron2.data",
        "documentation": {}
    },
    {
        "label": "Boxes",
        "importPath": "detectron2.structures",
        "description": "detectron2.structures",
        "isExtraImport": true,
        "detail": "detectron2.structures",
        "documentation": {}
    },
    {
        "label": "BoxMode",
        "importPath": "detectron2.structures",
        "description": "detectron2.structures",
        "isExtraImport": true,
        "detail": "detectron2.structures",
        "documentation": {}
    },
    {
        "label": "Instances",
        "importPath": "detectron2.structures",
        "description": "detectron2.structures",
        "isExtraImport": true,
        "detail": "detectron2.structures",
        "documentation": {}
    },
    {
        "label": "Instances",
        "importPath": "detectron2.structures",
        "description": "detectron2.structures",
        "isExtraImport": true,
        "detail": "detectron2.structures",
        "documentation": {}
    },
    {
        "label": "Boxes",
        "importPath": "detectron2.structures",
        "description": "detectron2.structures",
        "isExtraImport": true,
        "detail": "detectron2.structures",
        "documentation": {}
    },
    {
        "label": "Instances",
        "importPath": "detectron2.structures",
        "description": "detectron2.structures",
        "isExtraImport": true,
        "detail": "detectron2.structures",
        "documentation": {}
    },
    {
        "label": "Instances",
        "importPath": "detectron2.structures",
        "description": "detectron2.structures",
        "isExtraImport": true,
        "detail": "detectron2.structures",
        "documentation": {}
    },
    {
        "label": "logging",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "logging",
        "description": "logging",
        "detail": "logging",
        "documentation": {}
    },
    {
        "label": "warning",
        "importPath": "logging",
        "description": "logging",
        "isExtraImport": true,
        "detail": "logging",
        "documentation": {}
    },
    {
        "label": "detector_postprocess",
        "importPath": "detectron2.modeling.postprocessing",
        "description": "detectron2.modeling.postprocessing",
        "isExtraImport": true,
        "detail": "detectron2.modeling.postprocessing",
        "documentation": {}
    },
    {
        "label": "detector_postprocess",
        "importPath": "detectron2.modeling.postprocessing",
        "description": "detectron2.modeling.postprocessing",
        "isExtraImport": true,
        "detail": "detectron2.modeling.postprocessing",
        "documentation": {}
    },
    {
        "label": "ShapeSpec",
        "importPath": "detectron2.layers",
        "description": "detectron2.layers",
        "isExtraImport": true,
        "detail": "detectron2.layers",
        "documentation": {}
    },
    {
        "label": "Conv2d",
        "importPath": "detectron2.layers",
        "description": "detectron2.layers",
        "isExtraImport": true,
        "detail": "detectron2.layers",
        "documentation": {}
    },
    {
        "label": "batched_nms",
        "importPath": "detectron2.layers",
        "description": "detectron2.layers",
        "isExtraImport": true,
        "detail": "detectron2.layers",
        "documentation": {}
    },
    {
        "label": "cat",
        "importPath": "detectron2.layers",
        "description": "detectron2.layers",
        "isExtraImport": true,
        "detail": "detectron2.layers",
        "documentation": {}
    },
    {
        "label": "get_norm",
        "importPath": "detectron2.layers",
        "description": "detectron2.layers",
        "isExtraImport": true,
        "detail": "detectron2.layers",
        "documentation": {}
    },
    {
        "label": "Conv2d",
        "importPath": "detectron2.layers",
        "description": "detectron2.layers",
        "isExtraImport": true,
        "detail": "detectron2.layers",
        "documentation": {}
    },
    {
        "label": "cat",
        "importPath": "detectron2.layers",
        "description": "detectron2.layers",
        "isExtraImport": true,
        "detail": "detectron2.layers",
        "documentation": {}
    },
    {
        "label": "get_norm",
        "importPath": "detectron2.layers",
        "description": "detectron2.layers",
        "isExtraImport": true,
        "detail": "detectron2.layers",
        "documentation": {}
    },
    {
        "label": "Conv2d",
        "importPath": "detectron2.layers",
        "description": "detectron2.layers",
        "isExtraImport": true,
        "detail": "detectron2.layers",
        "documentation": {}
    },
    {
        "label": "cat",
        "importPath": "detectron2.layers",
        "description": "detectron2.layers",
        "isExtraImport": true,
        "detail": "detectron2.layers",
        "documentation": {}
    },
    {
        "label": "cat",
        "importPath": "detectron2.layers",
        "description": "detectron2.layers",
        "isExtraImport": true,
        "detail": "detectron2.layers",
        "documentation": {}
    },
    {
        "label": "ImageList",
        "importPath": "projects.mmdet3d_plugin.dd3d.structures.image_list",
        "description": "projects.mmdet3d_plugin.dd3d.structures.image_list",
        "isExtraImport": true,
        "detail": "projects.mmdet3d_plugin.dd3d.structures.image_list",
        "documentation": {}
    },
    {
        "label": "ImageList",
        "importPath": "projects.mmdet3d_plugin.dd3d.structures.image_list",
        "description": "projects.mmdet3d_plugin.dd3d.structures.image_list",
        "isExtraImport": true,
        "detail": "projects.mmdet3d_plugin.dd3d.structures.image_list",
        "documentation": {}
    },
    {
        "label": "compute_features_locations",
        "importPath": "projects.mmdet3d_plugin.dd3d.utils.tensor2d",
        "description": "projects.mmdet3d_plugin.dd3d.utils.tensor2d",
        "isExtraImport": true,
        "detail": "projects.mmdet3d_plugin.dd3d.utils.tensor2d",
        "documentation": {}
    },
    {
        "label": "smooth_l1_loss",
        "importPath": "projects.mmdet3d_plugin.dd3d.layers.smooth_l1_loss",
        "description": "projects.mmdet3d_plugin.dd3d.layers.smooth_l1_loss",
        "isExtraImport": true,
        "detail": "projects.mmdet3d_plugin.dd3d.layers.smooth_l1_loss",
        "documentation": {}
    },
    {
        "label": "sigmoid_focal_loss",
        "importPath": "fvcore.nn",
        "description": "fvcore.nn",
        "isExtraImport": true,
        "detail": "fvcore.nn",
        "documentation": {}
    },
    {
        "label": "get_world_size",
        "importPath": "detectron2.utils.comm",
        "description": "detectron2.utils.comm",
        "isExtraImport": true,
        "detail": "detectron2.utils.comm",
        "documentation": {}
    },
    {
        "label": "IOULoss",
        "importPath": "projects.mmdet3d_plugin.dd3d.layers.iou_loss",
        "description": "projects.mmdet3d_plugin.dd3d.layers.iou_loss",
        "isExtraImport": true,
        "detail": "projects.mmdet3d_plugin.dd3d.layers.iou_loss",
        "documentation": {}
    },
    {
        "label": "ModuleListDial",
        "importPath": "projects.mmdet3d_plugin.dd3d.layers.normalization",
        "description": "projects.mmdet3d_plugin.dd3d.layers.normalization",
        "isExtraImport": true,
        "detail": "projects.mmdet3d_plugin.dd3d.layers.normalization",
        "documentation": {}
    },
    {
        "label": "Scale",
        "importPath": "projects.mmdet3d_plugin.dd3d.layers.normalization",
        "description": "projects.mmdet3d_plugin.dd3d.layers.normalization",
        "isExtraImport": true,
        "detail": "projects.mmdet3d_plugin.dd3d.layers.normalization",
        "documentation": {}
    },
    {
        "label": "ModuleListDial",
        "importPath": "projects.mmdet3d_plugin.dd3d.layers.normalization",
        "description": "projects.mmdet3d_plugin.dd3d.layers.normalization",
        "isExtraImport": true,
        "detail": "projects.mmdet3d_plugin.dd3d.layers.normalization",
        "documentation": {}
    },
    {
        "label": "Offset",
        "importPath": "projects.mmdet3d_plugin.dd3d.layers.normalization",
        "description": "projects.mmdet3d_plugin.dd3d.layers.normalization",
        "isExtraImport": true,
        "detail": "projects.mmdet3d_plugin.dd3d.layers.normalization",
        "documentation": {}
    },
    {
        "label": "Scale",
        "importPath": "projects.mmdet3d_plugin.dd3d.layers.normalization",
        "description": "projects.mmdet3d_plugin.dd3d.layers.normalization",
        "isExtraImport": true,
        "detail": "projects.mmdet3d_plugin.dd3d.layers.normalization",
        "documentation": {}
    },
    {
        "label": "reduce_sum",
        "importPath": "projects.mmdet3d_plugin.dd3d.utils.comm",
        "description": "projects.mmdet3d_plugin.dd3d.utils.comm",
        "isExtraImport": true,
        "detail": "projects.mmdet3d_plugin.dd3d.utils.comm",
        "documentation": {}
    },
    {
        "label": "reduce_sum",
        "importPath": "projects.mmdet3d_plugin.dd3d.utils.comm",
        "description": "projects.mmdet3d_plugin.dd3d.utils.comm",
        "isExtraImport": true,
        "detail": "projects.mmdet3d_plugin.dd3d.utils.comm",
        "documentation": {}
    },
    {
        "label": "smooth_l1_loss",
        "importPath": "fvcore.nn.smooth_l1_loss",
        "description": "fvcore.nn.smooth_l1_loss",
        "isExtraImport": true,
        "detail": "fvcore.nn.smooth_l1_loss",
        "documentation": {}
    },
    {
        "label": "comm",
        "importPath": "detectron2.utils",
        "description": "detectron2.utils",
        "isExtraImport": true,
        "detail": "detectron2.utils",
        "documentation": {}
    },
    {
        "label": "comm",
        "importPath": "detectron2.utils",
        "description": "detectron2.utils",
        "isExtraImport": true,
        "detail": "detectron2.utils",
        "documentation": {}
    },
    {
        "label": "HEADS",
        "importPath": "mmdet.models.builder",
        "description": "mmdet.models.builder",
        "isExtraImport": true,
        "detail": "mmdet.models.builder",
        "documentation": {}
    },
    {
        "label": "BACKBONES",
        "importPath": "mmdet.models.builder",
        "description": "mmdet.models.builder",
        "isExtraImport": true,
        "detail": "mmdet.models.builder",
        "documentation": {}
    },
    {
        "label": "amp",
        "importPath": "torch.cuda",
        "description": "torch.cuda",
        "isExtraImport": true,
        "detail": "torch.cuda",
        "documentation": {}
    },
    {
        "label": "projects.mmdet3d_plugin.dd3d.structures.transform3d",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "projects.mmdet3d_plugin.dd3d.structures.transform3d",
        "description": "projects.mmdet3d_plugin.dd3d.structures.transform3d",
        "detail": "projects.mmdet3d_plugin.dd3d.structures.transform3d",
        "documentation": {}
    },
    {
        "label": "division",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "division",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "division",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "TORCH_VERSION",
        "importPath": "detectron2.utils.env",
        "description": "detectron2.utils.env",
        "isExtraImport": true,
        "detail": "detectron2.utils.env",
        "documentation": {}
    },
    {
        "label": "colorsys",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "colorsys",
        "description": "colorsys",
        "detail": "colorsys",
        "documentation": {}
    },
    {
        "label": "matplotlib.colors",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "matplotlib.colors",
        "description": "matplotlib.colors",
        "detail": "matplotlib.colors",
        "documentation": {}
    },
    {
        "label": "Optimizer",
        "importPath": "torch.optim.optimizer",
        "description": "torch.optim.optimizer",
        "isExtraImport": true,
        "detail": "torch.optim.optimizer",
        "documentation": {}
    },
    {
        "label": "OPTIMIZERS",
        "importPath": "mmcv.runner.optimizer.builder",
        "description": "mmcv.runner.optimizer.builder",
        "isExtraImport": true,
        "detail": "mmcv.runner.optimizer.builder",
        "documentation": {}
    },
    {
        "label": "make_grid",
        "importPath": "torchvision.utils",
        "description": "torchvision.utils",
        "isExtraImport": true,
        "detail": "torchvision.utils",
        "documentation": {}
    },
    {
        "label": "torchvision",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torchvision",
        "description": "torchvision",
        "detail": "torchvision",
        "documentation": {}
    },
    {
        "label": "matplotlib.pyplot",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "matplotlib.pyplot",
        "description": "matplotlib.pyplot",
        "detail": "matplotlib.pyplot",
        "documentation": {}
    },
    {
        "label": "sys",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "sys",
        "description": "sys",
        "detail": "sys",
        "documentation": {}
    },
    {
        "label": "build_detector",
        "importPath": "mmdet3d.models",
        "description": "mmdet3d.models",
        "isExtraImport": true,
        "detail": "mmdet3d.models",
        "documentation": {}
    },
    {
        "label": "build_model",
        "importPath": "mmdet3d.models",
        "description": "mmdet3d.models",
        "isExtraImport": true,
        "detail": "mmdet3d.models",
        "documentation": {}
    },
    {
        "label": "build_detector",
        "importPath": "mmdet3d.models",
        "description": "mmdet3d.models",
        "isExtraImport": true,
        "detail": "mmdet3d.models",
        "documentation": {}
    },
    {
        "label": "build_model",
        "importPath": "mmdet3d.models",
        "description": "mmdet3d.models",
        "isExtraImport": true,
        "detail": "mmdet3d.models",
        "documentation": {}
    },
    {
        "label": "build_model",
        "importPath": "mmdet3d.models",
        "description": "mmdet3d.models",
        "isExtraImport": true,
        "detail": "mmdet3d.models",
        "documentation": {}
    },
    {
        "label": "Axes",
        "importPath": "matplotlib.axes",
        "description": "matplotlib.axes",
        "isExtraImport": true,
        "detail": "matplotlib.axes",
        "documentation": {}
    },
    {
        "label": "Axes",
        "importPath": "matplotlib.axes",
        "description": "matplotlib.axes",
        "isExtraImport": true,
        "detail": "matplotlib.axes",
        "documentation": {}
    },
    {
        "label": "roi_align",
        "importPath": "mmcv.ops",
        "description": "mmcv.ops",
        "isExtraImport": true,
        "detail": "mmcv.ops",
        "documentation": {}
    },
    {
        "label": "mask",
        "importPath": "pycocotools",
        "description": "pycocotools",
        "isExtraImport": true,
        "detail": "pycocotools",
        "documentation": {}
    },
    {
        "label": "COCO",
        "importPath": "pycocotools.coco",
        "description": "pycocotools.coco",
        "isExtraImport": true,
        "detail": "pycocotools.coco",
        "documentation": {}
    },
    {
        "label": "bbox_overlaps",
        "importPath": "mmdet.core.evaluation.bbox_overlaps",
        "description": "mmdet.core.evaluation.bbox_overlaps",
        "isExtraImport": true,
        "detail": "mmdet.core.evaluation.bbox_overlaps",
        "documentation": {}
    },
    {
        "label": "S3DISData",
        "importPath": "tools.data_converter.s3dis_data_utils",
        "description": "tools.data_converter.s3dis_data_utils",
        "isExtraImport": true,
        "detail": "tools.data_converter.s3dis_data_utils",
        "documentation": {}
    },
    {
        "label": "S3DISSegData",
        "importPath": "tools.data_converter.s3dis_data_utils",
        "description": "tools.data_converter.s3dis_data_utils",
        "isExtraImport": true,
        "detail": "tools.data_converter.s3dis_data_utils",
        "documentation": {}
    },
    {
        "label": "ScanNetData",
        "importPath": "tools.data_converter.scannet_data_utils",
        "description": "tools.data_converter.scannet_data_utils",
        "isExtraImport": true,
        "detail": "tools.data_converter.scannet_data_utils",
        "documentation": {}
    },
    {
        "label": "ScanNetSegData",
        "importPath": "tools.data_converter.scannet_data_utils",
        "description": "tools.data_converter.scannet_data_utils",
        "isExtraImport": true,
        "detail": "tools.data_converter.scannet_data_utils",
        "documentation": {}
    },
    {
        "label": "SUNRGBDData",
        "importPath": "tools.data_converter.sunrgbd_data_utils",
        "description": "tools.data_converter.sunrgbd_data_utils",
        "isExtraImport": true,
        "detail": "tools.data_converter.sunrgbd_data_utils",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "futures",
        "importPath": "concurrent",
        "description": "concurrent",
        "isExtraImport": true,
        "detail": "concurrent",
        "documentation": {}
    },
    {
        "label": "futures",
        "importPath": "concurrent",
        "description": "concurrent",
        "isExtraImport": true,
        "detail": "concurrent",
        "documentation": {}
    },
    {
        "label": "futures",
        "importPath": "concurrent",
        "description": "concurrent",
        "isExtraImport": true,
        "detail": "concurrent",
        "documentation": {}
    },
    {
        "label": "futures",
        "importPath": "concurrent",
        "description": "concurrent",
        "isExtraImport": true,
        "detail": "concurrent",
        "documentation": {}
    },
    {
        "label": "io",
        "importPath": "skimage",
        "description": "skimage",
        "isExtraImport": true,
        "detail": "skimage",
        "documentation": {}
    },
    {
        "label": "LyftDataset",
        "importPath": "lyft_dataset_sdk.lyftdataset",
        "description": "lyft_dataset_sdk.lyftdataset",
        "isExtraImport": true,
        "detail": "lyft_dataset_sdk.lyftdataset",
        "documentation": {}
    },
    {
        "label": "base64",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "base64",
        "description": "base64",
        "detail": "base64",
        "documentation": {}
    },
    {
        "label": "NuImages",
        "importPath": "nuimages",
        "description": "nuimages",
        "isExtraImport": true,
        "detail": "nuimages",
        "documentation": {}
    },
    {
        "label": "mask_decode",
        "importPath": "nuimages.utils.utils",
        "description": "nuimages.utils.utils",
        "isExtraImport": true,
        "detail": "nuimages.utils.utils",
        "documentation": {}
    },
    {
        "label": "name_to_index_mapping",
        "importPath": "nuimages.utils.utils",
        "description": "nuimages.utils.utils",
        "isExtraImport": true,
        "detail": "nuimages.utils.utils",
        "documentation": {}
    },
    {
        "label": "MultiPoint",
        "importPath": "shapely.geometry",
        "description": "shapely.geometry",
        "isExtraImport": true,
        "detail": "shapely.geometry",
        "documentation": {}
    },
    {
        "label": "box",
        "importPath": "shapely.geometry",
        "description": "shapely.geometry",
        "isExtraImport": true,
        "detail": "shapely.geometry",
        "documentation": {}
    },
    {
        "label": "points_cam2img",
        "importPath": "mmdet3d.core.bbox.box_np_ops",
        "description": "mmdet3d.core.bbox.box_np_ops",
        "isExtraImport": true,
        "detail": "mmdet3d.core.bbox.box_np_ops",
        "documentation": {}
    },
    {
        "label": "io",
        "importPath": "scipy",
        "description": "scipy",
        "isExtraImport": true,
        "detail": "scipy",
        "documentation": {}
    },
    {
        "label": "tensorflow",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "tensorflow",
        "description": "tensorflow",
        "detail": "tensorflow",
        "documentation": {}
    },
    {
        "label": "glob",
        "importPath": "glob",
        "description": "glob",
        "isExtraImport": true,
        "detail": "glob",
        "documentation": {}
    },
    {
        "label": "range_image_utils",
        "importPath": "waymo_open_dataset.utils",
        "description": "waymo_open_dataset.utils",
        "isExtraImport": true,
        "detail": "waymo_open_dataset.utils",
        "documentation": {}
    },
    {
        "label": "transform_utils",
        "importPath": "waymo_open_dataset.utils",
        "description": "waymo_open_dataset.utils",
        "isExtraImport": true,
        "detail": "waymo_open_dataset.utils",
        "documentation": {}
    },
    {
        "label": "\\",
        "importPath": "waymo_open_dataset.utils.frame_utils",
        "description": "waymo_open_dataset.utils.frame_utils",
        "isExtraImport": true,
        "detail": "waymo_open_dataset.utils.frame_utils",
        "documentation": {}
    },
    {
        "label": "__version__",
        "importPath": "mmdet",
        "description": "mmdet",
        "isExtraImport": true,
        "detail": "mmdet",
        "documentation": {}
    },
    {
        "label": "__version__",
        "importPath": "mmdet",
        "description": "mmdet",
        "isExtraImport": true,
        "detail": "mmdet",
        "documentation": {}
    },
    {
        "label": "collect_env",
        "importPath": "mmdet3d.utils",
        "description": "mmdet3d.utils",
        "isExtraImport": true,
        "detail": "mmdet3d.utils",
        "documentation": {}
    },
    {
        "label": "get_root_logger",
        "importPath": "mmdet3d.utils",
        "description": "mmdet3d.utils",
        "isExtraImport": true,
        "detail": "mmdet3d.utils",
        "documentation": {}
    },
    {
        "label": "collect_env",
        "importPath": "mmdet3d.utils",
        "description": "mmdet3d.utils",
        "isExtraImport": true,
        "detail": "mmdet3d.utils",
        "documentation": {}
    },
    {
        "label": "get_root_logger",
        "importPath": "mmdet3d.utils",
        "description": "mmdet3d.utils",
        "isExtraImport": true,
        "detail": "mmdet3d.utils",
        "documentation": {}
    },
    {
        "label": "__version__",
        "importPath": "mmseg",
        "description": "mmseg",
        "isExtraImport": true,
        "detail": "mmseg",
        "documentation": {}
    },
    {
        "label": "__version__",
        "importPath": "mmseg",
        "description": "mmseg",
        "isExtraImport": true,
        "detail": "mmseg",
        "documentation": {}
    },
    {
        "label": "show_multi_modality_result",
        "importPath": "mmdet3d.core.visualizer",
        "description": "mmdet3d.core.visualizer",
        "isExtraImport": true,
        "detail": "mmdet3d.core.visualizer",
        "documentation": {}
    },
    {
        "label": "show_result",
        "importPath": "mmdet3d.core.visualizer",
        "description": "mmdet3d.core.visualizer",
        "isExtraImport": true,
        "detail": "mmdet3d.core.visualizer",
        "documentation": {}
    },
    {
        "label": "show_seg_result",
        "importPath": "mmdet3d.core.visualizer",
        "description": "mmdet3d.core.visualizer",
        "isExtraImport": true,
        "detail": "mmdet3d.core.visualizer",
        "documentation": {}
    },
    {
        "label": "subprocess",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "subprocess",
        "description": "subprocess",
        "detail": "subprocess",
        "documentation": {}
    },
    {
        "label": "create_groundtruth_database",
        "importPath": "data_converter.create_gt_database",
        "description": "data_converter.create_gt_database",
        "isExtraImport": true,
        "detail": "data_converter.create_gt_database",
        "documentation": {}
    },
    {
        "label": "nuscenes_converter",
        "importPath": "data_converter",
        "description": "data_converter",
        "isExtraImport": true,
        "detail": "data_converter",
        "documentation": {}
    },
    {
        "label": "lyft_converter",
        "importPath": "data_converter",
        "description": "data_converter",
        "isExtraImport": true,
        "detail": "data_converter",
        "documentation": {}
    },
    {
        "label": "kitti_converter",
        "importPath": "data_converter",
        "description": "data_converter",
        "isExtraImport": true,
        "detail": "data_converter",
        "documentation": {}
    },
    {
        "label": "indoor_converter",
        "importPath": "data_converter",
        "description": "data_converter",
        "isExtraImport": true,
        "detail": "data_converter",
        "documentation": {}
    },
    {
        "label": "single_gpu_test",
        "importPath": "mmdet3d.apis",
        "description": "mmdet3d.apis",
        "isExtraImport": true,
        "detail": "mmdet3d.apis",
        "documentation": {}
    },
    {
        "label": "custom_multi_gpu_test",
        "importPath": "projects.mmdet3d_plugin.bevformer.apis.test",
        "description": "projects.mmdet3d_plugin.bevformer.apis.test",
        "isExtraImport": true,
        "detail": "projects.mmdet3d_plugin.bevformer.apis.test",
        "documentation": {}
    },
    {
        "label": "dataset_type",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.coco_instance",
        "description": "projects.configs._base_.datasets.coco_instance",
        "peekOfCode": "dataset_type = 'CocoDataset'\ndata_root = 'data/coco/'\nimg_norm_cfg = dict(\n    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\ntrain_pipeline = [\n    dict(type='LoadImageFromFile'),\n    dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n    dict(type='Resize', img_scale=(1333, 800), keep_ratio=True),\n    dict(type='RandomFlip', flip_ratio=0.5),\n    dict(type='Normalize', **img_norm_cfg),",
        "detail": "projects.configs._base_.datasets.coco_instance",
        "documentation": {}
    },
    {
        "label": "data_root",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.coco_instance",
        "description": "projects.configs._base_.datasets.coco_instance",
        "peekOfCode": "data_root = 'data/coco/'\nimg_norm_cfg = dict(\n    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\ntrain_pipeline = [\n    dict(type='LoadImageFromFile'),\n    dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n    dict(type='Resize', img_scale=(1333, 800), keep_ratio=True),\n    dict(type='RandomFlip', flip_ratio=0.5),\n    dict(type='Normalize', **img_norm_cfg),\n    dict(type='Pad', size_divisor=32),",
        "detail": "projects.configs._base_.datasets.coco_instance",
        "documentation": {}
    },
    {
        "label": "img_norm_cfg",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.coco_instance",
        "description": "projects.configs._base_.datasets.coco_instance",
        "peekOfCode": "img_norm_cfg = dict(\n    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\ntrain_pipeline = [\n    dict(type='LoadImageFromFile'),\n    dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n    dict(type='Resize', img_scale=(1333, 800), keep_ratio=True),\n    dict(type='RandomFlip', flip_ratio=0.5),\n    dict(type='Normalize', **img_norm_cfg),\n    dict(type='Pad', size_divisor=32),\n    dict(type='DefaultFormatBundle'),",
        "detail": "projects.configs._base_.datasets.coco_instance",
        "documentation": {}
    },
    {
        "label": "train_pipeline",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.coco_instance",
        "description": "projects.configs._base_.datasets.coco_instance",
        "peekOfCode": "train_pipeline = [\n    dict(type='LoadImageFromFile'),\n    dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n    dict(type='Resize', img_scale=(1333, 800), keep_ratio=True),\n    dict(type='RandomFlip', flip_ratio=0.5),\n    dict(type='Normalize', **img_norm_cfg),\n    dict(type='Pad', size_divisor=32),\n    dict(type='DefaultFormatBundle'),\n    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels', 'gt_masks']),\n]",
        "detail": "projects.configs._base_.datasets.coco_instance",
        "documentation": {}
    },
    {
        "label": "test_pipeline",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.coco_instance",
        "description": "projects.configs._base_.datasets.coco_instance",
        "peekOfCode": "test_pipeline = [\n    dict(type='LoadImageFromFile'),\n    dict(\n        type='MultiScaleFlipAug',\n        img_scale=(1333, 800),\n        flip=False,\n        transforms=[\n            dict(type='Resize', keep_ratio=True),\n            dict(type='RandomFlip'),\n            dict(type='Normalize', **img_norm_cfg),",
        "detail": "projects.configs._base_.datasets.coco_instance",
        "documentation": {}
    },
    {
        "label": "data",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.coco_instance",
        "description": "projects.configs._base_.datasets.coco_instance",
        "peekOfCode": "data = dict(\n    samples_per_gpu=2,\n    workers_per_gpu=2,\n    train=dict(\n        type=dataset_type,\n        ann_file=data_root + 'annotations/instances_train2017.json',\n        img_prefix=data_root + 'train2017/',\n        pipeline=train_pipeline),\n    val=dict(\n        type=dataset_type,",
        "detail": "projects.configs._base_.datasets.coco_instance",
        "documentation": {}
    },
    {
        "label": "evaluation",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.coco_instance",
        "description": "projects.configs._base_.datasets.coco_instance",
        "peekOfCode": "evaluation = dict(metric=['bbox', 'segm'])",
        "detail": "projects.configs._base_.datasets.coco_instance",
        "documentation": {}
    },
    {
        "label": "dataset_type",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.kitti-3d-3class",
        "description": "projects.configs._base_.datasets.kitti-3d-3class",
        "peekOfCode": "dataset_type = 'KittiDataset'\ndata_root = 'data/kitti/'\nclass_names = ['Pedestrian', 'Cyclist', 'Car']\npoint_cloud_range = [0, -40, -3, 70.4, 40, 1]\ninput_modality = dict(use_lidar=True, use_camera=False)\ndb_sampler = dict(\n    data_root=data_root,\n    info_path=data_root + 'kitti_dbinfos_train.pkl',\n    rate=1.0,\n    prepare=dict(",
        "detail": "projects.configs._base_.datasets.kitti-3d-3class",
        "documentation": {}
    },
    {
        "label": "data_root",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.kitti-3d-3class",
        "description": "projects.configs._base_.datasets.kitti-3d-3class",
        "peekOfCode": "data_root = 'data/kitti/'\nclass_names = ['Pedestrian', 'Cyclist', 'Car']\npoint_cloud_range = [0, -40, -3, 70.4, 40, 1]\ninput_modality = dict(use_lidar=True, use_camera=False)\ndb_sampler = dict(\n    data_root=data_root,\n    info_path=data_root + 'kitti_dbinfos_train.pkl',\n    rate=1.0,\n    prepare=dict(\n        filter_by_difficulty=[-1],",
        "detail": "projects.configs._base_.datasets.kitti-3d-3class",
        "documentation": {}
    },
    {
        "label": "class_names",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.kitti-3d-3class",
        "description": "projects.configs._base_.datasets.kitti-3d-3class",
        "peekOfCode": "class_names = ['Pedestrian', 'Cyclist', 'Car']\npoint_cloud_range = [0, -40, -3, 70.4, 40, 1]\ninput_modality = dict(use_lidar=True, use_camera=False)\ndb_sampler = dict(\n    data_root=data_root,\n    info_path=data_root + 'kitti_dbinfos_train.pkl',\n    rate=1.0,\n    prepare=dict(\n        filter_by_difficulty=[-1],\n        filter_by_min_points=dict(Car=5, Pedestrian=10, Cyclist=10)),",
        "detail": "projects.configs._base_.datasets.kitti-3d-3class",
        "documentation": {}
    },
    {
        "label": "point_cloud_range",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.kitti-3d-3class",
        "description": "projects.configs._base_.datasets.kitti-3d-3class",
        "peekOfCode": "point_cloud_range = [0, -40, -3, 70.4, 40, 1]\ninput_modality = dict(use_lidar=True, use_camera=False)\ndb_sampler = dict(\n    data_root=data_root,\n    info_path=data_root + 'kitti_dbinfos_train.pkl',\n    rate=1.0,\n    prepare=dict(\n        filter_by_difficulty=[-1],\n        filter_by_min_points=dict(Car=5, Pedestrian=10, Cyclist=10)),\n    classes=class_names,",
        "detail": "projects.configs._base_.datasets.kitti-3d-3class",
        "documentation": {}
    },
    {
        "label": "input_modality",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.kitti-3d-3class",
        "description": "projects.configs._base_.datasets.kitti-3d-3class",
        "peekOfCode": "input_modality = dict(use_lidar=True, use_camera=False)\ndb_sampler = dict(\n    data_root=data_root,\n    info_path=data_root + 'kitti_dbinfos_train.pkl',\n    rate=1.0,\n    prepare=dict(\n        filter_by_difficulty=[-1],\n        filter_by_min_points=dict(Car=5, Pedestrian=10, Cyclist=10)),\n    classes=class_names,\n    sample_groups=dict(Car=12, Pedestrian=6, Cyclist=6))",
        "detail": "projects.configs._base_.datasets.kitti-3d-3class",
        "documentation": {}
    },
    {
        "label": "db_sampler",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.kitti-3d-3class",
        "description": "projects.configs._base_.datasets.kitti-3d-3class",
        "peekOfCode": "db_sampler = dict(\n    data_root=data_root,\n    info_path=data_root + 'kitti_dbinfos_train.pkl',\n    rate=1.0,\n    prepare=dict(\n        filter_by_difficulty=[-1],\n        filter_by_min_points=dict(Car=5, Pedestrian=10, Cyclist=10)),\n    classes=class_names,\n    sample_groups=dict(Car=12, Pedestrian=6, Cyclist=6))\nfile_client_args = dict(backend='disk')",
        "detail": "projects.configs._base_.datasets.kitti-3d-3class",
        "documentation": {}
    },
    {
        "label": "file_client_args",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.kitti-3d-3class",
        "description": "projects.configs._base_.datasets.kitti-3d-3class",
        "peekOfCode": "file_client_args = dict(backend='disk')\n# Uncomment the following if use ceph or other file clients.\n# See https://mmcv.readthedocs.io/en/latest/api.html#mmcv.fileio.FileClient\n# for more details.\n# file_client_args = dict(\n#     backend='petrel', path_mapping=dict(data='s3://kitti_data/'))\ntrain_pipeline = [\n    dict(\n        type='LoadPointsFromFile',\n        coord_type='LIDAR',",
        "detail": "projects.configs._base_.datasets.kitti-3d-3class",
        "documentation": {}
    },
    {
        "label": "train_pipeline",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.kitti-3d-3class",
        "description": "projects.configs._base_.datasets.kitti-3d-3class",
        "peekOfCode": "train_pipeline = [\n    dict(\n        type='LoadPointsFromFile',\n        coord_type='LIDAR',\n        load_dim=4,\n        use_dim=4,\n        file_client_args=file_client_args),\n    dict(\n        type='LoadAnnotations3D',\n        with_bbox_3d=True,",
        "detail": "projects.configs._base_.datasets.kitti-3d-3class",
        "documentation": {}
    },
    {
        "label": "test_pipeline",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.kitti-3d-3class",
        "description": "projects.configs._base_.datasets.kitti-3d-3class",
        "peekOfCode": "test_pipeline = [\n    dict(\n        type='LoadPointsFromFile',\n        coord_type='LIDAR',\n        load_dim=4,\n        use_dim=4,\n        file_client_args=file_client_args),\n    dict(\n        type='MultiScaleFlipAug3D',\n        img_scale=(1333, 800),",
        "detail": "projects.configs._base_.datasets.kitti-3d-3class",
        "documentation": {}
    },
    {
        "label": "eval_pipeline",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.kitti-3d-3class",
        "description": "projects.configs._base_.datasets.kitti-3d-3class",
        "peekOfCode": "eval_pipeline = [\n    dict(\n        type='LoadPointsFromFile',\n        coord_type='LIDAR',\n        load_dim=4,\n        use_dim=4,\n        file_client_args=file_client_args),\n    dict(\n        type='DefaultFormatBundle3D',\n        class_names=class_names,",
        "detail": "projects.configs._base_.datasets.kitti-3d-3class",
        "documentation": {}
    },
    {
        "label": "data",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.kitti-3d-3class",
        "description": "projects.configs._base_.datasets.kitti-3d-3class",
        "peekOfCode": "data = dict(\n    samples_per_gpu=6,\n    workers_per_gpu=4,\n    train=dict(\n        type='RepeatDataset',\n        times=2,\n        dataset=dict(\n            type=dataset_type,\n            data_root=data_root,\n            ann_file=data_root + 'kitti_infos_train.pkl',",
        "detail": "projects.configs._base_.datasets.kitti-3d-3class",
        "documentation": {}
    },
    {
        "label": "evaluation",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.kitti-3d-3class",
        "description": "projects.configs._base_.datasets.kitti-3d-3class",
        "peekOfCode": "evaluation = dict(interval=1, pipeline=eval_pipeline)",
        "detail": "projects.configs._base_.datasets.kitti-3d-3class",
        "documentation": {}
    },
    {
        "label": "dataset_type",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.kitti-3d-car",
        "description": "projects.configs._base_.datasets.kitti-3d-car",
        "peekOfCode": "dataset_type = 'KittiDataset'\ndata_root = 'data/kitti/'\nclass_names = ['Car']\npoint_cloud_range = [0, -40, -3, 70.4, 40, 1]\ninput_modality = dict(use_lidar=True, use_camera=False)\ndb_sampler = dict(\n    data_root=data_root,\n    info_path=data_root + 'kitti_dbinfos_train.pkl',\n    rate=1.0,\n    prepare=dict(filter_by_difficulty=[-1], filter_by_min_points=dict(Car=5)),",
        "detail": "projects.configs._base_.datasets.kitti-3d-car",
        "documentation": {}
    },
    {
        "label": "data_root",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.kitti-3d-car",
        "description": "projects.configs._base_.datasets.kitti-3d-car",
        "peekOfCode": "data_root = 'data/kitti/'\nclass_names = ['Car']\npoint_cloud_range = [0, -40, -3, 70.4, 40, 1]\ninput_modality = dict(use_lidar=True, use_camera=False)\ndb_sampler = dict(\n    data_root=data_root,\n    info_path=data_root + 'kitti_dbinfos_train.pkl',\n    rate=1.0,\n    prepare=dict(filter_by_difficulty=[-1], filter_by_min_points=dict(Car=5)),\n    classes=class_names,",
        "detail": "projects.configs._base_.datasets.kitti-3d-car",
        "documentation": {}
    },
    {
        "label": "class_names",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.kitti-3d-car",
        "description": "projects.configs._base_.datasets.kitti-3d-car",
        "peekOfCode": "class_names = ['Car']\npoint_cloud_range = [0, -40, -3, 70.4, 40, 1]\ninput_modality = dict(use_lidar=True, use_camera=False)\ndb_sampler = dict(\n    data_root=data_root,\n    info_path=data_root + 'kitti_dbinfos_train.pkl',\n    rate=1.0,\n    prepare=dict(filter_by_difficulty=[-1], filter_by_min_points=dict(Car=5)),\n    classes=class_names,\n    sample_groups=dict(Car=15))",
        "detail": "projects.configs._base_.datasets.kitti-3d-car",
        "documentation": {}
    },
    {
        "label": "point_cloud_range",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.kitti-3d-car",
        "description": "projects.configs._base_.datasets.kitti-3d-car",
        "peekOfCode": "point_cloud_range = [0, -40, -3, 70.4, 40, 1]\ninput_modality = dict(use_lidar=True, use_camera=False)\ndb_sampler = dict(\n    data_root=data_root,\n    info_path=data_root + 'kitti_dbinfos_train.pkl',\n    rate=1.0,\n    prepare=dict(filter_by_difficulty=[-1], filter_by_min_points=dict(Car=5)),\n    classes=class_names,\n    sample_groups=dict(Car=15))\nfile_client_args = dict(backend='disk')",
        "detail": "projects.configs._base_.datasets.kitti-3d-car",
        "documentation": {}
    },
    {
        "label": "input_modality",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.kitti-3d-car",
        "description": "projects.configs._base_.datasets.kitti-3d-car",
        "peekOfCode": "input_modality = dict(use_lidar=True, use_camera=False)\ndb_sampler = dict(\n    data_root=data_root,\n    info_path=data_root + 'kitti_dbinfos_train.pkl',\n    rate=1.0,\n    prepare=dict(filter_by_difficulty=[-1], filter_by_min_points=dict(Car=5)),\n    classes=class_names,\n    sample_groups=dict(Car=15))\nfile_client_args = dict(backend='disk')\n# Uncomment the following if use ceph or other file clients.",
        "detail": "projects.configs._base_.datasets.kitti-3d-car",
        "documentation": {}
    },
    {
        "label": "db_sampler",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.kitti-3d-car",
        "description": "projects.configs._base_.datasets.kitti-3d-car",
        "peekOfCode": "db_sampler = dict(\n    data_root=data_root,\n    info_path=data_root + 'kitti_dbinfos_train.pkl',\n    rate=1.0,\n    prepare=dict(filter_by_difficulty=[-1], filter_by_min_points=dict(Car=5)),\n    classes=class_names,\n    sample_groups=dict(Car=15))\nfile_client_args = dict(backend='disk')\n# Uncomment the following if use ceph or other file clients.\n# See https://mmcv.readthedocs.io/en/latest/api.html#mmcv.fileio.FileClient",
        "detail": "projects.configs._base_.datasets.kitti-3d-car",
        "documentation": {}
    },
    {
        "label": "file_client_args",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.kitti-3d-car",
        "description": "projects.configs._base_.datasets.kitti-3d-car",
        "peekOfCode": "file_client_args = dict(backend='disk')\n# Uncomment the following if use ceph or other file clients.\n# See https://mmcv.readthedocs.io/en/latest/api.html#mmcv.fileio.FileClient\n# for more details.\n# file_client_args = dict(\n#     backend='petrel', path_mapping=dict(data='s3://kitti_data/'))\ntrain_pipeline = [\n    dict(\n        type='LoadPointsFromFile',\n        coord_type='LIDAR',",
        "detail": "projects.configs._base_.datasets.kitti-3d-car",
        "documentation": {}
    },
    {
        "label": "train_pipeline",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.kitti-3d-car",
        "description": "projects.configs._base_.datasets.kitti-3d-car",
        "peekOfCode": "train_pipeline = [\n    dict(\n        type='LoadPointsFromFile',\n        coord_type='LIDAR',\n        load_dim=4,\n        use_dim=4,\n        file_client_args=file_client_args),\n    dict(\n        type='LoadAnnotations3D',\n        with_bbox_3d=True,",
        "detail": "projects.configs._base_.datasets.kitti-3d-car",
        "documentation": {}
    },
    {
        "label": "test_pipeline",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.kitti-3d-car",
        "description": "projects.configs._base_.datasets.kitti-3d-car",
        "peekOfCode": "test_pipeline = [\n    dict(\n        type='LoadPointsFromFile',\n        coord_type='LIDAR',\n        load_dim=4,\n        use_dim=4,\n        file_client_args=file_client_args),\n    dict(\n        type='MultiScaleFlipAug3D',\n        img_scale=(1333, 800),",
        "detail": "projects.configs._base_.datasets.kitti-3d-car",
        "documentation": {}
    },
    {
        "label": "eval_pipeline",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.kitti-3d-car",
        "description": "projects.configs._base_.datasets.kitti-3d-car",
        "peekOfCode": "eval_pipeline = [\n    dict(\n        type='LoadPointsFromFile',\n        coord_type='LIDAR',\n        load_dim=4,\n        use_dim=4,\n        file_client_args=file_client_args),\n    dict(\n        type='DefaultFormatBundle3D',\n        class_names=class_names,",
        "detail": "projects.configs._base_.datasets.kitti-3d-car",
        "documentation": {}
    },
    {
        "label": "data",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.kitti-3d-car",
        "description": "projects.configs._base_.datasets.kitti-3d-car",
        "peekOfCode": "data = dict(\n    samples_per_gpu=6,\n    workers_per_gpu=4,\n    train=dict(\n        type='RepeatDataset',\n        times=2,\n        dataset=dict(\n            type=dataset_type,\n            data_root=data_root,\n            ann_file=data_root + 'kitti_infos_train.pkl',",
        "detail": "projects.configs._base_.datasets.kitti-3d-car",
        "documentation": {}
    },
    {
        "label": "evaluation",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.kitti-3d-car",
        "description": "projects.configs._base_.datasets.kitti-3d-car",
        "peekOfCode": "evaluation = dict(interval=1, pipeline=eval_pipeline)",
        "detail": "projects.configs._base_.datasets.kitti-3d-car",
        "documentation": {}
    },
    {
        "label": "point_cloud_range",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.lyft-3d",
        "description": "projects.configs._base_.datasets.lyft-3d",
        "peekOfCode": "point_cloud_range = [-80, -80, -5, 80, 80, 3]\n# For Lyft we usually do 9-class detection\nclass_names = [\n    'car', 'truck', 'bus', 'emergency_vehicle', 'other_vehicle', 'motorcycle',\n    'bicycle', 'pedestrian', 'animal'\n]\ndataset_type = 'LyftDataset'\ndata_root = 'data/lyft/'\n# Input modality for Lyft dataset, this is consistent with the submission\n# format which requires the information in input_modality.",
        "detail": "projects.configs._base_.datasets.lyft-3d",
        "documentation": {}
    },
    {
        "label": "class_names",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.lyft-3d",
        "description": "projects.configs._base_.datasets.lyft-3d",
        "peekOfCode": "class_names = [\n    'car', 'truck', 'bus', 'emergency_vehicle', 'other_vehicle', 'motorcycle',\n    'bicycle', 'pedestrian', 'animal'\n]\ndataset_type = 'LyftDataset'\ndata_root = 'data/lyft/'\n# Input modality for Lyft dataset, this is consistent with the submission\n# format which requires the information in input_modality.\ninput_modality = dict(\n    use_lidar=True,",
        "detail": "projects.configs._base_.datasets.lyft-3d",
        "documentation": {}
    },
    {
        "label": "dataset_type",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.lyft-3d",
        "description": "projects.configs._base_.datasets.lyft-3d",
        "peekOfCode": "dataset_type = 'LyftDataset'\ndata_root = 'data/lyft/'\n# Input modality for Lyft dataset, this is consistent with the submission\n# format which requires the information in input_modality.\ninput_modality = dict(\n    use_lidar=True,\n    use_camera=False,\n    use_radar=False,\n    use_map=False,\n    use_external=False)",
        "detail": "projects.configs._base_.datasets.lyft-3d",
        "documentation": {}
    },
    {
        "label": "data_root",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.lyft-3d",
        "description": "projects.configs._base_.datasets.lyft-3d",
        "peekOfCode": "data_root = 'data/lyft/'\n# Input modality for Lyft dataset, this is consistent with the submission\n# format which requires the information in input_modality.\ninput_modality = dict(\n    use_lidar=True,\n    use_camera=False,\n    use_radar=False,\n    use_map=False,\n    use_external=False)\nfile_client_args = dict(backend='disk')",
        "detail": "projects.configs._base_.datasets.lyft-3d",
        "documentation": {}
    },
    {
        "label": "input_modality",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.lyft-3d",
        "description": "projects.configs._base_.datasets.lyft-3d",
        "peekOfCode": "input_modality = dict(\n    use_lidar=True,\n    use_camera=False,\n    use_radar=False,\n    use_map=False,\n    use_external=False)\nfile_client_args = dict(backend='disk')\n# Uncomment the following if use ceph or other file clients.\n# See https://mmcv.readthedocs.io/en/latest/api.html#mmcv.fileio.FileClient\n# for more details.",
        "detail": "projects.configs._base_.datasets.lyft-3d",
        "documentation": {}
    },
    {
        "label": "file_client_args",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.lyft-3d",
        "description": "projects.configs._base_.datasets.lyft-3d",
        "peekOfCode": "file_client_args = dict(backend='disk')\n# Uncomment the following if use ceph or other file clients.\n# See https://mmcv.readthedocs.io/en/latest/api.html#mmcv.fileio.FileClient\n# for more details.\n# file_client_args = dict(\n#     backend='petrel',\n#     path_mapping=dict({\n#         './data/lyft/': 's3://lyft/lyft/',\n#         'data/lyft/': 's3://lyft/lyft/'\n#    }))",
        "detail": "projects.configs._base_.datasets.lyft-3d",
        "documentation": {}
    },
    {
        "label": "train_pipeline",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.lyft-3d",
        "description": "projects.configs._base_.datasets.lyft-3d",
        "peekOfCode": "train_pipeline = [\n    dict(\n        type='LoadPointsFromFile',\n        coord_type='LIDAR',\n        load_dim=5,\n        use_dim=5,\n        file_client_args=file_client_args),\n    dict(\n        type='LoadPointsFromMultiSweeps',\n        sweeps_num=10,",
        "detail": "projects.configs._base_.datasets.lyft-3d",
        "documentation": {}
    },
    {
        "label": "test_pipeline",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.lyft-3d",
        "description": "projects.configs._base_.datasets.lyft-3d",
        "peekOfCode": "test_pipeline = [\n    dict(\n        type='LoadPointsFromFile',\n        coord_type='LIDAR',\n        load_dim=5,\n        use_dim=5,\n        file_client_args=file_client_args),\n    dict(\n        type='LoadPointsFromMultiSweeps',\n        sweeps_num=10,",
        "detail": "projects.configs._base_.datasets.lyft-3d",
        "documentation": {}
    },
    {
        "label": "eval_pipeline",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.lyft-3d",
        "description": "projects.configs._base_.datasets.lyft-3d",
        "peekOfCode": "eval_pipeline = [\n    dict(\n        type='LoadPointsFromFile',\n        coord_type='LIDAR',\n        load_dim=5,\n        use_dim=5,\n        file_client_args=file_client_args),\n    dict(\n        type='LoadPointsFromMultiSweeps',\n        sweeps_num=10,",
        "detail": "projects.configs._base_.datasets.lyft-3d",
        "documentation": {}
    },
    {
        "label": "data",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.lyft-3d",
        "description": "projects.configs._base_.datasets.lyft-3d",
        "peekOfCode": "data = dict(\n    samples_per_gpu=2,\n    workers_per_gpu=2,\n    train=dict(\n        type=dataset_type,\n        data_root=data_root,\n        ann_file=data_root + 'lyft_infos_train.pkl',\n        pipeline=train_pipeline,\n        classes=class_names,\n        modality=input_modality,",
        "detail": "projects.configs._base_.datasets.lyft-3d",
        "documentation": {}
    },
    {
        "label": "evaluation",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.lyft-3d",
        "description": "projects.configs._base_.datasets.lyft-3d",
        "peekOfCode": "evaluation = dict(interval=24, pipeline=eval_pipeline)",
        "detail": "projects.configs._base_.datasets.lyft-3d",
        "documentation": {}
    },
    {
        "label": "dataset_type",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.nuim_instance",
        "description": "projects.configs._base_.datasets.nuim_instance",
        "peekOfCode": "dataset_type = 'CocoDataset'\ndata_root = 'data/nuimages/'\nclass_names = [\n    'car', 'truck', 'trailer', 'bus', 'construction_vehicle', 'bicycle',\n    'motorcycle', 'pedestrian', 'traffic_cone', 'barrier'\n]\nimg_norm_cfg = dict(\n    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\ntrain_pipeline = [\n    dict(type='LoadImageFromFile'),",
        "detail": "projects.configs._base_.datasets.nuim_instance",
        "documentation": {}
    },
    {
        "label": "data_root",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.nuim_instance",
        "description": "projects.configs._base_.datasets.nuim_instance",
        "peekOfCode": "data_root = 'data/nuimages/'\nclass_names = [\n    'car', 'truck', 'trailer', 'bus', 'construction_vehicle', 'bicycle',\n    'motorcycle', 'pedestrian', 'traffic_cone', 'barrier'\n]\nimg_norm_cfg = dict(\n    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\ntrain_pipeline = [\n    dict(type='LoadImageFromFile'),\n    dict(type='LoadAnnotations', with_bbox=True, with_mask=True),",
        "detail": "projects.configs._base_.datasets.nuim_instance",
        "documentation": {}
    },
    {
        "label": "class_names",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.nuim_instance",
        "description": "projects.configs._base_.datasets.nuim_instance",
        "peekOfCode": "class_names = [\n    'car', 'truck', 'trailer', 'bus', 'construction_vehicle', 'bicycle',\n    'motorcycle', 'pedestrian', 'traffic_cone', 'barrier'\n]\nimg_norm_cfg = dict(\n    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\ntrain_pipeline = [\n    dict(type='LoadImageFromFile'),\n    dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n    dict(",
        "detail": "projects.configs._base_.datasets.nuim_instance",
        "documentation": {}
    },
    {
        "label": "img_norm_cfg",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.nuim_instance",
        "description": "projects.configs._base_.datasets.nuim_instance",
        "peekOfCode": "img_norm_cfg = dict(\n    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\ntrain_pipeline = [\n    dict(type='LoadImageFromFile'),\n    dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n    dict(\n        type='Resize',\n        img_scale=[(1280, 720), (1920, 1080)],\n        multiscale_mode='range',\n        keep_ratio=True),",
        "detail": "projects.configs._base_.datasets.nuim_instance",
        "documentation": {}
    },
    {
        "label": "train_pipeline",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.nuim_instance",
        "description": "projects.configs._base_.datasets.nuim_instance",
        "peekOfCode": "train_pipeline = [\n    dict(type='LoadImageFromFile'),\n    dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n    dict(\n        type='Resize',\n        img_scale=[(1280, 720), (1920, 1080)],\n        multiscale_mode='range',\n        keep_ratio=True),\n    dict(type='RandomFlip', flip_ratio=0.5),\n    dict(type='Normalize', **img_norm_cfg),",
        "detail": "projects.configs._base_.datasets.nuim_instance",
        "documentation": {}
    },
    {
        "label": "test_pipeline",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.nuim_instance",
        "description": "projects.configs._base_.datasets.nuim_instance",
        "peekOfCode": "test_pipeline = [\n    dict(type='LoadImageFromFile'),\n    dict(\n        type='MultiScaleFlipAug',\n        img_scale=(1600, 900),\n        flip=False,\n        transforms=[\n            dict(type='Resize', keep_ratio=True),\n            dict(type='RandomFlip'),\n            dict(type='Normalize', **img_norm_cfg),",
        "detail": "projects.configs._base_.datasets.nuim_instance",
        "documentation": {}
    },
    {
        "label": "data",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.nuim_instance",
        "description": "projects.configs._base_.datasets.nuim_instance",
        "peekOfCode": "data = dict(\n    samples_per_gpu=2,\n    workers_per_gpu=2,\n    train=dict(\n        type=dataset_type,\n        ann_file=data_root + 'annotations/nuimages_v1.0-train.json',\n        img_prefix=data_root,\n        classes=class_names,\n        pipeline=train_pipeline),\n    val=dict(",
        "detail": "projects.configs._base_.datasets.nuim_instance",
        "documentation": {}
    },
    {
        "label": "evaluation",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.nuim_instance",
        "description": "projects.configs._base_.datasets.nuim_instance",
        "peekOfCode": "evaluation = dict(metric=['bbox', 'segm'])",
        "detail": "projects.configs._base_.datasets.nuim_instance",
        "documentation": {}
    },
    {
        "label": "point_cloud_range",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.nus-3d",
        "description": "projects.configs._base_.datasets.nus-3d",
        "peekOfCode": "point_cloud_range = [-50, -50, -5, 50, 50, 3]\n# For nuScenes we usually do 10-class detection\nclass_names = [\n    'car', 'truck', 'trailer', 'bus', 'construction_vehicle', 'bicycle',\n    'motorcycle', 'pedestrian', 'traffic_cone', 'barrier'\n]\ndataset_type = 'NuScenesDataset'\ndata_root = '/data/nuscenes/'\n# Input modality for nuScenes dataset, this is consistent with the submission\n# format which requires the information in input_modality.",
        "detail": "projects.configs._base_.datasets.nus-3d",
        "documentation": {}
    },
    {
        "label": "class_names",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.nus-3d",
        "description": "projects.configs._base_.datasets.nus-3d",
        "peekOfCode": "class_names = [\n    'car', 'truck', 'trailer', 'bus', 'construction_vehicle', 'bicycle',\n    'motorcycle', 'pedestrian', 'traffic_cone', 'barrier'\n]\ndataset_type = 'NuScenesDataset'\ndata_root = '/data/nuscenes/'\n# Input modality for nuScenes dataset, this is consistent with the submission\n# format which requires the information in input_modality.\ninput_modality = dict(\n    use_lidar=True,",
        "detail": "projects.configs._base_.datasets.nus-3d",
        "documentation": {}
    },
    {
        "label": "dataset_type",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.nus-3d",
        "description": "projects.configs._base_.datasets.nus-3d",
        "peekOfCode": "dataset_type = 'NuScenesDataset'\ndata_root = '/data/nuscenes/'\n# Input modality for nuScenes dataset, this is consistent with the submission\n# format which requires the information in input_modality.\ninput_modality = dict(\n    use_lidar=True,\n    use_camera=False,\n    use_radar=False,\n    use_map=False,\n    use_external=False)",
        "detail": "projects.configs._base_.datasets.nus-3d",
        "documentation": {}
    },
    {
        "label": "data_root",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.nus-3d",
        "description": "projects.configs._base_.datasets.nus-3d",
        "peekOfCode": "data_root = '/data/nuscenes/'\n# Input modality for nuScenes dataset, this is consistent with the submission\n# format which requires the information in input_modality.\ninput_modality = dict(\n    use_lidar=True,\n    use_camera=False,\n    use_radar=False,\n    use_map=False,\n    use_external=False)\nfile_client_args = dict(backend='disk')",
        "detail": "projects.configs._base_.datasets.nus-3d",
        "documentation": {}
    },
    {
        "label": "input_modality",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.nus-3d",
        "description": "projects.configs._base_.datasets.nus-3d",
        "peekOfCode": "input_modality = dict(\n    use_lidar=True,\n    use_camera=False,\n    use_radar=False,\n    use_map=False,\n    use_external=False)\nfile_client_args = dict(backend='disk')\n# Uncomment the following if use ceph or other file clients.\n# See https://mmcv.readthedocs.io/en/latest/api.html#mmcv.fileio.FileClient\n# for more details.",
        "detail": "projects.configs._base_.datasets.nus-3d",
        "documentation": {}
    },
    {
        "label": "file_client_args",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.nus-3d",
        "description": "projects.configs._base_.datasets.nus-3d",
        "peekOfCode": "file_client_args = dict(backend='disk')\n# Uncomment the following if use ceph or other file clients.\n# See https://mmcv.readthedocs.io/en/latest/api.html#mmcv.fileio.FileClient\n# for more details.\n# file_client_args = dict(\n#     backend='petrel',\n#     path_mapping=dict({\n#         './data/nuscenes/': 's3://nuscenes/nuscenes/',\n#         'data/nuscenes/': 's3://nuscenes/nuscenes/'\n#     }))",
        "detail": "projects.configs._base_.datasets.nus-3d",
        "documentation": {}
    },
    {
        "label": "train_pipeline",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.nus-3d",
        "description": "projects.configs._base_.datasets.nus-3d",
        "peekOfCode": "train_pipeline = [\n    dict(\n        type='LoadPointsFromFile',\n        coord_type='LIDAR',\n        load_dim=5,\n        use_dim=5,\n        file_client_args=file_client_args),\n    dict(\n        type='LoadPointsFromMultiSweeps',\n        sweeps_num=10,",
        "detail": "projects.configs._base_.datasets.nus-3d",
        "documentation": {}
    },
    {
        "label": "test_pipeline",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.nus-3d",
        "description": "projects.configs._base_.datasets.nus-3d",
        "peekOfCode": "test_pipeline = [\n    dict(\n        type='LoadPointsFromFile',\n        coord_type='LIDAR',\n        load_dim=5,\n        use_dim=5,\n        file_client_args=file_client_args),\n    dict(\n        type='LoadPointsFromMultiSweeps',\n        sweeps_num=10,",
        "detail": "projects.configs._base_.datasets.nus-3d",
        "documentation": {}
    },
    {
        "label": "eval_pipeline",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.nus-3d",
        "description": "projects.configs._base_.datasets.nus-3d",
        "peekOfCode": "eval_pipeline = [\n    dict(\n        type='LoadPointsFromFile',\n        coord_type='LIDAR',\n        load_dim=5,\n        use_dim=5,\n        file_client_args=file_client_args),\n    dict(\n        type='LoadPointsFromMultiSweeps',\n        sweeps_num=10,",
        "detail": "projects.configs._base_.datasets.nus-3d",
        "documentation": {}
    },
    {
        "label": "data",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.nus-3d",
        "description": "projects.configs._base_.datasets.nus-3d",
        "peekOfCode": "data = dict(\n    samples_per_gpu=1,\n    workers_per_gpu=2,\n    train=dict(\n        type=dataset_type,\n        data_root=data_root,\n        ann_file=data_root + 'nuscenes_infos_train.pkl',\n        pipeline=train_pipeline,\n        classes=class_names,\n        modality=input_modality,",
        "detail": "projects.configs._base_.datasets.nus-3d",
        "documentation": {}
    },
    {
        "label": "evaluation",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.nus-3d",
        "description": "projects.configs._base_.datasets.nus-3d",
        "peekOfCode": "evaluation = dict(interval=24, pipeline=eval_pipeline)",
        "detail": "projects.configs._base_.datasets.nus-3d",
        "documentation": {}
    },
    {
        "label": "dataset_type",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.nus-mono3d",
        "description": "projects.configs._base_.datasets.nus-mono3d",
        "peekOfCode": "dataset_type = 'CustomNuScenesMonoDataset'\ndata_root = 'data/nuscenes/'\nclass_names = [\n    'car', 'truck', 'trailer', 'bus', 'construction_vehicle', 'bicycle',\n    'motorcycle', 'pedestrian', 'traffic_cone', 'barrier'\n]\n# Input modality for nuScenes dataset, this is consistent with the submission\n# format which requires the information in input_modality.\ninput_modality = dict(\n    use_lidar=False,",
        "detail": "projects.configs._base_.datasets.nus-mono3d",
        "documentation": {}
    },
    {
        "label": "data_root",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.nus-mono3d",
        "description": "projects.configs._base_.datasets.nus-mono3d",
        "peekOfCode": "data_root = 'data/nuscenes/'\nclass_names = [\n    'car', 'truck', 'trailer', 'bus', 'construction_vehicle', 'bicycle',\n    'motorcycle', 'pedestrian', 'traffic_cone', 'barrier'\n]\n# Input modality for nuScenes dataset, this is consistent with the submission\n# format which requires the information in input_modality.\ninput_modality = dict(\n    use_lidar=False,\n    use_camera=True,",
        "detail": "projects.configs._base_.datasets.nus-mono3d",
        "documentation": {}
    },
    {
        "label": "class_names",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.nus-mono3d",
        "description": "projects.configs._base_.datasets.nus-mono3d",
        "peekOfCode": "class_names = [\n    'car', 'truck', 'trailer', 'bus', 'construction_vehicle', 'bicycle',\n    'motorcycle', 'pedestrian', 'traffic_cone', 'barrier'\n]\n# Input modality for nuScenes dataset, this is consistent with the submission\n# format which requires the information in input_modality.\ninput_modality = dict(\n    use_lidar=False,\n    use_camera=True,\n    use_radar=False,",
        "detail": "projects.configs._base_.datasets.nus-mono3d",
        "documentation": {}
    },
    {
        "label": "input_modality",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.nus-mono3d",
        "description": "projects.configs._base_.datasets.nus-mono3d",
        "peekOfCode": "input_modality = dict(\n    use_lidar=False,\n    use_camera=True,\n    use_radar=False,\n    use_map=False,\n    use_external=False)\nimg_norm_cfg = dict(\n    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\ntrain_pipeline = [\n    dict(type='LoadImageFromFileMono3D'),",
        "detail": "projects.configs._base_.datasets.nus-mono3d",
        "documentation": {}
    },
    {
        "label": "img_norm_cfg",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.nus-mono3d",
        "description": "projects.configs._base_.datasets.nus-mono3d",
        "peekOfCode": "img_norm_cfg = dict(\n    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\ntrain_pipeline = [\n    dict(type='LoadImageFromFileMono3D'),\n    dict(\n        type='LoadAnnotations3D',\n        with_bbox=True,\n        with_label=True,\n        with_attr_label=True,\n        with_bbox_3d=True,",
        "detail": "projects.configs._base_.datasets.nus-mono3d",
        "documentation": {}
    },
    {
        "label": "train_pipeline",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.nus-mono3d",
        "description": "projects.configs._base_.datasets.nus-mono3d",
        "peekOfCode": "train_pipeline = [\n    dict(type='LoadImageFromFileMono3D'),\n    dict(\n        type='LoadAnnotations3D',\n        with_bbox=True,\n        with_label=True,\n        with_attr_label=True,\n        with_bbox_3d=True,\n        with_label_3d=True,\n        with_bbox_depth=True),",
        "detail": "projects.configs._base_.datasets.nus-mono3d",
        "documentation": {}
    },
    {
        "label": "test_pipeline",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.nus-mono3d",
        "description": "projects.configs._base_.datasets.nus-mono3d",
        "peekOfCode": "test_pipeline = [\n    dict(type='LoadImageFromFileMono3D'),\n    dict(\n        type='MultiScaleFlipAug',\n        scale_factor=1.0,\n        flip=False,\n        transforms=[\n            dict(type='RandomFlip3D'),\n            dict(type='Normalize', **img_norm_cfg),\n            dict(type='Pad', size_divisor=32),",
        "detail": "projects.configs._base_.datasets.nus-mono3d",
        "documentation": {}
    },
    {
        "label": "eval_pipeline",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.nus-mono3d",
        "description": "projects.configs._base_.datasets.nus-mono3d",
        "peekOfCode": "eval_pipeline = [\n    dict(type='LoadImageFromFileMono3D'),\n    dict(\n        type='DefaultFormatBundle3D',\n        class_names=class_names,\n        with_label=False),\n    dict(type='Collect3D', keys=['img'])\n]\ndata = dict(\n    samples_per_gpu=2,",
        "detail": "projects.configs._base_.datasets.nus-mono3d",
        "documentation": {}
    },
    {
        "label": "data",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.nus-mono3d",
        "description": "projects.configs._base_.datasets.nus-mono3d",
        "peekOfCode": "data = dict(\n    samples_per_gpu=2,\n    workers_per_gpu=2,\n    train=dict(\n        type=dataset_type,\n        data_root=data_root,\n        ann_file=data_root + 'nuscenes_infos_train_mono3d.coco.json',\n        img_prefix=data_root,\n        classes=class_names,\n        pipeline=train_pipeline,",
        "detail": "projects.configs._base_.datasets.nus-mono3d",
        "documentation": {}
    },
    {
        "label": "evaluation",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.nus-mono3d",
        "description": "projects.configs._base_.datasets.nus-mono3d",
        "peekOfCode": "evaluation = dict(interval=2)",
        "detail": "projects.configs._base_.datasets.nus-mono3d",
        "documentation": {}
    },
    {
        "label": "point_cloud_range",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.range100_lyft-3d",
        "description": "projects.configs._base_.datasets.range100_lyft-3d",
        "peekOfCode": "point_cloud_range = [-100, -100, -5, 100, 100, 3]\n# For Lyft we usually do 9-class detection\nclass_names = [\n    'car', 'truck', 'bus', 'emergency_vehicle', 'other_vehicle', 'motorcycle',\n    'bicycle', 'pedestrian', 'animal'\n]\ndataset_type = 'LyftDataset'\ndata_root = 'data/lyft/'\n# Input modality for Lyft dataset, this is consistent with the submission\n# format which requires the information in input_modality.",
        "detail": "projects.configs._base_.datasets.range100_lyft-3d",
        "documentation": {}
    },
    {
        "label": "class_names",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.range100_lyft-3d",
        "description": "projects.configs._base_.datasets.range100_lyft-3d",
        "peekOfCode": "class_names = [\n    'car', 'truck', 'bus', 'emergency_vehicle', 'other_vehicle', 'motorcycle',\n    'bicycle', 'pedestrian', 'animal'\n]\ndataset_type = 'LyftDataset'\ndata_root = 'data/lyft/'\n# Input modality for Lyft dataset, this is consistent with the submission\n# format which requires the information in input_modality.\ninput_modality = dict(\n    use_lidar=True,",
        "detail": "projects.configs._base_.datasets.range100_lyft-3d",
        "documentation": {}
    },
    {
        "label": "dataset_type",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.range100_lyft-3d",
        "description": "projects.configs._base_.datasets.range100_lyft-3d",
        "peekOfCode": "dataset_type = 'LyftDataset'\ndata_root = 'data/lyft/'\n# Input modality for Lyft dataset, this is consistent with the submission\n# format which requires the information in input_modality.\ninput_modality = dict(\n    use_lidar=True,\n    use_camera=False,\n    use_radar=False,\n    use_map=False,\n    use_external=False)",
        "detail": "projects.configs._base_.datasets.range100_lyft-3d",
        "documentation": {}
    },
    {
        "label": "data_root",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.range100_lyft-3d",
        "description": "projects.configs._base_.datasets.range100_lyft-3d",
        "peekOfCode": "data_root = 'data/lyft/'\n# Input modality for Lyft dataset, this is consistent with the submission\n# format which requires the information in input_modality.\ninput_modality = dict(\n    use_lidar=True,\n    use_camera=False,\n    use_radar=False,\n    use_map=False,\n    use_external=False)\nfile_client_args = dict(backend='disk')",
        "detail": "projects.configs._base_.datasets.range100_lyft-3d",
        "documentation": {}
    },
    {
        "label": "input_modality",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.range100_lyft-3d",
        "description": "projects.configs._base_.datasets.range100_lyft-3d",
        "peekOfCode": "input_modality = dict(\n    use_lidar=True,\n    use_camera=False,\n    use_radar=False,\n    use_map=False,\n    use_external=False)\nfile_client_args = dict(backend='disk')\n# Uncomment the following if use ceph or other file clients.\n# See https://mmcv.readthedocs.io/en/latest/api.html#mmcv.fileio.FileClient\n# for more details.",
        "detail": "projects.configs._base_.datasets.range100_lyft-3d",
        "documentation": {}
    },
    {
        "label": "file_client_args",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.range100_lyft-3d",
        "description": "projects.configs._base_.datasets.range100_lyft-3d",
        "peekOfCode": "file_client_args = dict(backend='disk')\n# Uncomment the following if use ceph or other file clients.\n# See https://mmcv.readthedocs.io/en/latest/api.html#mmcv.fileio.FileClient\n# for more details.\n# file_client_args = dict(\n#     backend='petrel',\n#     path_mapping=dict({\n#         './data/lyft/': 's3://lyft/lyft/',\n#         'data/lyft/': 's3://lyft/lyft/'\n#    }))",
        "detail": "projects.configs._base_.datasets.range100_lyft-3d",
        "documentation": {}
    },
    {
        "label": "train_pipeline",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.range100_lyft-3d",
        "description": "projects.configs._base_.datasets.range100_lyft-3d",
        "peekOfCode": "train_pipeline = [\n    dict(\n        type='LoadPointsFromFile',\n        coord_type='LIDAR',\n        load_dim=5,\n        use_dim=5,\n        file_client_args=file_client_args),\n    dict(\n        type='LoadPointsFromMultiSweeps',\n        sweeps_num=10,",
        "detail": "projects.configs._base_.datasets.range100_lyft-3d",
        "documentation": {}
    },
    {
        "label": "test_pipeline",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.range100_lyft-3d",
        "description": "projects.configs._base_.datasets.range100_lyft-3d",
        "peekOfCode": "test_pipeline = [\n    dict(\n        type='LoadPointsFromFile',\n        coord_type='LIDAR',\n        load_dim=5,\n        use_dim=5,\n        file_client_args=file_client_args),\n    dict(\n        type='LoadPointsFromMultiSweeps',\n        sweeps_num=10,",
        "detail": "projects.configs._base_.datasets.range100_lyft-3d",
        "documentation": {}
    },
    {
        "label": "eval_pipeline",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.range100_lyft-3d",
        "description": "projects.configs._base_.datasets.range100_lyft-3d",
        "peekOfCode": "eval_pipeline = [\n    dict(\n        type='LoadPointsFromFile',\n        coord_type='LIDAR',\n        load_dim=5,\n        use_dim=5,\n        file_client_args=file_client_args),\n    dict(\n        type='LoadPointsFromMultiSweeps',\n        sweeps_num=10,",
        "detail": "projects.configs._base_.datasets.range100_lyft-3d",
        "documentation": {}
    },
    {
        "label": "data",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.range100_lyft-3d",
        "description": "projects.configs._base_.datasets.range100_lyft-3d",
        "peekOfCode": "data = dict(\n    samples_per_gpu=2,\n    workers_per_gpu=2,\n    train=dict(\n        type=dataset_type,\n        data_root=data_root,\n        ann_file=data_root + 'lyft_infos_train.pkl',\n        pipeline=train_pipeline,\n        classes=class_names,\n        modality=input_modality,",
        "detail": "projects.configs._base_.datasets.range100_lyft-3d",
        "documentation": {}
    },
    {
        "label": "evaluation",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.range100_lyft-3d",
        "description": "projects.configs._base_.datasets.range100_lyft-3d",
        "peekOfCode": "evaluation = dict(interval=24, pipeline=eval_pipeline)",
        "detail": "projects.configs._base_.datasets.range100_lyft-3d",
        "documentation": {}
    },
    {
        "label": "dataset_type",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.s3dis-3d-5class",
        "description": "projects.configs._base_.datasets.s3dis-3d-5class",
        "peekOfCode": "dataset_type = 'S3DISDataset'\ndata_root = './data/s3dis/'\nclass_names = ('table', 'chair', 'sofa', 'bookcase', 'board')\ntrain_area = [1, 2, 3, 4, 6]\ntest_area = 5\ntrain_pipeline = [\n    dict(\n        type='LoadPointsFromFile',\n        coord_type='DEPTH',\n        shift_height=True,",
        "detail": "projects.configs._base_.datasets.s3dis-3d-5class",
        "documentation": {}
    },
    {
        "label": "data_root",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.s3dis-3d-5class",
        "description": "projects.configs._base_.datasets.s3dis-3d-5class",
        "peekOfCode": "data_root = './data/s3dis/'\nclass_names = ('table', 'chair', 'sofa', 'bookcase', 'board')\ntrain_area = [1, 2, 3, 4, 6]\ntest_area = 5\ntrain_pipeline = [\n    dict(\n        type='LoadPointsFromFile',\n        coord_type='DEPTH',\n        shift_height=True,\n        load_dim=6,",
        "detail": "projects.configs._base_.datasets.s3dis-3d-5class",
        "documentation": {}
    },
    {
        "label": "class_names",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.s3dis-3d-5class",
        "description": "projects.configs._base_.datasets.s3dis-3d-5class",
        "peekOfCode": "class_names = ('table', 'chair', 'sofa', 'bookcase', 'board')\ntrain_area = [1, 2, 3, 4, 6]\ntest_area = 5\ntrain_pipeline = [\n    dict(\n        type='LoadPointsFromFile',\n        coord_type='DEPTH',\n        shift_height=True,\n        load_dim=6,\n        use_dim=[0, 1, 2, 3, 4, 5]),",
        "detail": "projects.configs._base_.datasets.s3dis-3d-5class",
        "documentation": {}
    },
    {
        "label": "train_area",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.s3dis-3d-5class",
        "description": "projects.configs._base_.datasets.s3dis-3d-5class",
        "peekOfCode": "train_area = [1, 2, 3, 4, 6]\ntest_area = 5\ntrain_pipeline = [\n    dict(\n        type='LoadPointsFromFile',\n        coord_type='DEPTH',\n        shift_height=True,\n        load_dim=6,\n        use_dim=[0, 1, 2, 3, 4, 5]),\n    dict(type='LoadAnnotations3D', with_bbox_3d=True, with_label_3d=True),",
        "detail": "projects.configs._base_.datasets.s3dis-3d-5class",
        "documentation": {}
    },
    {
        "label": "test_area",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.s3dis-3d-5class",
        "description": "projects.configs._base_.datasets.s3dis-3d-5class",
        "peekOfCode": "test_area = 5\ntrain_pipeline = [\n    dict(\n        type='LoadPointsFromFile',\n        coord_type='DEPTH',\n        shift_height=True,\n        load_dim=6,\n        use_dim=[0, 1, 2, 3, 4, 5]),\n    dict(type='LoadAnnotations3D', with_bbox_3d=True, with_label_3d=True),\n    dict(type='PointSample', num_points=40000),",
        "detail": "projects.configs._base_.datasets.s3dis-3d-5class",
        "documentation": {}
    },
    {
        "label": "train_pipeline",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.s3dis-3d-5class",
        "description": "projects.configs._base_.datasets.s3dis-3d-5class",
        "peekOfCode": "train_pipeline = [\n    dict(\n        type='LoadPointsFromFile',\n        coord_type='DEPTH',\n        shift_height=True,\n        load_dim=6,\n        use_dim=[0, 1, 2, 3, 4, 5]),\n    dict(type='LoadAnnotations3D', with_bbox_3d=True, with_label_3d=True),\n    dict(type='PointSample', num_points=40000),\n    dict(",
        "detail": "projects.configs._base_.datasets.s3dis-3d-5class",
        "documentation": {}
    },
    {
        "label": "test_pipeline",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.s3dis-3d-5class",
        "description": "projects.configs._base_.datasets.s3dis-3d-5class",
        "peekOfCode": "test_pipeline = [\n    dict(\n        type='LoadPointsFromFile',\n        coord_type='DEPTH',\n        shift_height=True,\n        load_dim=6,\n        use_dim=[0, 1, 2, 3, 4, 5]),\n    dict(\n        type='MultiScaleFlipAug3D',\n        img_scale=(1333, 800),",
        "detail": "projects.configs._base_.datasets.s3dis-3d-5class",
        "documentation": {}
    },
    {
        "label": "eval_pipeline",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.s3dis-3d-5class",
        "description": "projects.configs._base_.datasets.s3dis-3d-5class",
        "peekOfCode": "eval_pipeline = [\n    dict(\n        type='LoadPointsFromFile',\n        coord_type='DEPTH',\n        shift_height=False,\n        load_dim=6,\n        use_dim=[0, 1, 2, 3, 4, 5]),\n    dict(\n        type='DefaultFormatBundle3D',\n        class_names=class_names,",
        "detail": "projects.configs._base_.datasets.s3dis-3d-5class",
        "documentation": {}
    },
    {
        "label": "data",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.s3dis-3d-5class",
        "description": "projects.configs._base_.datasets.s3dis-3d-5class",
        "peekOfCode": "data = dict(\n    samples_per_gpu=8,\n    workers_per_gpu=4,\n    train=dict(\n        type='RepeatDataset',\n        times=5,\n        dataset=dict(\n            type='ConcatDataset',\n            datasets=[\n                dict(",
        "detail": "projects.configs._base_.datasets.s3dis-3d-5class",
        "documentation": {}
    },
    {
        "label": "evaluation",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.s3dis-3d-5class",
        "description": "projects.configs._base_.datasets.s3dis-3d-5class",
        "peekOfCode": "evaluation = dict(pipeline=eval_pipeline)",
        "detail": "projects.configs._base_.datasets.s3dis-3d-5class",
        "documentation": {}
    },
    {
        "label": "dataset_type",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.s3dis_seg-3d-13class",
        "description": "projects.configs._base_.datasets.s3dis_seg-3d-13class",
        "peekOfCode": "dataset_type = 'S3DISSegDataset'\ndata_root = './data/s3dis/'\nclass_names = ('ceiling', 'floor', 'wall', 'beam', 'column', 'window', 'door',\n               'table', 'chair', 'sofa', 'bookcase', 'board', 'clutter')\nnum_points = 4096\ntrain_area = [1, 2, 3, 4, 6]\ntest_area = 5\ntrain_pipeline = [\n    dict(\n        type='LoadPointsFromFile',",
        "detail": "projects.configs._base_.datasets.s3dis_seg-3d-13class",
        "documentation": {}
    },
    {
        "label": "data_root",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.s3dis_seg-3d-13class",
        "description": "projects.configs._base_.datasets.s3dis_seg-3d-13class",
        "peekOfCode": "data_root = './data/s3dis/'\nclass_names = ('ceiling', 'floor', 'wall', 'beam', 'column', 'window', 'door',\n               'table', 'chair', 'sofa', 'bookcase', 'board', 'clutter')\nnum_points = 4096\ntrain_area = [1, 2, 3, 4, 6]\ntest_area = 5\ntrain_pipeline = [\n    dict(\n        type='LoadPointsFromFile',\n        coord_type='DEPTH',",
        "detail": "projects.configs._base_.datasets.s3dis_seg-3d-13class",
        "documentation": {}
    },
    {
        "label": "class_names",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.s3dis_seg-3d-13class",
        "description": "projects.configs._base_.datasets.s3dis_seg-3d-13class",
        "peekOfCode": "class_names = ('ceiling', 'floor', 'wall', 'beam', 'column', 'window', 'door',\n               'table', 'chair', 'sofa', 'bookcase', 'board', 'clutter')\nnum_points = 4096\ntrain_area = [1, 2, 3, 4, 6]\ntest_area = 5\ntrain_pipeline = [\n    dict(\n        type='LoadPointsFromFile',\n        coord_type='DEPTH',\n        shift_height=False,",
        "detail": "projects.configs._base_.datasets.s3dis_seg-3d-13class",
        "documentation": {}
    },
    {
        "label": "num_points",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.s3dis_seg-3d-13class",
        "description": "projects.configs._base_.datasets.s3dis_seg-3d-13class",
        "peekOfCode": "num_points = 4096\ntrain_area = [1, 2, 3, 4, 6]\ntest_area = 5\ntrain_pipeline = [\n    dict(\n        type='LoadPointsFromFile',\n        coord_type='DEPTH',\n        shift_height=False,\n        use_color=True,\n        load_dim=6,",
        "detail": "projects.configs._base_.datasets.s3dis_seg-3d-13class",
        "documentation": {}
    },
    {
        "label": "train_area",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.s3dis_seg-3d-13class",
        "description": "projects.configs._base_.datasets.s3dis_seg-3d-13class",
        "peekOfCode": "train_area = [1, 2, 3, 4, 6]\ntest_area = 5\ntrain_pipeline = [\n    dict(\n        type='LoadPointsFromFile',\n        coord_type='DEPTH',\n        shift_height=False,\n        use_color=True,\n        load_dim=6,\n        use_dim=[0, 1, 2, 3, 4, 5]),",
        "detail": "projects.configs._base_.datasets.s3dis_seg-3d-13class",
        "documentation": {}
    },
    {
        "label": "test_area",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.s3dis_seg-3d-13class",
        "description": "projects.configs._base_.datasets.s3dis_seg-3d-13class",
        "peekOfCode": "test_area = 5\ntrain_pipeline = [\n    dict(\n        type='LoadPointsFromFile',\n        coord_type='DEPTH',\n        shift_height=False,\n        use_color=True,\n        load_dim=6,\n        use_dim=[0, 1, 2, 3, 4, 5]),\n    dict(",
        "detail": "projects.configs._base_.datasets.s3dis_seg-3d-13class",
        "documentation": {}
    },
    {
        "label": "train_pipeline",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.s3dis_seg-3d-13class",
        "description": "projects.configs._base_.datasets.s3dis_seg-3d-13class",
        "peekOfCode": "train_pipeline = [\n    dict(\n        type='LoadPointsFromFile',\n        coord_type='DEPTH',\n        shift_height=False,\n        use_color=True,\n        load_dim=6,\n        use_dim=[0, 1, 2, 3, 4, 5]),\n    dict(\n        type='LoadAnnotations3D',",
        "detail": "projects.configs._base_.datasets.s3dis_seg-3d-13class",
        "documentation": {}
    },
    {
        "label": "test_pipeline",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.s3dis_seg-3d-13class",
        "description": "projects.configs._base_.datasets.s3dis_seg-3d-13class",
        "peekOfCode": "test_pipeline = [\n    dict(\n        type='LoadPointsFromFile',\n        coord_type='DEPTH',\n        shift_height=False,\n        use_color=True,\n        load_dim=6,\n        use_dim=[0, 1, 2, 3, 4, 5]),\n    dict(type='NormalizePointsColor', color_mean=None),\n    dict(",
        "detail": "projects.configs._base_.datasets.s3dis_seg-3d-13class",
        "documentation": {}
    },
    {
        "label": "eval_pipeline",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.s3dis_seg-3d-13class",
        "description": "projects.configs._base_.datasets.s3dis_seg-3d-13class",
        "peekOfCode": "eval_pipeline = [\n    dict(\n        type='LoadPointsFromFile',\n        coord_type='DEPTH',\n        shift_height=False,\n        use_color=True,\n        load_dim=6,\n        use_dim=[0, 1, 2, 3, 4, 5]),\n    dict(\n        type='LoadAnnotations3D',",
        "detail": "projects.configs._base_.datasets.s3dis_seg-3d-13class",
        "documentation": {}
    },
    {
        "label": "data",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.s3dis_seg-3d-13class",
        "description": "projects.configs._base_.datasets.s3dis_seg-3d-13class",
        "peekOfCode": "data = dict(\n    samples_per_gpu=8,\n    workers_per_gpu=4,\n    # train on area 1, 2, 3, 4, 6\n    # test on area 5\n    train=dict(\n        type=dataset_type,\n        data_root=data_root,\n        ann_files=[\n            data_root + f's3dis_infos_Area_{i}.pkl' for i in train_area",
        "detail": "projects.configs._base_.datasets.s3dis_seg-3d-13class",
        "documentation": {}
    },
    {
        "label": "evaluation",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.s3dis_seg-3d-13class",
        "description": "projects.configs._base_.datasets.s3dis_seg-3d-13class",
        "peekOfCode": "evaluation = dict(pipeline=eval_pipeline)",
        "detail": "projects.configs._base_.datasets.s3dis_seg-3d-13class",
        "documentation": {}
    },
    {
        "label": "dataset_type",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.scannet-3d-18class",
        "description": "projects.configs._base_.datasets.scannet-3d-18class",
        "peekOfCode": "dataset_type = 'ScanNetDataset'\ndata_root = './data/scannet/'\nclass_names = ('cabinet', 'bed', 'chair', 'sofa', 'table', 'door', 'window',\n               'bookshelf', 'picture', 'counter', 'desk', 'curtain',\n               'refrigerator', 'showercurtrain', 'toilet', 'sink', 'bathtub',\n               'garbagebin')\ntrain_pipeline = [\n    dict(\n        type='LoadPointsFromFile',\n        coord_type='DEPTH',",
        "detail": "projects.configs._base_.datasets.scannet-3d-18class",
        "documentation": {}
    },
    {
        "label": "data_root",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.scannet-3d-18class",
        "description": "projects.configs._base_.datasets.scannet-3d-18class",
        "peekOfCode": "data_root = './data/scannet/'\nclass_names = ('cabinet', 'bed', 'chair', 'sofa', 'table', 'door', 'window',\n               'bookshelf', 'picture', 'counter', 'desk', 'curtain',\n               'refrigerator', 'showercurtrain', 'toilet', 'sink', 'bathtub',\n               'garbagebin')\ntrain_pipeline = [\n    dict(\n        type='LoadPointsFromFile',\n        coord_type='DEPTH',\n        shift_height=True,",
        "detail": "projects.configs._base_.datasets.scannet-3d-18class",
        "documentation": {}
    },
    {
        "label": "class_names",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.scannet-3d-18class",
        "description": "projects.configs._base_.datasets.scannet-3d-18class",
        "peekOfCode": "class_names = ('cabinet', 'bed', 'chair', 'sofa', 'table', 'door', 'window',\n               'bookshelf', 'picture', 'counter', 'desk', 'curtain',\n               'refrigerator', 'showercurtrain', 'toilet', 'sink', 'bathtub',\n               'garbagebin')\ntrain_pipeline = [\n    dict(\n        type='LoadPointsFromFile',\n        coord_type='DEPTH',\n        shift_height=True,\n        load_dim=6,",
        "detail": "projects.configs._base_.datasets.scannet-3d-18class",
        "documentation": {}
    },
    {
        "label": "train_pipeline",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.scannet-3d-18class",
        "description": "projects.configs._base_.datasets.scannet-3d-18class",
        "peekOfCode": "train_pipeline = [\n    dict(\n        type='LoadPointsFromFile',\n        coord_type='DEPTH',\n        shift_height=True,\n        load_dim=6,\n        use_dim=[0, 1, 2]),\n    dict(\n        type='LoadAnnotations3D',\n        with_bbox_3d=True,",
        "detail": "projects.configs._base_.datasets.scannet-3d-18class",
        "documentation": {}
    },
    {
        "label": "test_pipeline",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.scannet-3d-18class",
        "description": "projects.configs._base_.datasets.scannet-3d-18class",
        "peekOfCode": "test_pipeline = [\n    dict(\n        type='LoadPointsFromFile',\n        coord_type='DEPTH',\n        shift_height=True,\n        load_dim=6,\n        use_dim=[0, 1, 2]),\n    dict(type='GlobalAlignment', rotation_axis=2),\n    dict(\n        type='MultiScaleFlipAug3D',",
        "detail": "projects.configs._base_.datasets.scannet-3d-18class",
        "documentation": {}
    },
    {
        "label": "eval_pipeline",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.scannet-3d-18class",
        "description": "projects.configs._base_.datasets.scannet-3d-18class",
        "peekOfCode": "eval_pipeline = [\n    dict(\n        type='LoadPointsFromFile',\n        coord_type='DEPTH',\n        shift_height=False,\n        load_dim=6,\n        use_dim=[0, 1, 2]),\n    dict(type='GlobalAlignment', rotation_axis=2),\n    dict(\n        type='DefaultFormatBundle3D',",
        "detail": "projects.configs._base_.datasets.scannet-3d-18class",
        "documentation": {}
    },
    {
        "label": "data",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.scannet-3d-18class",
        "description": "projects.configs._base_.datasets.scannet-3d-18class",
        "peekOfCode": "data = dict(\n    samples_per_gpu=8,\n    workers_per_gpu=4,\n    train=dict(\n        type='RepeatDataset',\n        times=5,\n        dataset=dict(\n            type=dataset_type,\n            data_root=data_root,\n            ann_file=data_root + 'scannet_infos_train.pkl',",
        "detail": "projects.configs._base_.datasets.scannet-3d-18class",
        "documentation": {}
    },
    {
        "label": "evaluation",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.scannet-3d-18class",
        "description": "projects.configs._base_.datasets.scannet-3d-18class",
        "peekOfCode": "evaluation = dict(pipeline=eval_pipeline)",
        "detail": "projects.configs._base_.datasets.scannet-3d-18class",
        "documentation": {}
    },
    {
        "label": "dataset_type",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.scannet_seg-3d-20class",
        "description": "projects.configs._base_.datasets.scannet_seg-3d-20class",
        "peekOfCode": "dataset_type = 'ScanNetSegDataset'\ndata_root = './data/scannet/'\nclass_names = ('wall', 'floor', 'cabinet', 'bed', 'chair', 'sofa', 'table',\n               'door', 'window', 'bookshelf', 'picture', 'counter', 'desk',\n               'curtain', 'refrigerator', 'showercurtrain', 'toilet', 'sink',\n               'bathtub', 'otherfurniture')\nnum_points = 8192\ntrain_pipeline = [\n    dict(\n        type='LoadPointsFromFile',",
        "detail": "projects.configs._base_.datasets.scannet_seg-3d-20class",
        "documentation": {}
    },
    {
        "label": "data_root",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.scannet_seg-3d-20class",
        "description": "projects.configs._base_.datasets.scannet_seg-3d-20class",
        "peekOfCode": "data_root = './data/scannet/'\nclass_names = ('wall', 'floor', 'cabinet', 'bed', 'chair', 'sofa', 'table',\n               'door', 'window', 'bookshelf', 'picture', 'counter', 'desk',\n               'curtain', 'refrigerator', 'showercurtrain', 'toilet', 'sink',\n               'bathtub', 'otherfurniture')\nnum_points = 8192\ntrain_pipeline = [\n    dict(\n        type='LoadPointsFromFile',\n        coord_type='DEPTH',",
        "detail": "projects.configs._base_.datasets.scannet_seg-3d-20class",
        "documentation": {}
    },
    {
        "label": "class_names",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.scannet_seg-3d-20class",
        "description": "projects.configs._base_.datasets.scannet_seg-3d-20class",
        "peekOfCode": "class_names = ('wall', 'floor', 'cabinet', 'bed', 'chair', 'sofa', 'table',\n               'door', 'window', 'bookshelf', 'picture', 'counter', 'desk',\n               'curtain', 'refrigerator', 'showercurtrain', 'toilet', 'sink',\n               'bathtub', 'otherfurniture')\nnum_points = 8192\ntrain_pipeline = [\n    dict(\n        type='LoadPointsFromFile',\n        coord_type='DEPTH',\n        shift_height=False,",
        "detail": "projects.configs._base_.datasets.scannet_seg-3d-20class",
        "documentation": {}
    },
    {
        "label": "num_points",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.scannet_seg-3d-20class",
        "description": "projects.configs._base_.datasets.scannet_seg-3d-20class",
        "peekOfCode": "num_points = 8192\ntrain_pipeline = [\n    dict(\n        type='LoadPointsFromFile',\n        coord_type='DEPTH',\n        shift_height=False,\n        use_color=True,\n        load_dim=6,\n        use_dim=[0, 1, 2, 3, 4, 5]),\n    dict(",
        "detail": "projects.configs._base_.datasets.scannet_seg-3d-20class",
        "documentation": {}
    },
    {
        "label": "train_pipeline",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.scannet_seg-3d-20class",
        "description": "projects.configs._base_.datasets.scannet_seg-3d-20class",
        "peekOfCode": "train_pipeline = [\n    dict(\n        type='LoadPointsFromFile',\n        coord_type='DEPTH',\n        shift_height=False,\n        use_color=True,\n        load_dim=6,\n        use_dim=[0, 1, 2, 3, 4, 5]),\n    dict(\n        type='LoadAnnotations3D',",
        "detail": "projects.configs._base_.datasets.scannet_seg-3d-20class",
        "documentation": {}
    },
    {
        "label": "test_pipeline",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.scannet_seg-3d-20class",
        "description": "projects.configs._base_.datasets.scannet_seg-3d-20class",
        "peekOfCode": "test_pipeline = [\n    dict(\n        type='LoadPointsFromFile',\n        coord_type='DEPTH',\n        shift_height=False,\n        use_color=True,\n        load_dim=6,\n        use_dim=[0, 1, 2, 3, 4, 5]),\n    dict(type='NormalizePointsColor', color_mean=None),\n    dict(",
        "detail": "projects.configs._base_.datasets.scannet_seg-3d-20class",
        "documentation": {}
    },
    {
        "label": "eval_pipeline",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.scannet_seg-3d-20class",
        "description": "projects.configs._base_.datasets.scannet_seg-3d-20class",
        "peekOfCode": "eval_pipeline = [\n    dict(\n        type='LoadPointsFromFile',\n        coord_type='DEPTH',\n        shift_height=False,\n        use_color=True,\n        load_dim=6,\n        use_dim=[0, 1, 2, 3, 4, 5]),\n    dict(\n        type='LoadAnnotations3D',",
        "detail": "projects.configs._base_.datasets.scannet_seg-3d-20class",
        "documentation": {}
    },
    {
        "label": "data",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.scannet_seg-3d-20class",
        "description": "projects.configs._base_.datasets.scannet_seg-3d-20class",
        "peekOfCode": "data = dict(\n    samples_per_gpu=8,\n    workers_per_gpu=4,\n    train=dict(\n        type=dataset_type,\n        data_root=data_root,\n        ann_file=data_root + 'scannet_infos_train.pkl',\n        pipeline=train_pipeline,\n        classes=class_names,\n        test_mode=False,",
        "detail": "projects.configs._base_.datasets.scannet_seg-3d-20class",
        "documentation": {}
    },
    {
        "label": "evaluation",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.scannet_seg-3d-20class",
        "description": "projects.configs._base_.datasets.scannet_seg-3d-20class",
        "peekOfCode": "evaluation = dict(pipeline=eval_pipeline)",
        "detail": "projects.configs._base_.datasets.scannet_seg-3d-20class",
        "documentation": {}
    },
    {
        "label": "dataset_type",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.sunrgbd-3d-10class",
        "description": "projects.configs._base_.datasets.sunrgbd-3d-10class",
        "peekOfCode": "dataset_type = 'SUNRGBDDataset'\ndata_root = 'data/sunrgbd/'\nclass_names = ('bed', 'table', 'sofa', 'chair', 'toilet', 'desk', 'dresser',\n               'night_stand', 'bookshelf', 'bathtub')\ntrain_pipeline = [\n    dict(\n        type='LoadPointsFromFile',\n        coord_type='DEPTH',\n        shift_height=True,\n        load_dim=6,",
        "detail": "projects.configs._base_.datasets.sunrgbd-3d-10class",
        "documentation": {}
    },
    {
        "label": "data_root",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.sunrgbd-3d-10class",
        "description": "projects.configs._base_.datasets.sunrgbd-3d-10class",
        "peekOfCode": "data_root = 'data/sunrgbd/'\nclass_names = ('bed', 'table', 'sofa', 'chair', 'toilet', 'desk', 'dresser',\n               'night_stand', 'bookshelf', 'bathtub')\ntrain_pipeline = [\n    dict(\n        type='LoadPointsFromFile',\n        coord_type='DEPTH',\n        shift_height=True,\n        load_dim=6,\n        use_dim=[0, 1, 2]),",
        "detail": "projects.configs._base_.datasets.sunrgbd-3d-10class",
        "documentation": {}
    },
    {
        "label": "class_names",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.sunrgbd-3d-10class",
        "description": "projects.configs._base_.datasets.sunrgbd-3d-10class",
        "peekOfCode": "class_names = ('bed', 'table', 'sofa', 'chair', 'toilet', 'desk', 'dresser',\n               'night_stand', 'bookshelf', 'bathtub')\ntrain_pipeline = [\n    dict(\n        type='LoadPointsFromFile',\n        coord_type='DEPTH',\n        shift_height=True,\n        load_dim=6,\n        use_dim=[0, 1, 2]),\n    dict(type='LoadAnnotations3D'),",
        "detail": "projects.configs._base_.datasets.sunrgbd-3d-10class",
        "documentation": {}
    },
    {
        "label": "train_pipeline",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.sunrgbd-3d-10class",
        "description": "projects.configs._base_.datasets.sunrgbd-3d-10class",
        "peekOfCode": "train_pipeline = [\n    dict(\n        type='LoadPointsFromFile',\n        coord_type='DEPTH',\n        shift_height=True,\n        load_dim=6,\n        use_dim=[0, 1, 2]),\n    dict(type='LoadAnnotations3D'),\n    dict(\n        type='RandomFlip3D',",
        "detail": "projects.configs._base_.datasets.sunrgbd-3d-10class",
        "documentation": {}
    },
    {
        "label": "test_pipeline",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.sunrgbd-3d-10class",
        "description": "projects.configs._base_.datasets.sunrgbd-3d-10class",
        "peekOfCode": "test_pipeline = [\n    dict(\n        type='LoadPointsFromFile',\n        coord_type='DEPTH',\n        shift_height=True,\n        load_dim=6,\n        use_dim=[0, 1, 2]),\n    dict(\n        type='MultiScaleFlipAug3D',\n        img_scale=(1333, 800),",
        "detail": "projects.configs._base_.datasets.sunrgbd-3d-10class",
        "documentation": {}
    },
    {
        "label": "eval_pipeline",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.sunrgbd-3d-10class",
        "description": "projects.configs._base_.datasets.sunrgbd-3d-10class",
        "peekOfCode": "eval_pipeline = [\n    dict(\n        type='LoadPointsFromFile',\n        coord_type='DEPTH',\n        shift_height=False,\n        load_dim=6,\n        use_dim=[0, 1, 2]),\n    dict(\n        type='DefaultFormatBundle3D',\n        class_names=class_names,",
        "detail": "projects.configs._base_.datasets.sunrgbd-3d-10class",
        "documentation": {}
    },
    {
        "label": "data",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.sunrgbd-3d-10class",
        "description": "projects.configs._base_.datasets.sunrgbd-3d-10class",
        "peekOfCode": "data = dict(\n    samples_per_gpu=16,\n    workers_per_gpu=4,\n    train=dict(\n        type='RepeatDataset',\n        times=5,\n        dataset=dict(\n            type=dataset_type,\n            data_root=data_root,\n            ann_file=data_root + 'sunrgbd_infos_train.pkl',",
        "detail": "projects.configs._base_.datasets.sunrgbd-3d-10class",
        "documentation": {}
    },
    {
        "label": "evaluation",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.sunrgbd-3d-10class",
        "description": "projects.configs._base_.datasets.sunrgbd-3d-10class",
        "peekOfCode": "evaluation = dict(pipeline=eval_pipeline)",
        "detail": "projects.configs._base_.datasets.sunrgbd-3d-10class",
        "documentation": {}
    },
    {
        "label": "dataset_type",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.waymoD5-3d-3class",
        "description": "projects.configs._base_.datasets.waymoD5-3d-3class",
        "peekOfCode": "dataset_type = 'LidarWaymoDataset'\ndata_root = 'data/waymo-full/kitti_format/'\nfile_client_args = dict(backend='disk')\n# Uncomment the following if use ceph or other file clients.\n# See https://mmcv.readthedocs.io/en/latest/api.html#mmcv.fileio.FileClient\n# for more details.\n# file_client_args = dict(\n#     backend='petrel', path_mapping=dict(data='s3://waymo_data/'))\nclass_names = ['Car', 'Pedestrian', 'Cyclist']\npoint_cloud_range = [-74.88, -74.88, -2, 74.88, 74.88, 4]",
        "detail": "projects.configs._base_.datasets.waymoD5-3d-3class",
        "documentation": {}
    },
    {
        "label": "data_root",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.waymoD5-3d-3class",
        "description": "projects.configs._base_.datasets.waymoD5-3d-3class",
        "peekOfCode": "data_root = 'data/waymo-full/kitti_format/'\nfile_client_args = dict(backend='disk')\n# Uncomment the following if use ceph or other file clients.\n# See https://mmcv.readthedocs.io/en/latest/api.html#mmcv.fileio.FileClient\n# for more details.\n# file_client_args = dict(\n#     backend='petrel', path_mapping=dict(data='s3://waymo_data/'))\nclass_names = ['Car', 'Pedestrian', 'Cyclist']\npoint_cloud_range = [-74.88, -74.88, -2, 74.88, 74.88, 4]\ninput_modality = dict(use_lidar=True, use_camera=False)",
        "detail": "projects.configs._base_.datasets.waymoD5-3d-3class",
        "documentation": {}
    },
    {
        "label": "file_client_args",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.waymoD5-3d-3class",
        "description": "projects.configs._base_.datasets.waymoD5-3d-3class",
        "peekOfCode": "file_client_args = dict(backend='disk')\n# Uncomment the following if use ceph or other file clients.\n# See https://mmcv.readthedocs.io/en/latest/api.html#mmcv.fileio.FileClient\n# for more details.\n# file_client_args = dict(\n#     backend='petrel', path_mapping=dict(data='s3://waymo_data/'))\nclass_names = ['Car', 'Pedestrian', 'Cyclist']\npoint_cloud_range = [-74.88, -74.88, -2, 74.88, 74.88, 4]\ninput_modality = dict(use_lidar=True, use_camera=False)\ndb_sampler = dict(",
        "detail": "projects.configs._base_.datasets.waymoD5-3d-3class",
        "documentation": {}
    },
    {
        "label": "class_names",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.waymoD5-3d-3class",
        "description": "projects.configs._base_.datasets.waymoD5-3d-3class",
        "peekOfCode": "class_names = ['Car', 'Pedestrian', 'Cyclist']\npoint_cloud_range = [-74.88, -74.88, -2, 74.88, 74.88, 4]\ninput_modality = dict(use_lidar=True, use_camera=False)\ndb_sampler = dict(\n    data_root=data_root,\n    info_path=data_root + 'waymo_dbinfos_train.pkl',\n    rate=1.0,\n    prepare=dict(\n        filter_by_difficulty=[-1],\n        filter_by_min_points=dict(Car=5, Pedestrian=10, Cyclist=10)),",
        "detail": "projects.configs._base_.datasets.waymoD5-3d-3class",
        "documentation": {}
    },
    {
        "label": "point_cloud_range",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.waymoD5-3d-3class",
        "description": "projects.configs._base_.datasets.waymoD5-3d-3class",
        "peekOfCode": "point_cloud_range = [-74.88, -74.88, -2, 74.88, 74.88, 4]\ninput_modality = dict(use_lidar=True, use_camera=False)\ndb_sampler = dict(\n    data_root=data_root,\n    info_path=data_root + 'waymo_dbinfos_train.pkl',\n    rate=1.0,\n    prepare=dict(\n        filter_by_difficulty=[-1],\n        filter_by_min_points=dict(Car=5, Pedestrian=10, Cyclist=10)),\n    classes=class_names,",
        "detail": "projects.configs._base_.datasets.waymoD5-3d-3class",
        "documentation": {}
    },
    {
        "label": "input_modality",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.waymoD5-3d-3class",
        "description": "projects.configs._base_.datasets.waymoD5-3d-3class",
        "peekOfCode": "input_modality = dict(use_lidar=True, use_camera=False)\ndb_sampler = dict(\n    data_root=data_root,\n    info_path=data_root + 'waymo_dbinfos_train.pkl',\n    rate=1.0,\n    prepare=dict(\n        filter_by_difficulty=[-1],\n        filter_by_min_points=dict(Car=5, Pedestrian=10, Cyclist=10)),\n    classes=class_names,\n    sample_groups=dict(Car=15, Pedestrian=10, Cyclist=10),",
        "detail": "projects.configs._base_.datasets.waymoD5-3d-3class",
        "documentation": {}
    },
    {
        "label": "db_sampler",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.waymoD5-3d-3class",
        "description": "projects.configs._base_.datasets.waymoD5-3d-3class",
        "peekOfCode": "db_sampler = dict(\n    data_root=data_root,\n    info_path=data_root + 'waymo_dbinfos_train.pkl',\n    rate=1.0,\n    prepare=dict(\n        filter_by_difficulty=[-1],\n        filter_by_min_points=dict(Car=5, Pedestrian=10, Cyclist=10)),\n    classes=class_names,\n    sample_groups=dict(Car=15, Pedestrian=10, Cyclist=10),\n    points_loader=dict(",
        "detail": "projects.configs._base_.datasets.waymoD5-3d-3class",
        "documentation": {}
    },
    {
        "label": "train_pipeline",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.waymoD5-3d-3class",
        "description": "projects.configs._base_.datasets.waymoD5-3d-3class",
        "peekOfCode": "train_pipeline = [\n    dict(\n        type='LoadPointsFromFile',\n        coord_type='LIDAR',\n        load_dim=6,\n        use_dim=5,\n        file_client_args=file_client_args),\n    dict(\n        type='LoadAnnotations3D',\n        with_bbox_3d=True,",
        "detail": "projects.configs._base_.datasets.waymoD5-3d-3class",
        "documentation": {}
    },
    {
        "label": "test_pipeline",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.waymoD5-3d-3class",
        "description": "projects.configs._base_.datasets.waymoD5-3d-3class",
        "peekOfCode": "test_pipeline = [\n    dict(\n        type='LoadPointsFromFile',\n        coord_type='LIDAR',\n        load_dim=6,\n        use_dim=5,\n        file_client_args=file_client_args),\n    dict(\n        type='MultiScaleFlipAug3D',\n        img_scale=(1333, 800),",
        "detail": "projects.configs._base_.datasets.waymoD5-3d-3class",
        "documentation": {}
    },
    {
        "label": "eval_pipeline",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.waymoD5-3d-3class",
        "description": "projects.configs._base_.datasets.waymoD5-3d-3class",
        "peekOfCode": "eval_pipeline = [\n    dict(\n        type='LoadPointsFromFile',\n        coord_type='LIDAR',\n        load_dim=6,\n        use_dim=5,\n        file_client_args=file_client_args),\n    dict(\n        type='DefaultFormatBundle3D',\n        class_names=class_names,",
        "detail": "projects.configs._base_.datasets.waymoD5-3d-3class",
        "documentation": {}
    },
    {
        "label": "data",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.waymoD5-3d-3class",
        "description": "projects.configs._base_.datasets.waymoD5-3d-3class",
        "peekOfCode": "data = dict(\n    samples_per_gpu=2,\n    workers_per_gpu=4,\n    train=dict(\n        type='RepeatDataset',\n        times=2,\n        dataset=dict(\n            type=dataset_type,\n            data_root=data_root,\n            ann_file=data_root + 'waymo_infos_train.pkl',",
        "detail": "projects.configs._base_.datasets.waymoD5-3d-3class",
        "documentation": {}
    },
    {
        "label": "evaluation",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.waymoD5-3d-3class",
        "description": "projects.configs._base_.datasets.waymoD5-3d-3class",
        "peekOfCode": "evaluation = dict(interval=24, pipeline=eval_pipeline)",
        "detail": "projects.configs._base_.datasets.waymoD5-3d-3class",
        "documentation": {}
    },
    {
        "label": "dataset_type",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.waymoD5-3d-car",
        "description": "projects.configs._base_.datasets.waymoD5-3d-car",
        "peekOfCode": "dataset_type = 'WaymoDataset'\ndata_root = 'data/waymo/kitti_format/'\nfile_client_args = dict(backend='disk')\n# Uncomment the following if use ceph or other file clients.\n# See https://mmcv.readthedocs.io/en/latest/api.html#mmcv.fileio.FileClient\n# for more details.\n# file_client_args = dict(\n#     backend='petrel', path_mapping=dict(data='s3://waymo_data/'))\nclass_names = ['Car']\npoint_cloud_range = [-74.88, -74.88, -2, 74.88, 74.88, 4]",
        "detail": "projects.configs._base_.datasets.waymoD5-3d-car",
        "documentation": {}
    },
    {
        "label": "data_root",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.waymoD5-3d-car",
        "description": "projects.configs._base_.datasets.waymoD5-3d-car",
        "peekOfCode": "data_root = 'data/waymo/kitti_format/'\nfile_client_args = dict(backend='disk')\n# Uncomment the following if use ceph or other file clients.\n# See https://mmcv.readthedocs.io/en/latest/api.html#mmcv.fileio.FileClient\n# for more details.\n# file_client_args = dict(\n#     backend='petrel', path_mapping=dict(data='s3://waymo_data/'))\nclass_names = ['Car']\npoint_cloud_range = [-74.88, -74.88, -2, 74.88, 74.88, 4]\ninput_modality = dict(use_lidar=True, use_camera=False)",
        "detail": "projects.configs._base_.datasets.waymoD5-3d-car",
        "documentation": {}
    },
    {
        "label": "file_client_args",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.waymoD5-3d-car",
        "description": "projects.configs._base_.datasets.waymoD5-3d-car",
        "peekOfCode": "file_client_args = dict(backend='disk')\n# Uncomment the following if use ceph or other file clients.\n# See https://mmcv.readthedocs.io/en/latest/api.html#mmcv.fileio.FileClient\n# for more details.\n# file_client_args = dict(\n#     backend='petrel', path_mapping=dict(data='s3://waymo_data/'))\nclass_names = ['Car']\npoint_cloud_range = [-74.88, -74.88, -2, 74.88, 74.88, 4]\ninput_modality = dict(use_lidar=True, use_camera=False)\ndb_sampler = dict(",
        "detail": "projects.configs._base_.datasets.waymoD5-3d-car",
        "documentation": {}
    },
    {
        "label": "class_names",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.waymoD5-3d-car",
        "description": "projects.configs._base_.datasets.waymoD5-3d-car",
        "peekOfCode": "class_names = ['Car']\npoint_cloud_range = [-74.88, -74.88, -2, 74.88, 74.88, 4]\ninput_modality = dict(use_lidar=True, use_camera=False)\ndb_sampler = dict(\n    data_root=data_root,\n    info_path=data_root + 'waymo_dbinfos_train.pkl',\n    rate=1.0,\n    prepare=dict(filter_by_difficulty=[-1], filter_by_min_points=dict(Car=5)),\n    classes=class_names,\n    sample_groups=dict(Car=15),",
        "detail": "projects.configs._base_.datasets.waymoD5-3d-car",
        "documentation": {}
    },
    {
        "label": "point_cloud_range",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.waymoD5-3d-car",
        "description": "projects.configs._base_.datasets.waymoD5-3d-car",
        "peekOfCode": "point_cloud_range = [-74.88, -74.88, -2, 74.88, 74.88, 4]\ninput_modality = dict(use_lidar=True, use_camera=False)\ndb_sampler = dict(\n    data_root=data_root,\n    info_path=data_root + 'waymo_dbinfos_train.pkl',\n    rate=1.0,\n    prepare=dict(filter_by_difficulty=[-1], filter_by_min_points=dict(Car=5)),\n    classes=class_names,\n    sample_groups=dict(Car=15),\n    points_loader=dict(",
        "detail": "projects.configs._base_.datasets.waymoD5-3d-car",
        "documentation": {}
    },
    {
        "label": "input_modality",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.waymoD5-3d-car",
        "description": "projects.configs._base_.datasets.waymoD5-3d-car",
        "peekOfCode": "input_modality = dict(use_lidar=True, use_camera=False)\ndb_sampler = dict(\n    data_root=data_root,\n    info_path=data_root + 'waymo_dbinfos_train.pkl',\n    rate=1.0,\n    prepare=dict(filter_by_difficulty=[-1], filter_by_min_points=dict(Car=5)),\n    classes=class_names,\n    sample_groups=dict(Car=15),\n    points_loader=dict(\n        type='LoadPointsFromFile',",
        "detail": "projects.configs._base_.datasets.waymoD5-3d-car",
        "documentation": {}
    },
    {
        "label": "db_sampler",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.waymoD5-3d-car",
        "description": "projects.configs._base_.datasets.waymoD5-3d-car",
        "peekOfCode": "db_sampler = dict(\n    data_root=data_root,\n    info_path=data_root + 'waymo_dbinfos_train.pkl',\n    rate=1.0,\n    prepare=dict(filter_by_difficulty=[-1], filter_by_min_points=dict(Car=5)),\n    classes=class_names,\n    sample_groups=dict(Car=15),\n    points_loader=dict(\n        type='LoadPointsFromFile',\n        coord_type='LIDAR',",
        "detail": "projects.configs._base_.datasets.waymoD5-3d-car",
        "documentation": {}
    },
    {
        "label": "train_pipeline",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.waymoD5-3d-car",
        "description": "projects.configs._base_.datasets.waymoD5-3d-car",
        "peekOfCode": "train_pipeline = [\n    dict(\n        type='LoadPointsFromFile',\n        coord_type='LIDAR',\n        load_dim=6,\n        use_dim=5,\n        file_client_args=file_client_args),\n    dict(\n        type='LoadAnnotations3D',\n        with_bbox_3d=True,",
        "detail": "projects.configs._base_.datasets.waymoD5-3d-car",
        "documentation": {}
    },
    {
        "label": "test_pipeline",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.waymoD5-3d-car",
        "description": "projects.configs._base_.datasets.waymoD5-3d-car",
        "peekOfCode": "test_pipeline = [\n    dict(\n        type='LoadPointsFromFile',\n        coord_type='LIDAR',\n        load_dim=6,\n        use_dim=5,\n        file_client_args=file_client_args),\n    dict(\n        type='MultiScaleFlipAug3D',\n        img_scale=(1333, 800),",
        "detail": "projects.configs._base_.datasets.waymoD5-3d-car",
        "documentation": {}
    },
    {
        "label": "eval_pipeline",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.waymoD5-3d-car",
        "description": "projects.configs._base_.datasets.waymoD5-3d-car",
        "peekOfCode": "eval_pipeline = [\n    dict(\n        type='LoadPointsFromFile',\n        coord_type='LIDAR',\n        load_dim=6,\n        use_dim=5,\n        file_client_args=file_client_args),\n    dict(\n        type='DefaultFormatBundle3D',\n        class_names=class_names,",
        "detail": "projects.configs._base_.datasets.waymoD5-3d-car",
        "documentation": {}
    },
    {
        "label": "data",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.waymoD5-3d-car",
        "description": "projects.configs._base_.datasets.waymoD5-3d-car",
        "peekOfCode": "data = dict(\n    samples_per_gpu=2,\n    workers_per_gpu=4,\n    train=dict(\n        type='RepeatDataset',\n        times=2,\n        dataset=dict(\n            type=dataset_type,\n            data_root=data_root,\n            ann_file=data_root + 'waymo_infos_train.pkl',",
        "detail": "projects.configs._base_.datasets.waymoD5-3d-car",
        "documentation": {}
    },
    {
        "label": "evaluation",
        "kind": 5,
        "importPath": "projects.configs._base_.datasets.waymoD5-3d-car",
        "description": "projects.configs._base_.datasets.waymoD5-3d-car",
        "peekOfCode": "evaluation = dict(interval=24, pipeline=eval_pipeline)",
        "detail": "projects.configs._base_.datasets.waymoD5-3d-car",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "projects.configs._base_.models.3dssd",
        "description": "projects.configs._base_.models.3dssd",
        "peekOfCode": "model = dict(\n    type='SSD3DNet',\n    backbone=dict(\n        type='PointNet2SAMSG',\n        in_channels=4,\n        num_points=(4096, 512, (256, 256)),\n        radii=((0.2, 0.4, 0.8), (0.4, 0.8, 1.6), (1.6, 3.2, 4.8)),\n        num_samples=((32, 32, 64), (32, 32, 64), (32, 32, 32)),\n        sa_channels=(((16, 16, 32), (16, 16, 32), (32, 32, 64)),\n                     ((64, 64, 128), (64, 64, 128), (64, 96, 128)),",
        "detail": "projects.configs._base_.models.3dssd",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "projects.configs._base_.models.cascade_mask_rcnn_r50_fpn",
        "description": "projects.configs._base_.models.cascade_mask_rcnn_r50_fpn",
        "peekOfCode": "model = dict(\n    type='CascadeRCNN',\n    pretrained='torchvision://resnet50',\n    backbone=dict(\n        type='ResNet',\n        depth=50,\n        num_stages=4,\n        out_indices=(0, 1, 2, 3),\n        frozen_stages=1,\n        norm_cfg=dict(type='BN', requires_grad=True),",
        "detail": "projects.configs._base_.models.cascade_mask_rcnn_r50_fpn",
        "documentation": {}
    },
    {
        "label": "voxel_size",
        "kind": 5,
        "importPath": "projects.configs._base_.models.centerpoint_01voxel_second_secfpn_nus",
        "description": "projects.configs._base_.models.centerpoint_01voxel_second_secfpn_nus",
        "peekOfCode": "voxel_size = [0.1, 0.1, 0.2]\nmodel = dict(\n    type='CenterPoint',\n    pts_voxel_layer=dict(\n        max_num_points=10, voxel_size=voxel_size, max_voxels=(90000, 120000)),\n    pts_voxel_encoder=dict(type='HardSimpleVFE', num_features=5),\n    pts_middle_encoder=dict(\n        type='SparseEncoder',\n        in_channels=5,\n        sparse_shape=[41, 1024, 1024],",
        "detail": "projects.configs._base_.models.centerpoint_01voxel_second_secfpn_nus",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "projects.configs._base_.models.centerpoint_01voxel_second_secfpn_nus",
        "description": "projects.configs._base_.models.centerpoint_01voxel_second_secfpn_nus",
        "peekOfCode": "model = dict(\n    type='CenterPoint',\n    pts_voxel_layer=dict(\n        max_num_points=10, voxel_size=voxel_size, max_voxels=(90000, 120000)),\n    pts_voxel_encoder=dict(type='HardSimpleVFE', num_features=5),\n    pts_middle_encoder=dict(\n        type='SparseEncoder',\n        in_channels=5,\n        sparse_shape=[41, 1024, 1024],\n        output_channels=128,",
        "detail": "projects.configs._base_.models.centerpoint_01voxel_second_secfpn_nus",
        "documentation": {}
    },
    {
        "label": "voxel_size",
        "kind": 5,
        "importPath": "projects.configs._base_.models.centerpoint_02pillar_second_secfpn_nus",
        "description": "projects.configs._base_.models.centerpoint_02pillar_second_secfpn_nus",
        "peekOfCode": "voxel_size = [0.2, 0.2, 8]\nmodel = dict(\n    type='CenterPoint',\n    pts_voxel_layer=dict(\n        max_num_points=20, voxel_size=voxel_size, max_voxels=(30000, 40000)),\n    pts_voxel_encoder=dict(\n        type='PillarFeatureNet',\n        in_channels=5,\n        feat_channels=[64],\n        with_distance=False,",
        "detail": "projects.configs._base_.models.centerpoint_02pillar_second_secfpn_nus",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "projects.configs._base_.models.centerpoint_02pillar_second_secfpn_nus",
        "description": "projects.configs._base_.models.centerpoint_02pillar_second_secfpn_nus",
        "peekOfCode": "model = dict(\n    type='CenterPoint',\n    pts_voxel_layer=dict(\n        max_num_points=20, voxel_size=voxel_size, max_voxels=(30000, 40000)),\n    pts_voxel_encoder=dict(\n        type='PillarFeatureNet',\n        in_channels=5,\n        feat_channels=[64],\n        with_distance=False,\n        voxel_size=(0.2, 0.2, 8),",
        "detail": "projects.configs._base_.models.centerpoint_02pillar_second_secfpn_nus",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "projects.configs._base_.models.fcos3d",
        "description": "projects.configs._base_.models.fcos3d",
        "peekOfCode": "model = dict(\n    type='FCOSMono3D',\n    pretrained='open-mmlab://detectron2/resnet101_caffe',\n    backbone=dict(\n        type='ResNet',\n        depth=101,\n        num_stages=4,\n        out_indices=(0, 1, 2, 3),\n        frozen_stages=1,\n        norm_cfg=dict(type='BN', requires_grad=False),",
        "detail": "projects.configs._base_.models.fcos3d",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "projects.configs._base_.models.groupfree3d",
        "description": "projects.configs._base_.models.groupfree3d",
        "peekOfCode": "model = dict(\n    type='GroupFree3DNet',\n    backbone=dict(\n        type='PointNet2SASSG',\n        in_channels=3,\n        num_points=(2048, 1024, 512, 256),\n        radius=(0.2, 0.4, 0.8, 1.2),\n        num_samples=(64, 32, 16, 16),\n        sa_channels=((64, 64, 128), (128, 128, 256), (128, 128, 256),\n                     (128, 128, 256)),",
        "detail": "projects.configs._base_.models.groupfree3d",
        "documentation": {}
    },
    {
        "label": "primitive_z_cfg",
        "kind": 5,
        "importPath": "projects.configs._base_.models.h3dnet",
        "description": "projects.configs._base_.models.h3dnet",
        "peekOfCode": "primitive_z_cfg = dict(\n    type='PrimitiveHead',\n    num_dims=2,\n    num_classes=18,\n    primitive_mode='z',\n    upper_thresh=100.0,\n    surface_thresh=0.5,\n    vote_module_cfg=dict(\n        in_channels=256,\n        vote_per_seed=1,",
        "detail": "projects.configs._base_.models.h3dnet",
        "documentation": {}
    },
    {
        "label": "primitive_xy_cfg",
        "kind": 5,
        "importPath": "projects.configs._base_.models.h3dnet",
        "description": "projects.configs._base_.models.h3dnet",
        "peekOfCode": "primitive_xy_cfg = dict(\n    type='PrimitiveHead',\n    num_dims=1,\n    num_classes=18,\n    primitive_mode='xy',\n    upper_thresh=100.0,\n    surface_thresh=0.5,\n    vote_module_cfg=dict(\n        in_channels=256,\n        vote_per_seed=1,",
        "detail": "projects.configs._base_.models.h3dnet",
        "documentation": {}
    },
    {
        "label": "primitive_line_cfg",
        "kind": 5,
        "importPath": "projects.configs._base_.models.h3dnet",
        "description": "projects.configs._base_.models.h3dnet",
        "peekOfCode": "primitive_line_cfg = dict(\n    type='PrimitiveHead',\n    num_dims=0,\n    num_classes=18,\n    primitive_mode='line',\n    upper_thresh=100.0,\n    surface_thresh=0.5,\n    vote_module_cfg=dict(\n        in_channels=256,\n        vote_per_seed=1,",
        "detail": "projects.configs._base_.models.h3dnet",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "projects.configs._base_.models.h3dnet",
        "description": "projects.configs._base_.models.h3dnet",
        "peekOfCode": "model = dict(\n    type='H3DNet',\n    backbone=dict(\n        type='MultiBackbone',\n        num_streams=4,\n        suffixes=['net0', 'net1', 'net2', 'net3'],\n        conv_cfg=dict(type='Conv1d'),\n        norm_cfg=dict(type='BN1d', eps=1e-5, momentum=0.01),\n        act_cfg=dict(type='ReLU'),\n        backbones=dict(",
        "detail": "projects.configs._base_.models.h3dnet",
        "documentation": {}
    },
    {
        "label": "_base_",
        "kind": 5,
        "importPath": "projects.configs._base_.models.hv_pointpillars_fpn_lyft",
        "description": "projects.configs._base_.models.hv_pointpillars_fpn_lyft",
        "peekOfCode": "_base_ = './hv_pointpillars_fpn_nus.py'\n# model settings (based on nuScenes model settings)\n# Voxel size for voxel encoder\n# Usually voxel size is changed consistently with the point cloud range\n# If point cloud range is modified, do remember to change all related\n# keys in the config.\nmodel = dict(\n    pts_voxel_layer=dict(\n        max_num_points=20,\n        point_cloud_range=[-80, -80, -5, 80, 80, 3],",
        "detail": "projects.configs._base_.models.hv_pointpillars_fpn_lyft",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "projects.configs._base_.models.hv_pointpillars_fpn_lyft",
        "description": "projects.configs._base_.models.hv_pointpillars_fpn_lyft",
        "peekOfCode": "model = dict(\n    pts_voxel_layer=dict(\n        max_num_points=20,\n        point_cloud_range=[-80, -80, -5, 80, 80, 3],\n        max_voxels=(60000, 60000)),\n    pts_voxel_encoder=dict(\n        feat_channels=[64], point_cloud_range=[-80, -80, -5, 80, 80, 3]),\n    pts_middle_encoder=dict(output_shape=[640, 640]),\n    pts_bbox_head=dict(\n        num_classes=9,",
        "detail": "projects.configs._base_.models.hv_pointpillars_fpn_lyft",
        "documentation": {}
    },
    {
        "label": "voxel_size",
        "kind": 5,
        "importPath": "projects.configs._base_.models.hv_pointpillars_fpn_nus",
        "description": "projects.configs._base_.models.hv_pointpillars_fpn_nus",
        "peekOfCode": "voxel_size = [0.25, 0.25, 8]\nmodel = dict(\n    type='MVXFasterRCNN',\n    pts_voxel_layer=dict(\n        max_num_points=64,\n        point_cloud_range=[-50, -50, -5, 50, 50, 3],\n        voxel_size=voxel_size,\n        max_voxels=(30000, 40000)),\n    pts_voxel_encoder=dict(\n        type='HardVFE',",
        "detail": "projects.configs._base_.models.hv_pointpillars_fpn_nus",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "projects.configs._base_.models.hv_pointpillars_fpn_nus",
        "description": "projects.configs._base_.models.hv_pointpillars_fpn_nus",
        "peekOfCode": "model = dict(\n    type='MVXFasterRCNN',\n    pts_voxel_layer=dict(\n        max_num_points=64,\n        point_cloud_range=[-50, -50, -5, 50, 50, 3],\n        voxel_size=voxel_size,\n        max_voxels=(30000, 40000)),\n    pts_voxel_encoder=dict(\n        type='HardVFE',\n        in_channels=4,",
        "detail": "projects.configs._base_.models.hv_pointpillars_fpn_nus",
        "documentation": {}
    },
    {
        "label": "_base_",
        "kind": 5,
        "importPath": "projects.configs._base_.models.hv_pointpillars_fpn_range100_lyft",
        "description": "projects.configs._base_.models.hv_pointpillars_fpn_range100_lyft",
        "peekOfCode": "_base_ = './hv_pointpillars_fpn_nus.py'\n# model settings (based on nuScenes model settings)\n# Voxel size for voxel encoder\n# Usually voxel size is changed consistently with the point cloud range\n# If point cloud range is modified, do remember to change all related\n# keys in the config.\nmodel = dict(\n    pts_voxel_layer=dict(\n        max_num_points=20,\n        point_cloud_range=[-100, -100, -5, 100, 100, 3],",
        "detail": "projects.configs._base_.models.hv_pointpillars_fpn_range100_lyft",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "projects.configs._base_.models.hv_pointpillars_fpn_range100_lyft",
        "description": "projects.configs._base_.models.hv_pointpillars_fpn_range100_lyft",
        "peekOfCode": "model = dict(\n    pts_voxel_layer=dict(\n        max_num_points=20,\n        point_cloud_range=[-100, -100, -5, 100, 100, 3],\n        max_voxels=(60000, 60000)),\n    pts_voxel_encoder=dict(\n        feat_channels=[64], point_cloud_range=[-100, -100, -5, 100, 100, 3]),\n    pts_middle_encoder=dict(output_shape=[800, 800]),\n    pts_bbox_head=dict(\n        num_classes=9,",
        "detail": "projects.configs._base_.models.hv_pointpillars_fpn_range100_lyft",
        "documentation": {}
    },
    {
        "label": "voxel_size",
        "kind": 5,
        "importPath": "projects.configs._base_.models.hv_pointpillars_secfpn_kitti",
        "description": "projects.configs._base_.models.hv_pointpillars_secfpn_kitti",
        "peekOfCode": "voxel_size = [0.16, 0.16, 4]\nmodel = dict(\n    type='VoxelNet',\n    voxel_layer=dict(\n        max_num_points=32,  # max_points_per_voxel\n        point_cloud_range=[0, -39.68, -3, 69.12, 39.68, 1],\n        voxel_size=voxel_size,\n        max_voxels=(16000, 40000)  # (training, testing) max_voxels\n    ),\n    voxel_encoder=dict(",
        "detail": "projects.configs._base_.models.hv_pointpillars_secfpn_kitti",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "projects.configs._base_.models.hv_pointpillars_secfpn_kitti",
        "description": "projects.configs._base_.models.hv_pointpillars_secfpn_kitti",
        "peekOfCode": "model = dict(\n    type='VoxelNet',\n    voxel_layer=dict(\n        max_num_points=32,  # max_points_per_voxel\n        point_cloud_range=[0, -39.68, -3, 69.12, 39.68, 1],\n        voxel_size=voxel_size,\n        max_voxels=(16000, 40000)  # (training, testing) max_voxels\n    ),\n    voxel_encoder=dict(\n        type='PillarFeatureNet',",
        "detail": "projects.configs._base_.models.hv_pointpillars_secfpn_kitti",
        "documentation": {}
    },
    {
        "label": "voxel_size",
        "kind": 5,
        "importPath": "projects.configs._base_.models.hv_pointpillars_secfpn_waymo",
        "description": "projects.configs._base_.models.hv_pointpillars_secfpn_waymo",
        "peekOfCode": "voxel_size = [0.32, 0.32, 6]\nmodel = dict(\n    type='MVXFasterRCNN',\n    pts_voxel_layer=dict(\n        max_num_points=20,\n        point_cloud_range=[-74.88, -74.88, -2, 74.88, 74.88, 4],\n        voxel_size=voxel_size,\n        max_voxels=(32000, 32000)),\n    pts_voxel_encoder=dict(\n        type='HardVFE',",
        "detail": "projects.configs._base_.models.hv_pointpillars_secfpn_waymo",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "projects.configs._base_.models.hv_pointpillars_secfpn_waymo",
        "description": "projects.configs._base_.models.hv_pointpillars_secfpn_waymo",
        "peekOfCode": "model = dict(\n    type='MVXFasterRCNN',\n    pts_voxel_layer=dict(\n        max_num_points=20,\n        point_cloud_range=[-74.88, -74.88, -2, 74.88, 74.88, 4],\n        voxel_size=voxel_size,\n        max_voxels=(32000, 32000)),\n    pts_voxel_encoder=dict(\n        type='HardVFE',\n        in_channels=5,",
        "detail": "projects.configs._base_.models.hv_pointpillars_secfpn_waymo",
        "documentation": {}
    },
    {
        "label": "voxel_size",
        "kind": 5,
        "importPath": "projects.configs._base_.models.hv_second_secfpn_kitti",
        "description": "projects.configs._base_.models.hv_second_secfpn_kitti",
        "peekOfCode": "voxel_size = [0.05, 0.05, 0.1]\nmodel = dict(\n    type='VoxelNet',\n    voxel_layer=dict(\n        max_num_points=5,\n        point_cloud_range=[0, -40, -3, 70.4, 40, 1],\n        voxel_size=voxel_size,\n        max_voxels=(16000, 40000)),\n    voxel_encoder=dict(type='HardSimpleVFE'),\n    middle_encoder=dict(",
        "detail": "projects.configs._base_.models.hv_second_secfpn_kitti",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "projects.configs._base_.models.hv_second_secfpn_kitti",
        "description": "projects.configs._base_.models.hv_second_secfpn_kitti",
        "peekOfCode": "model = dict(\n    type='VoxelNet',\n    voxel_layer=dict(\n        max_num_points=5,\n        point_cloud_range=[0, -40, -3, 70.4, 40, 1],\n        voxel_size=voxel_size,\n        max_voxels=(16000, 40000)),\n    voxel_encoder=dict(type='HardSimpleVFE'),\n    middle_encoder=dict(\n        type='SparseEncoder',",
        "detail": "projects.configs._base_.models.hv_second_secfpn_kitti",
        "documentation": {}
    },
    {
        "label": "voxel_size",
        "kind": 5,
        "importPath": "projects.configs._base_.models.hv_second_secfpn_waymo",
        "description": "projects.configs._base_.models.hv_second_secfpn_waymo",
        "peekOfCode": "voxel_size = [0.08, 0.08, 0.1]\nmodel = dict(\n    type='VoxelNet',\n    voxel_layer=dict(\n        max_num_points=10,\n        point_cloud_range=[-76.8, -51.2, -2, 76.8, 51.2, 4],\n        voxel_size=voxel_size,\n        max_voxels=(80000, 90000)),\n    voxel_encoder=dict(type='HardSimpleVFE', num_features=5),\n    middle_encoder=dict(",
        "detail": "projects.configs._base_.models.hv_second_secfpn_waymo",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "projects.configs._base_.models.hv_second_secfpn_waymo",
        "description": "projects.configs._base_.models.hv_second_secfpn_waymo",
        "peekOfCode": "model = dict(\n    type='VoxelNet',\n    voxel_layer=dict(\n        max_num_points=10,\n        point_cloud_range=[-76.8, -51.2, -2, 76.8, 51.2, 4],\n        voxel_size=voxel_size,\n        max_voxels=(80000, 90000)),\n    voxel_encoder=dict(type='HardSimpleVFE', num_features=5),\n    middle_encoder=dict(\n        type='SparseEncoder',",
        "detail": "projects.configs._base_.models.hv_second_secfpn_waymo",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "projects.configs._base_.models.imvotenet_image",
        "description": "projects.configs._base_.models.imvotenet_image",
        "peekOfCode": "model = dict(\n    type='ImVoteNet',\n    img_backbone=dict(\n        type='ResNet',\n        depth=50,\n        num_stages=4,\n        out_indices=(0, 1, 2, 3),\n        frozen_stages=1,\n        norm_cfg=dict(type='BN', requires_grad=False),\n        norm_eval=True,",
        "detail": "projects.configs._base_.models.imvotenet_image",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "projects.configs._base_.models.mask_rcnn_r50_fpn",
        "description": "projects.configs._base_.models.mask_rcnn_r50_fpn",
        "peekOfCode": "model = dict(\n    type='MaskRCNN',\n    pretrained='torchvision://resnet50',\n    backbone=dict(\n        type='ResNet',\n        depth=50,\n        num_stages=4,\n        out_indices=(0, 1, 2, 3),\n        frozen_stages=1,\n        norm_cfg=dict(type='BN', requires_grad=True),",
        "detail": "projects.configs._base_.models.mask_rcnn_r50_fpn",
        "documentation": {}
    },
    {
        "label": "_base_",
        "kind": 5,
        "importPath": "projects.configs._base_.models.paconv_cuda_ssg",
        "description": "projects.configs._base_.models.paconv_cuda_ssg",
        "peekOfCode": "_base_ = './paconv_ssg.py'\nmodel = dict(\n    backbone=dict(\n        sa_cfg=dict(\n            type='PAConvCUDASAModule',\n            scorenet_cfg=dict(mlp_channels=[8, 16, 16]))))",
        "detail": "projects.configs._base_.models.paconv_cuda_ssg",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "projects.configs._base_.models.paconv_cuda_ssg",
        "description": "projects.configs._base_.models.paconv_cuda_ssg",
        "peekOfCode": "model = dict(\n    backbone=dict(\n        sa_cfg=dict(\n            type='PAConvCUDASAModule',\n            scorenet_cfg=dict(mlp_channels=[8, 16, 16]))))",
        "detail": "projects.configs._base_.models.paconv_cuda_ssg",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "projects.configs._base_.models.paconv_ssg",
        "description": "projects.configs._base_.models.paconv_ssg",
        "peekOfCode": "model = dict(\n    type='EncoderDecoder3D',\n    backbone=dict(\n        type='PointNet2SASSG',\n        in_channels=9,  # [xyz, rgb, normalized_xyz]\n        num_points=(1024, 256, 64, 16),\n        radius=(None, None, None, None),  # use kNN instead of ball query\n        num_samples=(32, 32, 32, 32),\n        sa_channels=((32, 32, 64), (64, 64, 128), (128, 128, 256), (256, 256,\n                                                                    512)),",
        "detail": "projects.configs._base_.models.paconv_ssg",
        "documentation": {}
    },
    {
        "label": "voxel_size",
        "kind": 5,
        "importPath": "projects.configs._base_.models.parta2",
        "description": "projects.configs._base_.models.parta2",
        "peekOfCode": "voxel_size = [0.05, 0.05, 0.1]\npoint_cloud_range = [0, -40, -3, 70.4, 40, 1]\nmodel = dict(\n    type='PartA2',\n    voxel_layer=dict(\n        max_num_points=5,  # max_points_per_voxel\n        point_cloud_range=point_cloud_range,\n        voxel_size=voxel_size,\n        max_voxels=(16000, 40000)  # (training, testing) max_voxels\n    ),",
        "detail": "projects.configs._base_.models.parta2",
        "documentation": {}
    },
    {
        "label": "point_cloud_range",
        "kind": 5,
        "importPath": "projects.configs._base_.models.parta2",
        "description": "projects.configs._base_.models.parta2",
        "peekOfCode": "point_cloud_range = [0, -40, -3, 70.4, 40, 1]\nmodel = dict(\n    type='PartA2',\n    voxel_layer=dict(\n        max_num_points=5,  # max_points_per_voxel\n        point_cloud_range=point_cloud_range,\n        voxel_size=voxel_size,\n        max_voxels=(16000, 40000)  # (training, testing) max_voxels\n    ),\n    voxel_encoder=dict(type='HardSimpleVFE'),",
        "detail": "projects.configs._base_.models.parta2",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "projects.configs._base_.models.parta2",
        "description": "projects.configs._base_.models.parta2",
        "peekOfCode": "model = dict(\n    type='PartA2',\n    voxel_layer=dict(\n        max_num_points=5,  # max_points_per_voxel\n        point_cloud_range=point_cloud_range,\n        voxel_size=voxel_size,\n        max_voxels=(16000, 40000)  # (training, testing) max_voxels\n    ),\n    voxel_encoder=dict(type='HardSimpleVFE'),\n    middle_encoder=dict(",
        "detail": "projects.configs._base_.models.parta2",
        "documentation": {}
    },
    {
        "label": "_base_",
        "kind": 5,
        "importPath": "projects.configs._base_.models.pointnet2_msg",
        "description": "projects.configs._base_.models.pointnet2_msg",
        "peekOfCode": "_base_ = './pointnet2_ssg.py'\n# model settings\nmodel = dict(\n    backbone=dict(\n        _delete_=True,\n        type='PointNet2SAMSG',\n        in_channels=6,  # [xyz, rgb], should be modified with dataset\n        num_points=(1024, 256, 64, 16),\n        radii=((0.05, 0.1), (0.1, 0.2), (0.2, 0.4), (0.4, 0.8)),\n        num_samples=((16, 32), (16, 32), (16, 32), (16, 32)),",
        "detail": "projects.configs._base_.models.pointnet2_msg",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "projects.configs._base_.models.pointnet2_msg",
        "description": "projects.configs._base_.models.pointnet2_msg",
        "peekOfCode": "model = dict(\n    backbone=dict(\n        _delete_=True,\n        type='PointNet2SAMSG',\n        in_channels=6,  # [xyz, rgb], should be modified with dataset\n        num_points=(1024, 256, 64, 16),\n        radii=((0.05, 0.1), (0.1, 0.2), (0.2, 0.4), (0.4, 0.8)),\n        num_samples=((16, 32), (16, 32), (16, 32), (16, 32)),\n        sa_channels=(((16, 16, 32), (32, 32, 64)), ((64, 64, 128), (64, 96,\n                                                                    128)),",
        "detail": "projects.configs._base_.models.pointnet2_msg",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "projects.configs._base_.models.pointnet2_ssg",
        "description": "projects.configs._base_.models.pointnet2_ssg",
        "peekOfCode": "model = dict(\n    type='EncoderDecoder3D',\n    backbone=dict(\n        type='PointNet2SASSG',\n        in_channels=6,  # [xyz, rgb], should be modified with dataset\n        num_points=(1024, 256, 64, 16),\n        radius=(0.1, 0.2, 0.4, 0.8),\n        num_samples=(32, 32, 32, 32),\n        sa_channels=((32, 32, 64), (64, 64, 128), (128, 128, 256), (256, 256,\n                                                                    512)),",
        "detail": "projects.configs._base_.models.pointnet2_ssg",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "projects.configs._base_.models.votenet",
        "description": "projects.configs._base_.models.votenet",
        "peekOfCode": "model = dict(\n    type='VoteNet',\n    backbone=dict(\n        type='PointNet2SASSG',\n        in_channels=4,\n        num_points=(2048, 1024, 512, 256),\n        radius=(0.2, 0.4, 0.8, 1.2),\n        num_samples=(64, 32, 16, 16),\n        sa_channels=((64, 64, 128), (128, 128, 256), (128, 128, 256),\n                     (128, 128, 256)),",
        "detail": "projects.configs._base_.models.votenet",
        "documentation": {}
    },
    {
        "label": "lr",
        "kind": 5,
        "importPath": "projects.configs._base_.schedules.cosine",
        "description": "projects.configs._base_.schedules.cosine",
        "peekOfCode": "lr = 0.003  # max learning rate\noptimizer = dict(\n    type='AdamW',\n    lr=lr,\n    betas=(0.95, 0.99),  # the momentum is change during training\n    weight_decay=0.001)\noptimizer_config = dict(grad_clip=dict(max_norm=10, norm_type=2))\nlr_config = dict(\n    policy='CosineAnnealing',\n    warmup='linear',",
        "detail": "projects.configs._base_.schedules.cosine",
        "documentation": {}
    },
    {
        "label": "optimizer",
        "kind": 5,
        "importPath": "projects.configs._base_.schedules.cosine",
        "description": "projects.configs._base_.schedules.cosine",
        "peekOfCode": "optimizer = dict(\n    type='AdamW',\n    lr=lr,\n    betas=(0.95, 0.99),  # the momentum is change during training\n    weight_decay=0.001)\noptimizer_config = dict(grad_clip=dict(max_norm=10, norm_type=2))\nlr_config = dict(\n    policy='CosineAnnealing',\n    warmup='linear',\n    warmup_iters=1000,",
        "detail": "projects.configs._base_.schedules.cosine",
        "documentation": {}
    },
    {
        "label": "optimizer_config",
        "kind": 5,
        "importPath": "projects.configs._base_.schedules.cosine",
        "description": "projects.configs._base_.schedules.cosine",
        "peekOfCode": "optimizer_config = dict(grad_clip=dict(max_norm=10, norm_type=2))\nlr_config = dict(\n    policy='CosineAnnealing',\n    warmup='linear',\n    warmup_iters=1000,\n    warmup_ratio=1.0 / 10,\n    min_lr_ratio=1e-5)\nmomentum_config = None\nrunner = dict(type='EpochBasedRunner', max_epochs=40)",
        "detail": "projects.configs._base_.schedules.cosine",
        "documentation": {}
    },
    {
        "label": "lr_config",
        "kind": 5,
        "importPath": "projects.configs._base_.schedules.cosine",
        "description": "projects.configs._base_.schedules.cosine",
        "peekOfCode": "lr_config = dict(\n    policy='CosineAnnealing',\n    warmup='linear',\n    warmup_iters=1000,\n    warmup_ratio=1.0 / 10,\n    min_lr_ratio=1e-5)\nmomentum_config = None\nrunner = dict(type='EpochBasedRunner', max_epochs=40)",
        "detail": "projects.configs._base_.schedules.cosine",
        "documentation": {}
    },
    {
        "label": "momentum_config",
        "kind": 5,
        "importPath": "projects.configs._base_.schedules.cosine",
        "description": "projects.configs._base_.schedules.cosine",
        "peekOfCode": "momentum_config = None\nrunner = dict(type='EpochBasedRunner', max_epochs=40)",
        "detail": "projects.configs._base_.schedules.cosine",
        "documentation": {}
    },
    {
        "label": "runner",
        "kind": 5,
        "importPath": "projects.configs._base_.schedules.cosine",
        "description": "projects.configs._base_.schedules.cosine",
        "peekOfCode": "runner = dict(type='EpochBasedRunner', max_epochs=40)",
        "detail": "projects.configs._base_.schedules.cosine",
        "documentation": {}
    },
    {
        "label": "optimizer",
        "kind": 5,
        "importPath": "projects.configs._base_.schedules.cyclic_20e",
        "description": "projects.configs._base_.schedules.cyclic_20e",
        "peekOfCode": "optimizer = dict(type='AdamW', lr=1e-4, weight_decay=0.01)\n# max_norm=10 is better for SECOND\noptimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))\nlr_config = dict(\n    policy='cyclic',\n    target_ratio=(10, 1e-4),\n    cyclic_times=1,\n    step_ratio_up=0.4,\n)\nmomentum_config = dict(",
        "detail": "projects.configs._base_.schedules.cyclic_20e",
        "documentation": {}
    },
    {
        "label": "optimizer_config",
        "kind": 5,
        "importPath": "projects.configs._base_.schedules.cyclic_20e",
        "description": "projects.configs._base_.schedules.cyclic_20e",
        "peekOfCode": "optimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))\nlr_config = dict(\n    policy='cyclic',\n    target_ratio=(10, 1e-4),\n    cyclic_times=1,\n    step_ratio_up=0.4,\n)\nmomentum_config = dict(\n    policy='cyclic',\n    target_ratio=(0.85 / 0.95, 1),",
        "detail": "projects.configs._base_.schedules.cyclic_20e",
        "documentation": {}
    },
    {
        "label": "lr_config",
        "kind": 5,
        "importPath": "projects.configs._base_.schedules.cyclic_20e",
        "description": "projects.configs._base_.schedules.cyclic_20e",
        "peekOfCode": "lr_config = dict(\n    policy='cyclic',\n    target_ratio=(10, 1e-4),\n    cyclic_times=1,\n    step_ratio_up=0.4,\n)\nmomentum_config = dict(\n    policy='cyclic',\n    target_ratio=(0.85 / 0.95, 1),\n    cyclic_times=1,",
        "detail": "projects.configs._base_.schedules.cyclic_20e",
        "documentation": {}
    },
    {
        "label": "momentum_config",
        "kind": 5,
        "importPath": "projects.configs._base_.schedules.cyclic_20e",
        "description": "projects.configs._base_.schedules.cyclic_20e",
        "peekOfCode": "momentum_config = dict(\n    policy='cyclic',\n    target_ratio=(0.85 / 0.95, 1),\n    cyclic_times=1,\n    step_ratio_up=0.4,\n)\n# runtime settings\nrunner = dict(type='EpochBasedRunner', max_epochs=20)",
        "detail": "projects.configs._base_.schedules.cyclic_20e",
        "documentation": {}
    },
    {
        "label": "runner",
        "kind": 5,
        "importPath": "projects.configs._base_.schedules.cyclic_20e",
        "description": "projects.configs._base_.schedules.cyclic_20e",
        "peekOfCode": "runner = dict(type='EpochBasedRunner', max_epochs=20)",
        "detail": "projects.configs._base_.schedules.cyclic_20e",
        "documentation": {}
    },
    {
        "label": "lr",
        "kind": 5,
        "importPath": "projects.configs._base_.schedules.cyclic_40e",
        "description": "projects.configs._base_.schedules.cyclic_40e",
        "peekOfCode": "lr = 0.0018\n# The optimizer follows the setting in SECOND.Pytorch, but here we use\n# the offcial AdamW optimizer implemented by PyTorch.\noptimizer = dict(type='AdamW', lr=lr, betas=(0.95, 0.99), weight_decay=0.01)\noptimizer_config = dict(grad_clip=dict(max_norm=10, norm_type=2))\n# We use cyclic learning rate and momentum schedule following SECOND.Pytorch\n# https://github.com/traveller59/second.pytorch/blob/3aba19c9688274f75ebb5e576f65cfe54773c021/torchplus/train/learning_schedules_fastai.py#L69  # noqa\n# We implement them in mmcv, for more details, please refer to\n# https://github.com/open-mmlab/mmcv/blob/f48241a65aebfe07db122e9db320c31b685dc674/mmcv/runner/hooks/lr_updater.py#L327  # noqa\n# https://github.com/open-mmlab/mmcv/blob/f48241a65aebfe07db122e9db320c31b685dc674/mmcv/runner/hooks/momentum_updater.py#L130  # noqa",
        "detail": "projects.configs._base_.schedules.cyclic_40e",
        "documentation": {}
    },
    {
        "label": "optimizer",
        "kind": 5,
        "importPath": "projects.configs._base_.schedules.cyclic_40e",
        "description": "projects.configs._base_.schedules.cyclic_40e",
        "peekOfCode": "optimizer = dict(type='AdamW', lr=lr, betas=(0.95, 0.99), weight_decay=0.01)\noptimizer_config = dict(grad_clip=dict(max_norm=10, norm_type=2))\n# We use cyclic learning rate and momentum schedule following SECOND.Pytorch\n# https://github.com/traveller59/second.pytorch/blob/3aba19c9688274f75ebb5e576f65cfe54773c021/torchplus/train/learning_schedules_fastai.py#L69  # noqa\n# We implement them in mmcv, for more details, please refer to\n# https://github.com/open-mmlab/mmcv/blob/f48241a65aebfe07db122e9db320c31b685dc674/mmcv/runner/hooks/lr_updater.py#L327  # noqa\n# https://github.com/open-mmlab/mmcv/blob/f48241a65aebfe07db122e9db320c31b685dc674/mmcv/runner/hooks/momentum_updater.py#L130  # noqa\nlr_config = dict(\n    policy='cyclic',\n    target_ratio=(10, 1e-4),",
        "detail": "projects.configs._base_.schedules.cyclic_40e",
        "documentation": {}
    },
    {
        "label": "optimizer_config",
        "kind": 5,
        "importPath": "projects.configs._base_.schedules.cyclic_40e",
        "description": "projects.configs._base_.schedules.cyclic_40e",
        "peekOfCode": "optimizer_config = dict(grad_clip=dict(max_norm=10, norm_type=2))\n# We use cyclic learning rate and momentum schedule following SECOND.Pytorch\n# https://github.com/traveller59/second.pytorch/blob/3aba19c9688274f75ebb5e576f65cfe54773c021/torchplus/train/learning_schedules_fastai.py#L69  # noqa\n# We implement them in mmcv, for more details, please refer to\n# https://github.com/open-mmlab/mmcv/blob/f48241a65aebfe07db122e9db320c31b685dc674/mmcv/runner/hooks/lr_updater.py#L327  # noqa\n# https://github.com/open-mmlab/mmcv/blob/f48241a65aebfe07db122e9db320c31b685dc674/mmcv/runner/hooks/momentum_updater.py#L130  # noqa\nlr_config = dict(\n    policy='cyclic',\n    target_ratio=(10, 1e-4),\n    cyclic_times=1,",
        "detail": "projects.configs._base_.schedules.cyclic_40e",
        "documentation": {}
    },
    {
        "label": "lr_config",
        "kind": 5,
        "importPath": "projects.configs._base_.schedules.cyclic_40e",
        "description": "projects.configs._base_.schedules.cyclic_40e",
        "peekOfCode": "lr_config = dict(\n    policy='cyclic',\n    target_ratio=(10, 1e-4),\n    cyclic_times=1,\n    step_ratio_up=0.4,\n)\nmomentum_config = dict(\n    policy='cyclic',\n    target_ratio=(0.85 / 0.95, 1),\n    cyclic_times=1,",
        "detail": "projects.configs._base_.schedules.cyclic_40e",
        "documentation": {}
    },
    {
        "label": "momentum_config",
        "kind": 5,
        "importPath": "projects.configs._base_.schedules.cyclic_40e",
        "description": "projects.configs._base_.schedules.cyclic_40e",
        "peekOfCode": "momentum_config = dict(\n    policy='cyclic',\n    target_ratio=(0.85 / 0.95, 1),\n    cyclic_times=1,\n    step_ratio_up=0.4,\n)\n# Although the max_epochs is 40, this schedule is usually used we\n# RepeatDataset with repeat ratio N, thus the actual max epoch\n# number could be Nx40\nrunner = dict(type='EpochBasedRunner', max_epochs=40)",
        "detail": "projects.configs._base_.schedules.cyclic_40e",
        "documentation": {}
    },
    {
        "label": "runner",
        "kind": 5,
        "importPath": "projects.configs._base_.schedules.cyclic_40e",
        "description": "projects.configs._base_.schedules.cyclic_40e",
        "peekOfCode": "runner = dict(type='EpochBasedRunner', max_epochs=40)",
        "detail": "projects.configs._base_.schedules.cyclic_40e",
        "documentation": {}
    },
    {
        "label": "optimizer",
        "kind": 5,
        "importPath": "projects.configs._base_.schedules.mmdet_schedule_1x",
        "description": "projects.configs._base_.schedules.mmdet_schedule_1x",
        "peekOfCode": "optimizer = dict(type='SGD', lr=0.02, momentum=0.9, weight_decay=0.0001)\noptimizer_config = dict(grad_clip=None)\n# learning policy\nlr_config = dict(\n    policy='step',\n    warmup='linear',\n    warmup_iters=500,\n    warmup_ratio=0.001,\n    step=[8, 11])\nrunner = dict(type='EpochBasedRunner', max_epochs=12)",
        "detail": "projects.configs._base_.schedules.mmdet_schedule_1x",
        "documentation": {}
    },
    {
        "label": "optimizer_config",
        "kind": 5,
        "importPath": "projects.configs._base_.schedules.mmdet_schedule_1x",
        "description": "projects.configs._base_.schedules.mmdet_schedule_1x",
        "peekOfCode": "optimizer_config = dict(grad_clip=None)\n# learning policy\nlr_config = dict(\n    policy='step',\n    warmup='linear',\n    warmup_iters=500,\n    warmup_ratio=0.001,\n    step=[8, 11])\nrunner = dict(type='EpochBasedRunner', max_epochs=12)",
        "detail": "projects.configs._base_.schedules.mmdet_schedule_1x",
        "documentation": {}
    },
    {
        "label": "lr_config",
        "kind": 5,
        "importPath": "projects.configs._base_.schedules.mmdet_schedule_1x",
        "description": "projects.configs._base_.schedules.mmdet_schedule_1x",
        "peekOfCode": "lr_config = dict(\n    policy='step',\n    warmup='linear',\n    warmup_iters=500,\n    warmup_ratio=0.001,\n    step=[8, 11])\nrunner = dict(type='EpochBasedRunner', max_epochs=12)",
        "detail": "projects.configs._base_.schedules.mmdet_schedule_1x",
        "documentation": {}
    },
    {
        "label": "runner",
        "kind": 5,
        "importPath": "projects.configs._base_.schedules.mmdet_schedule_1x",
        "description": "projects.configs._base_.schedules.mmdet_schedule_1x",
        "peekOfCode": "runner = dict(type='EpochBasedRunner', max_epochs=12)",
        "detail": "projects.configs._base_.schedules.mmdet_schedule_1x",
        "documentation": {}
    },
    {
        "label": "optimizer",
        "kind": 5,
        "importPath": "projects.configs._base_.schedules.schedule_2x",
        "description": "projects.configs._base_.schedules.schedule_2x",
        "peekOfCode": "optimizer = dict(type='AdamW', lr=0.001, weight_decay=0.01)\n# max_norm=10 is better for SECOND\noptimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))\nlr_config = dict(\n    policy='step',\n    warmup='linear',\n    warmup_iters=1000,\n    warmup_ratio=1.0 / 1000,\n    step=[20, 23])\nmomentum_config = None",
        "detail": "projects.configs._base_.schedules.schedule_2x",
        "documentation": {}
    },
    {
        "label": "optimizer_config",
        "kind": 5,
        "importPath": "projects.configs._base_.schedules.schedule_2x",
        "description": "projects.configs._base_.schedules.schedule_2x",
        "peekOfCode": "optimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))\nlr_config = dict(\n    policy='step',\n    warmup='linear',\n    warmup_iters=1000,\n    warmup_ratio=1.0 / 1000,\n    step=[20, 23])\nmomentum_config = None\n# runtime settings\nrunner = dict(type='EpochBasedRunner', max_epochs=24)",
        "detail": "projects.configs._base_.schedules.schedule_2x",
        "documentation": {}
    },
    {
        "label": "lr_config",
        "kind": 5,
        "importPath": "projects.configs._base_.schedules.schedule_2x",
        "description": "projects.configs._base_.schedules.schedule_2x",
        "peekOfCode": "lr_config = dict(\n    policy='step',\n    warmup='linear',\n    warmup_iters=1000,\n    warmup_ratio=1.0 / 1000,\n    step=[20, 23])\nmomentum_config = None\n# runtime settings\nrunner = dict(type='EpochBasedRunner', max_epochs=24)",
        "detail": "projects.configs._base_.schedules.schedule_2x",
        "documentation": {}
    },
    {
        "label": "momentum_config",
        "kind": 5,
        "importPath": "projects.configs._base_.schedules.schedule_2x",
        "description": "projects.configs._base_.schedules.schedule_2x",
        "peekOfCode": "momentum_config = None\n# runtime settings\nrunner = dict(type='EpochBasedRunner', max_epochs=24)",
        "detail": "projects.configs._base_.schedules.schedule_2x",
        "documentation": {}
    },
    {
        "label": "runner",
        "kind": 5,
        "importPath": "projects.configs._base_.schedules.schedule_2x",
        "description": "projects.configs._base_.schedules.schedule_2x",
        "peekOfCode": "runner = dict(type='EpochBasedRunner', max_epochs=24)",
        "detail": "projects.configs._base_.schedules.schedule_2x",
        "documentation": {}
    },
    {
        "label": "lr",
        "kind": 5,
        "importPath": "projects.configs._base_.schedules.schedule_3x",
        "description": "projects.configs._base_.schedules.schedule_3x",
        "peekOfCode": "lr = 0.008  # max learning rate\noptimizer = dict(type='AdamW', lr=lr, weight_decay=0.01)\noptimizer_config = dict(grad_clip=dict(max_norm=10, norm_type=2))\nlr_config = dict(policy='step', warmup=None, step=[24, 32])\n# runtime settings\nrunner = dict(type='EpochBasedRunner', max_epochs=36)",
        "detail": "projects.configs._base_.schedules.schedule_3x",
        "documentation": {}
    },
    {
        "label": "optimizer",
        "kind": 5,
        "importPath": "projects.configs._base_.schedules.schedule_3x",
        "description": "projects.configs._base_.schedules.schedule_3x",
        "peekOfCode": "optimizer = dict(type='AdamW', lr=lr, weight_decay=0.01)\noptimizer_config = dict(grad_clip=dict(max_norm=10, norm_type=2))\nlr_config = dict(policy='step', warmup=None, step=[24, 32])\n# runtime settings\nrunner = dict(type='EpochBasedRunner', max_epochs=36)",
        "detail": "projects.configs._base_.schedules.schedule_3x",
        "documentation": {}
    },
    {
        "label": "optimizer_config",
        "kind": 5,
        "importPath": "projects.configs._base_.schedules.schedule_3x",
        "description": "projects.configs._base_.schedules.schedule_3x",
        "peekOfCode": "optimizer_config = dict(grad_clip=dict(max_norm=10, norm_type=2))\nlr_config = dict(policy='step', warmup=None, step=[24, 32])\n# runtime settings\nrunner = dict(type='EpochBasedRunner', max_epochs=36)",
        "detail": "projects.configs._base_.schedules.schedule_3x",
        "documentation": {}
    },
    {
        "label": "lr_config",
        "kind": 5,
        "importPath": "projects.configs._base_.schedules.schedule_3x",
        "description": "projects.configs._base_.schedules.schedule_3x",
        "peekOfCode": "lr_config = dict(policy='step', warmup=None, step=[24, 32])\n# runtime settings\nrunner = dict(type='EpochBasedRunner', max_epochs=36)",
        "detail": "projects.configs._base_.schedules.schedule_3x",
        "documentation": {}
    },
    {
        "label": "runner",
        "kind": 5,
        "importPath": "projects.configs._base_.schedules.schedule_3x",
        "description": "projects.configs._base_.schedules.schedule_3x",
        "peekOfCode": "runner = dict(type='EpochBasedRunner', max_epochs=36)",
        "detail": "projects.configs._base_.schedules.schedule_3x",
        "documentation": {}
    },
    {
        "label": "optimizer",
        "kind": 5,
        "importPath": "projects.configs._base_.schedules.seg_cosine_150e",
        "description": "projects.configs._base_.schedules.seg_cosine_150e",
        "peekOfCode": "optimizer = dict(type='SGD', lr=0.2, weight_decay=0.0001, momentum=0.9)\noptimizer_config = dict(grad_clip=None)\nlr_config = dict(policy='CosineAnnealing', warmup=None, min_lr=0.002)\nmomentum_config = None\n# runtime settings\nrunner = dict(type='EpochBasedRunner', max_epochs=150)",
        "detail": "projects.configs._base_.schedules.seg_cosine_150e",
        "documentation": {}
    },
    {
        "label": "optimizer_config",
        "kind": 5,
        "importPath": "projects.configs._base_.schedules.seg_cosine_150e",
        "description": "projects.configs._base_.schedules.seg_cosine_150e",
        "peekOfCode": "optimizer_config = dict(grad_clip=None)\nlr_config = dict(policy='CosineAnnealing', warmup=None, min_lr=0.002)\nmomentum_config = None\n# runtime settings\nrunner = dict(type='EpochBasedRunner', max_epochs=150)",
        "detail": "projects.configs._base_.schedules.seg_cosine_150e",
        "documentation": {}
    },
    {
        "label": "lr_config",
        "kind": 5,
        "importPath": "projects.configs._base_.schedules.seg_cosine_150e",
        "description": "projects.configs._base_.schedules.seg_cosine_150e",
        "peekOfCode": "lr_config = dict(policy='CosineAnnealing', warmup=None, min_lr=0.002)\nmomentum_config = None\n# runtime settings\nrunner = dict(type='EpochBasedRunner', max_epochs=150)",
        "detail": "projects.configs._base_.schedules.seg_cosine_150e",
        "documentation": {}
    },
    {
        "label": "momentum_config",
        "kind": 5,
        "importPath": "projects.configs._base_.schedules.seg_cosine_150e",
        "description": "projects.configs._base_.schedules.seg_cosine_150e",
        "peekOfCode": "momentum_config = None\n# runtime settings\nrunner = dict(type='EpochBasedRunner', max_epochs=150)",
        "detail": "projects.configs._base_.schedules.seg_cosine_150e",
        "documentation": {}
    },
    {
        "label": "runner",
        "kind": 5,
        "importPath": "projects.configs._base_.schedules.seg_cosine_150e",
        "description": "projects.configs._base_.schedules.seg_cosine_150e",
        "peekOfCode": "runner = dict(type='EpochBasedRunner', max_epochs=150)",
        "detail": "projects.configs._base_.schedules.seg_cosine_150e",
        "documentation": {}
    },
    {
        "label": "optimizer",
        "kind": 5,
        "importPath": "projects.configs._base_.schedules.seg_cosine_200e",
        "description": "projects.configs._base_.schedules.seg_cosine_200e",
        "peekOfCode": "optimizer = dict(type='Adam', lr=0.001, weight_decay=0.01)\noptimizer_config = dict(grad_clip=None)\nlr_config = dict(policy='CosineAnnealing', warmup=None, min_lr=1e-5)\nmomentum_config = None\n# runtime settings\nrunner = dict(type='EpochBasedRunner', max_epochs=200)",
        "detail": "projects.configs._base_.schedules.seg_cosine_200e",
        "documentation": {}
    },
    {
        "label": "optimizer_config",
        "kind": 5,
        "importPath": "projects.configs._base_.schedules.seg_cosine_200e",
        "description": "projects.configs._base_.schedules.seg_cosine_200e",
        "peekOfCode": "optimizer_config = dict(grad_clip=None)\nlr_config = dict(policy='CosineAnnealing', warmup=None, min_lr=1e-5)\nmomentum_config = None\n# runtime settings\nrunner = dict(type='EpochBasedRunner', max_epochs=200)",
        "detail": "projects.configs._base_.schedules.seg_cosine_200e",
        "documentation": {}
    },
    {
        "label": "lr_config",
        "kind": 5,
        "importPath": "projects.configs._base_.schedules.seg_cosine_200e",
        "description": "projects.configs._base_.schedules.seg_cosine_200e",
        "peekOfCode": "lr_config = dict(policy='CosineAnnealing', warmup=None, min_lr=1e-5)\nmomentum_config = None\n# runtime settings\nrunner = dict(type='EpochBasedRunner', max_epochs=200)",
        "detail": "projects.configs._base_.schedules.seg_cosine_200e",
        "documentation": {}
    },
    {
        "label": "momentum_config",
        "kind": 5,
        "importPath": "projects.configs._base_.schedules.seg_cosine_200e",
        "description": "projects.configs._base_.schedules.seg_cosine_200e",
        "peekOfCode": "momentum_config = None\n# runtime settings\nrunner = dict(type='EpochBasedRunner', max_epochs=200)",
        "detail": "projects.configs._base_.schedules.seg_cosine_200e",
        "documentation": {}
    },
    {
        "label": "runner",
        "kind": 5,
        "importPath": "projects.configs._base_.schedules.seg_cosine_200e",
        "description": "projects.configs._base_.schedules.seg_cosine_200e",
        "peekOfCode": "runner = dict(type='EpochBasedRunner', max_epochs=200)",
        "detail": "projects.configs._base_.schedules.seg_cosine_200e",
        "documentation": {}
    },
    {
        "label": "optimizer",
        "kind": 5,
        "importPath": "projects.configs._base_.schedules.seg_cosine_50e",
        "description": "projects.configs._base_.schedules.seg_cosine_50e",
        "peekOfCode": "optimizer = dict(type='Adam', lr=0.001, weight_decay=0.001)\noptimizer_config = dict(grad_clip=None)\nlr_config = dict(policy='CosineAnnealing', warmup=None, min_lr=1e-5)\nmomentum_config = None\n# runtime settings\nrunner = dict(type='EpochBasedRunner', max_epochs=50)",
        "detail": "projects.configs._base_.schedules.seg_cosine_50e",
        "documentation": {}
    },
    {
        "label": "optimizer_config",
        "kind": 5,
        "importPath": "projects.configs._base_.schedules.seg_cosine_50e",
        "description": "projects.configs._base_.schedules.seg_cosine_50e",
        "peekOfCode": "optimizer_config = dict(grad_clip=None)\nlr_config = dict(policy='CosineAnnealing', warmup=None, min_lr=1e-5)\nmomentum_config = None\n# runtime settings\nrunner = dict(type='EpochBasedRunner', max_epochs=50)",
        "detail": "projects.configs._base_.schedules.seg_cosine_50e",
        "documentation": {}
    },
    {
        "label": "lr_config",
        "kind": 5,
        "importPath": "projects.configs._base_.schedules.seg_cosine_50e",
        "description": "projects.configs._base_.schedules.seg_cosine_50e",
        "peekOfCode": "lr_config = dict(policy='CosineAnnealing', warmup=None, min_lr=1e-5)\nmomentum_config = None\n# runtime settings\nrunner = dict(type='EpochBasedRunner', max_epochs=50)",
        "detail": "projects.configs._base_.schedules.seg_cosine_50e",
        "documentation": {}
    },
    {
        "label": "momentum_config",
        "kind": 5,
        "importPath": "projects.configs._base_.schedules.seg_cosine_50e",
        "description": "projects.configs._base_.schedules.seg_cosine_50e",
        "peekOfCode": "momentum_config = None\n# runtime settings\nrunner = dict(type='EpochBasedRunner', max_epochs=50)",
        "detail": "projects.configs._base_.schedules.seg_cosine_50e",
        "documentation": {}
    },
    {
        "label": "runner",
        "kind": 5,
        "importPath": "projects.configs._base_.schedules.seg_cosine_50e",
        "description": "projects.configs._base_.schedules.seg_cosine_50e",
        "peekOfCode": "runner = dict(type='EpochBasedRunner', max_epochs=50)",
        "detail": "projects.configs._base_.schedules.seg_cosine_50e",
        "documentation": {}
    },
    {
        "label": "checkpoint_config",
        "kind": 5,
        "importPath": "projects.configs._base_.default_runtime",
        "description": "projects.configs._base_.default_runtime",
        "peekOfCode": "checkpoint_config = dict(interval=1)\n# yapf:disable push\n# By default we use textlogger hook and tensorboard\n# For more loggers see\n# https://mmcv.readthedocs.io/en/latest/api.html#mmcv.runner.LoggerHook\nlog_config = dict(\n    interval=50,\n    hooks=[\n        dict(type='TextLoggerHook'),\n        dict(type='TensorboardLoggerHook')",
        "detail": "projects.configs._base_.default_runtime",
        "documentation": {}
    },
    {
        "label": "log_config",
        "kind": 5,
        "importPath": "projects.configs._base_.default_runtime",
        "description": "projects.configs._base_.default_runtime",
        "peekOfCode": "log_config = dict(\n    interval=50,\n    hooks=[\n        dict(type='TextLoggerHook'),\n        dict(type='TensorboardLoggerHook')\n    ])\n# yapf:enable\ndist_params = dict(backend='nccl')\nlog_level = 'INFO'\nwork_dir = None",
        "detail": "projects.configs._base_.default_runtime",
        "documentation": {}
    },
    {
        "label": "dist_params",
        "kind": 5,
        "importPath": "projects.configs._base_.default_runtime",
        "description": "projects.configs._base_.default_runtime",
        "peekOfCode": "dist_params = dict(backend='nccl')\nlog_level = 'INFO'\nwork_dir = None\nload_from = None\nresume_from = None\nworkflow = [('train', 1)]",
        "detail": "projects.configs._base_.default_runtime",
        "documentation": {}
    },
    {
        "label": "log_level",
        "kind": 5,
        "importPath": "projects.configs._base_.default_runtime",
        "description": "projects.configs._base_.default_runtime",
        "peekOfCode": "log_level = 'INFO'\nwork_dir = None\nload_from = None\nresume_from = None\nworkflow = [('train', 1)]",
        "detail": "projects.configs._base_.default_runtime",
        "documentation": {}
    },
    {
        "label": "work_dir",
        "kind": 5,
        "importPath": "projects.configs._base_.default_runtime",
        "description": "projects.configs._base_.default_runtime",
        "peekOfCode": "work_dir = None\nload_from = None\nresume_from = None\nworkflow = [('train', 1)]",
        "detail": "projects.configs._base_.default_runtime",
        "documentation": {}
    },
    {
        "label": "load_from",
        "kind": 5,
        "importPath": "projects.configs._base_.default_runtime",
        "description": "projects.configs._base_.default_runtime",
        "peekOfCode": "load_from = None\nresume_from = None\nworkflow = [('train', 1)]",
        "detail": "projects.configs._base_.default_runtime",
        "documentation": {}
    },
    {
        "label": "resume_from",
        "kind": 5,
        "importPath": "projects.configs._base_.default_runtime",
        "description": "projects.configs._base_.default_runtime",
        "peekOfCode": "resume_from = None\nworkflow = [('train', 1)]",
        "detail": "projects.configs._base_.default_runtime",
        "documentation": {}
    },
    {
        "label": "workflow",
        "kind": 5,
        "importPath": "projects.configs._base_.default_runtime",
        "description": "projects.configs._base_.default_runtime",
        "peekOfCode": "workflow = [('train', 1)]",
        "detail": "projects.configs._base_.default_runtime",
        "documentation": {}
    },
    {
        "label": "_base_",
        "kind": 5,
        "importPath": "projects.configs.bevformer.bevformer_base",
        "description": "projects.configs.bevformer.bevformer_base",
        "peekOfCode": "_base_ = [\n    '../datasets/custom_nus-3d.py',\n    '../_base_/default_runtime.py'\n]\n#\nplugin = True\nplugin_dir = 'projects/mmdet3d_plugin/'\n# If point cloud range is changed, the models should also change their point\n# cloud range accordingly\npoint_cloud_range = [-51.2, -51.2, -5.0, 51.2, 51.2, 3.0]",
        "detail": "projects.configs.bevformer.bevformer_base",
        "documentation": {}
    },
    {
        "label": "plugin",
        "kind": 5,
        "importPath": "projects.configs.bevformer.bevformer_base",
        "description": "projects.configs.bevformer.bevformer_base",
        "peekOfCode": "plugin = True\nplugin_dir = 'projects/mmdet3d_plugin/'\n# If point cloud range is changed, the models should also change their point\n# cloud range accordingly\npoint_cloud_range = [-51.2, -51.2, -5.0, 51.2, 51.2, 3.0]\nvoxel_size = [0.2, 0.2, 8]\nimg_norm_cfg = dict(\n    mean=[103.530, 116.280, 123.675], std=[1.0, 1.0, 1.0], to_rgb=False)\n# For nuScenes we usually do 10-class detection\nclass_names = [",
        "detail": "projects.configs.bevformer.bevformer_base",
        "documentation": {}
    },
    {
        "label": "plugin_dir",
        "kind": 5,
        "importPath": "projects.configs.bevformer.bevformer_base",
        "description": "projects.configs.bevformer.bevformer_base",
        "peekOfCode": "plugin_dir = 'projects/mmdet3d_plugin/'\n# If point cloud range is changed, the models should also change their point\n# cloud range accordingly\npoint_cloud_range = [-51.2, -51.2, -5.0, 51.2, 51.2, 3.0]\nvoxel_size = [0.2, 0.2, 8]\nimg_norm_cfg = dict(\n    mean=[103.530, 116.280, 123.675], std=[1.0, 1.0, 1.0], to_rgb=False)\n# For nuScenes we usually do 10-class detection\nclass_names = [\n    'car', 'truck', 'construction_vehicle', 'bus', 'trailer', 'barrier',",
        "detail": "projects.configs.bevformer.bevformer_base",
        "documentation": {}
    },
    {
        "label": "point_cloud_range",
        "kind": 5,
        "importPath": "projects.configs.bevformer.bevformer_base",
        "description": "projects.configs.bevformer.bevformer_base",
        "peekOfCode": "point_cloud_range = [-51.2, -51.2, -5.0, 51.2, 51.2, 3.0]\nvoxel_size = [0.2, 0.2, 8]\nimg_norm_cfg = dict(\n    mean=[103.530, 116.280, 123.675], std=[1.0, 1.0, 1.0], to_rgb=False)\n# For nuScenes we usually do 10-class detection\nclass_names = [\n    'car', 'truck', 'construction_vehicle', 'bus', 'trailer', 'barrier',\n    'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone'\n]\ninput_modality = dict(",
        "detail": "projects.configs.bevformer.bevformer_base",
        "documentation": {}
    },
    {
        "label": "voxel_size",
        "kind": 5,
        "importPath": "projects.configs.bevformer.bevformer_base",
        "description": "projects.configs.bevformer.bevformer_base",
        "peekOfCode": "voxel_size = [0.2, 0.2, 8]\nimg_norm_cfg = dict(\n    mean=[103.530, 116.280, 123.675], std=[1.0, 1.0, 1.0], to_rgb=False)\n# For nuScenes we usually do 10-class detection\nclass_names = [\n    'car', 'truck', 'construction_vehicle', 'bus', 'trailer', 'barrier',\n    'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone'\n]\ninput_modality = dict(\n    use_lidar=False,",
        "detail": "projects.configs.bevformer.bevformer_base",
        "documentation": {}
    },
    {
        "label": "img_norm_cfg",
        "kind": 5,
        "importPath": "projects.configs.bevformer.bevformer_base",
        "description": "projects.configs.bevformer.bevformer_base",
        "peekOfCode": "img_norm_cfg = dict(\n    mean=[103.530, 116.280, 123.675], std=[1.0, 1.0, 1.0], to_rgb=False)\n# For nuScenes we usually do 10-class detection\nclass_names = [\n    'car', 'truck', 'construction_vehicle', 'bus', 'trailer', 'barrier',\n    'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone'\n]\ninput_modality = dict(\n    use_lidar=False,\n    use_camera=True,",
        "detail": "projects.configs.bevformer.bevformer_base",
        "documentation": {}
    },
    {
        "label": "class_names",
        "kind": 5,
        "importPath": "projects.configs.bevformer.bevformer_base",
        "description": "projects.configs.bevformer.bevformer_base",
        "peekOfCode": "class_names = [\n    'car', 'truck', 'construction_vehicle', 'bus', 'trailer', 'barrier',\n    'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone'\n]\ninput_modality = dict(\n    use_lidar=False,\n    use_camera=True,\n    use_radar=False,\n    use_map=False,\n    use_external=True)",
        "detail": "projects.configs.bevformer.bevformer_base",
        "documentation": {}
    },
    {
        "label": "input_modality",
        "kind": 5,
        "importPath": "projects.configs.bevformer.bevformer_base",
        "description": "projects.configs.bevformer.bevformer_base",
        "peekOfCode": "input_modality = dict(\n    use_lidar=False,\n    use_camera=True,\n    use_radar=False,\n    use_map=False,\n    use_external=True)\n_dim_ = 256\n_pos_dim_ = _dim_//2\n_ffn_dim_ = _dim_*2\n_num_levels_ = 4",
        "detail": "projects.configs.bevformer.bevformer_base",
        "documentation": {}
    },
    {
        "label": "_dim_",
        "kind": 5,
        "importPath": "projects.configs.bevformer.bevformer_base",
        "description": "projects.configs.bevformer.bevformer_base",
        "peekOfCode": "_dim_ = 256\n_pos_dim_ = _dim_//2\n_ffn_dim_ = _dim_*2\n_num_levels_ = 4\nbev_h_ = 200\nbev_w_ = 200\nqueue_length = 4 # each sequence contains `queue_length` frames.\nmodel = dict(\n    type='BEVFormer',\n    use_grid_mask=True,",
        "detail": "projects.configs.bevformer.bevformer_base",
        "documentation": {}
    },
    {
        "label": "_pos_dim_",
        "kind": 5,
        "importPath": "projects.configs.bevformer.bevformer_base",
        "description": "projects.configs.bevformer.bevformer_base",
        "peekOfCode": "_pos_dim_ = _dim_//2\n_ffn_dim_ = _dim_*2\n_num_levels_ = 4\nbev_h_ = 200\nbev_w_ = 200\nqueue_length = 4 # each sequence contains `queue_length` frames.\nmodel = dict(\n    type='BEVFormer',\n    use_grid_mask=True,\n    video_test_mode=True,",
        "detail": "projects.configs.bevformer.bevformer_base",
        "documentation": {}
    },
    {
        "label": "_ffn_dim_",
        "kind": 5,
        "importPath": "projects.configs.bevformer.bevformer_base",
        "description": "projects.configs.bevformer.bevformer_base",
        "peekOfCode": "_ffn_dim_ = _dim_*2\n_num_levels_ = 4\nbev_h_ = 200\nbev_w_ = 200\nqueue_length = 4 # each sequence contains `queue_length` frames.\nmodel = dict(\n    type='BEVFormer',\n    use_grid_mask=True,\n    video_test_mode=True,\n    img_backbone=dict(",
        "detail": "projects.configs.bevformer.bevformer_base",
        "documentation": {}
    },
    {
        "label": "_num_levels_",
        "kind": 5,
        "importPath": "projects.configs.bevformer.bevformer_base",
        "description": "projects.configs.bevformer.bevformer_base",
        "peekOfCode": "_num_levels_ = 4\nbev_h_ = 200\nbev_w_ = 200\nqueue_length = 4 # each sequence contains `queue_length` frames.\nmodel = dict(\n    type='BEVFormer',\n    use_grid_mask=True,\n    video_test_mode=True,\n    img_backbone=dict(\n        type='ResNet',",
        "detail": "projects.configs.bevformer.bevformer_base",
        "documentation": {}
    },
    {
        "label": "bev_h_",
        "kind": 5,
        "importPath": "projects.configs.bevformer.bevformer_base",
        "description": "projects.configs.bevformer.bevformer_base",
        "peekOfCode": "bev_h_ = 200\nbev_w_ = 200\nqueue_length = 4 # each sequence contains `queue_length` frames.\nmodel = dict(\n    type='BEVFormer',\n    use_grid_mask=True,\n    video_test_mode=True,\n    img_backbone=dict(\n        type='ResNet',\n        depth=101,",
        "detail": "projects.configs.bevformer.bevformer_base",
        "documentation": {}
    },
    {
        "label": "bev_w_",
        "kind": 5,
        "importPath": "projects.configs.bevformer.bevformer_base",
        "description": "projects.configs.bevformer.bevformer_base",
        "peekOfCode": "bev_w_ = 200\nqueue_length = 4 # each sequence contains `queue_length` frames.\nmodel = dict(\n    type='BEVFormer',\n    use_grid_mask=True,\n    video_test_mode=True,\n    img_backbone=dict(\n        type='ResNet',\n        depth=101,\n        num_stages=4,",
        "detail": "projects.configs.bevformer.bevformer_base",
        "documentation": {}
    },
    {
        "label": "queue_length",
        "kind": 5,
        "importPath": "projects.configs.bevformer.bevformer_base",
        "description": "projects.configs.bevformer.bevformer_base",
        "peekOfCode": "queue_length = 4 # each sequence contains `queue_length` frames.\nmodel = dict(\n    type='BEVFormer',\n    use_grid_mask=True,\n    video_test_mode=True,\n    img_backbone=dict(\n        type='ResNet',\n        depth=101,\n        num_stages=4,\n        out_indices=(1, 2, 3),",
        "detail": "projects.configs.bevformer.bevformer_base",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "projects.configs.bevformer.bevformer_base",
        "description": "projects.configs.bevformer.bevformer_base",
        "peekOfCode": "model = dict(\n    type='BEVFormer',\n    use_grid_mask=True,\n    video_test_mode=True,\n    img_backbone=dict(\n        type='ResNet',\n        depth=101,\n        num_stages=4,\n        out_indices=(1, 2, 3),\n        frozen_stages=1,",
        "detail": "projects.configs.bevformer.bevformer_base",
        "documentation": {}
    },
    {
        "label": "dataset_type",
        "kind": 5,
        "importPath": "projects.configs.bevformer.bevformer_base",
        "description": "projects.configs.bevformer.bevformer_base",
        "peekOfCode": "dataset_type = 'CustomNuScenesDataset'\ndata_root = 'data/nuscenes/'\nfile_client_args = dict(backend='disk')\ntrain_pipeline = [\n    dict(type='LoadMultiViewImageFromFiles', to_float32=True),\n    dict(type='PhotoMetricDistortionMultiViewImage'),\n    dict(type='LoadAnnotations3D', with_bbox_3d=True, with_label_3d=True, with_attr_label=False),\n    dict(type='ObjectRangeFilter', point_cloud_range=point_cloud_range),\n    dict(type='ObjectNameFilter', classes=class_names),\n    dict(type='NormalizeMultiviewImage', **img_norm_cfg),",
        "detail": "projects.configs.bevformer.bevformer_base",
        "documentation": {}
    },
    {
        "label": "data_root",
        "kind": 5,
        "importPath": "projects.configs.bevformer.bevformer_base",
        "description": "projects.configs.bevformer.bevformer_base",
        "peekOfCode": "data_root = 'data/nuscenes/'\nfile_client_args = dict(backend='disk')\ntrain_pipeline = [\n    dict(type='LoadMultiViewImageFromFiles', to_float32=True),\n    dict(type='PhotoMetricDistortionMultiViewImage'),\n    dict(type='LoadAnnotations3D', with_bbox_3d=True, with_label_3d=True, with_attr_label=False),\n    dict(type='ObjectRangeFilter', point_cloud_range=point_cloud_range),\n    dict(type='ObjectNameFilter', classes=class_names),\n    dict(type='NormalizeMultiviewImage', **img_norm_cfg),\n    dict(type='PadMultiViewImage', size_divisor=32),",
        "detail": "projects.configs.bevformer.bevformer_base",
        "documentation": {}
    },
    {
        "label": "file_client_args",
        "kind": 5,
        "importPath": "projects.configs.bevformer.bevformer_base",
        "description": "projects.configs.bevformer.bevformer_base",
        "peekOfCode": "file_client_args = dict(backend='disk')\ntrain_pipeline = [\n    dict(type='LoadMultiViewImageFromFiles', to_float32=True),\n    dict(type='PhotoMetricDistortionMultiViewImage'),\n    dict(type='LoadAnnotations3D', with_bbox_3d=True, with_label_3d=True, with_attr_label=False),\n    dict(type='ObjectRangeFilter', point_cloud_range=point_cloud_range),\n    dict(type='ObjectNameFilter', classes=class_names),\n    dict(type='NormalizeMultiviewImage', **img_norm_cfg),\n    dict(type='PadMultiViewImage', size_divisor=32),\n    dict(type='DefaultFormatBundle3D', class_names=class_names),",
        "detail": "projects.configs.bevformer.bevformer_base",
        "documentation": {}
    },
    {
        "label": "train_pipeline",
        "kind": 5,
        "importPath": "projects.configs.bevformer.bevformer_base",
        "description": "projects.configs.bevformer.bevformer_base",
        "peekOfCode": "train_pipeline = [\n    dict(type='LoadMultiViewImageFromFiles', to_float32=True),\n    dict(type='PhotoMetricDistortionMultiViewImage'),\n    dict(type='LoadAnnotations3D', with_bbox_3d=True, with_label_3d=True, with_attr_label=False),\n    dict(type='ObjectRangeFilter', point_cloud_range=point_cloud_range),\n    dict(type='ObjectNameFilter', classes=class_names),\n    dict(type='NormalizeMultiviewImage', **img_norm_cfg),\n    dict(type='PadMultiViewImage', size_divisor=32),\n    dict(type='DefaultFormatBundle3D', class_names=class_names),\n    dict(type='CustomCollect3D', keys=['gt_bboxes_3d', 'gt_labels_3d', 'img'])",
        "detail": "projects.configs.bevformer.bevformer_base",
        "documentation": {}
    },
    {
        "label": "test_pipeline",
        "kind": 5,
        "importPath": "projects.configs.bevformer.bevformer_base",
        "description": "projects.configs.bevformer.bevformer_base",
        "peekOfCode": "test_pipeline = [\n    dict(type='LoadMultiViewImageFromFiles', to_float32=True),\n    dict(type='NormalizeMultiviewImage', **img_norm_cfg),\n    dict(type='PadMultiViewImage', size_divisor=32),\n    dict(\n        type='MultiScaleFlipAug3D',\n        img_scale=(1600, 900),\n        pts_scale_ratio=1,\n        flip=False,\n        transforms=[",
        "detail": "projects.configs.bevformer.bevformer_base",
        "documentation": {}
    },
    {
        "label": "data",
        "kind": 5,
        "importPath": "projects.configs.bevformer.bevformer_base",
        "description": "projects.configs.bevformer.bevformer_base",
        "peekOfCode": "data = dict(\n    samples_per_gpu=1,\n    workers_per_gpu=4,\n    train=dict(\n        type=dataset_type,\n        data_root=data_root,\n        ann_file=data_root + 'nuscenes_infos_temporal_train.pkl',\n        pipeline=train_pipeline,\n        classes=class_names,\n        modality=input_modality,",
        "detail": "projects.configs.bevformer.bevformer_base",
        "documentation": {}
    },
    {
        "label": "optimizer",
        "kind": 5,
        "importPath": "projects.configs.bevformer.bevformer_base",
        "description": "projects.configs.bevformer.bevformer_base",
        "peekOfCode": "optimizer = dict(\n    type='AdamW',\n    lr=2e-4,\n    paramwise_cfg=dict(\n        custom_keys={\n            'img_backbone': dict(lr_mult=0.1),\n        }),\n    weight_decay=0.01)\noptimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))\n# learning policy",
        "detail": "projects.configs.bevformer.bevformer_base",
        "documentation": {}
    },
    {
        "label": "optimizer_config",
        "kind": 5,
        "importPath": "projects.configs.bevformer.bevformer_base",
        "description": "projects.configs.bevformer.bevformer_base",
        "peekOfCode": "optimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))\n# learning policy\nlr_config = dict(\n    policy='CosineAnnealing',\n    warmup='linear',\n    warmup_iters=500,\n    warmup_ratio=1.0 / 3,\n    min_lr_ratio=1e-3)\ntotal_epochs = 24\nevaluation = dict(interval=1, pipeline=test_pipeline)",
        "detail": "projects.configs.bevformer.bevformer_base",
        "documentation": {}
    },
    {
        "label": "lr_config",
        "kind": 5,
        "importPath": "projects.configs.bevformer.bevformer_base",
        "description": "projects.configs.bevformer.bevformer_base",
        "peekOfCode": "lr_config = dict(\n    policy='CosineAnnealing',\n    warmup='linear',\n    warmup_iters=500,\n    warmup_ratio=1.0 / 3,\n    min_lr_ratio=1e-3)\ntotal_epochs = 24\nevaluation = dict(interval=1, pipeline=test_pipeline)\nrunner = dict(type='EpochBasedRunner', max_epochs=total_epochs)\nload_from = 'ckpts/r101_dcn_fcos3d_pretrain.pth'",
        "detail": "projects.configs.bevformer.bevformer_base",
        "documentation": {}
    },
    {
        "label": "total_epochs",
        "kind": 5,
        "importPath": "projects.configs.bevformer.bevformer_base",
        "description": "projects.configs.bevformer.bevformer_base",
        "peekOfCode": "total_epochs = 24\nevaluation = dict(interval=1, pipeline=test_pipeline)\nrunner = dict(type='EpochBasedRunner', max_epochs=total_epochs)\nload_from = 'ckpts/r101_dcn_fcos3d_pretrain.pth'\nlog_config = dict(\n    interval=50,\n    hooks=[\n        dict(type='TextLoggerHook'),\n        dict(type='TensorboardLoggerHook')\n    ])",
        "detail": "projects.configs.bevformer.bevformer_base",
        "documentation": {}
    },
    {
        "label": "evaluation",
        "kind": 5,
        "importPath": "projects.configs.bevformer.bevformer_base",
        "description": "projects.configs.bevformer.bevformer_base",
        "peekOfCode": "evaluation = dict(interval=1, pipeline=test_pipeline)\nrunner = dict(type='EpochBasedRunner', max_epochs=total_epochs)\nload_from = 'ckpts/r101_dcn_fcos3d_pretrain.pth'\nlog_config = dict(\n    interval=50,\n    hooks=[\n        dict(type='TextLoggerHook'),\n        dict(type='TensorboardLoggerHook')\n    ])\ncheckpoint_config = dict(interval=1)",
        "detail": "projects.configs.bevformer.bevformer_base",
        "documentation": {}
    },
    {
        "label": "runner",
        "kind": 5,
        "importPath": "projects.configs.bevformer.bevformer_base",
        "description": "projects.configs.bevformer.bevformer_base",
        "peekOfCode": "runner = dict(type='EpochBasedRunner', max_epochs=total_epochs)\nload_from = 'ckpts/r101_dcn_fcos3d_pretrain.pth'\nlog_config = dict(\n    interval=50,\n    hooks=[\n        dict(type='TextLoggerHook'),\n        dict(type='TensorboardLoggerHook')\n    ])\ncheckpoint_config = dict(interval=1)",
        "detail": "projects.configs.bevformer.bevformer_base",
        "documentation": {}
    },
    {
        "label": "load_from",
        "kind": 5,
        "importPath": "projects.configs.bevformer.bevformer_base",
        "description": "projects.configs.bevformer.bevformer_base",
        "peekOfCode": "load_from = 'ckpts/r101_dcn_fcos3d_pretrain.pth'\nlog_config = dict(\n    interval=50,\n    hooks=[\n        dict(type='TextLoggerHook'),\n        dict(type='TensorboardLoggerHook')\n    ])\ncheckpoint_config = dict(interval=1)",
        "detail": "projects.configs.bevformer.bevformer_base",
        "documentation": {}
    },
    {
        "label": "log_config",
        "kind": 5,
        "importPath": "projects.configs.bevformer.bevformer_base",
        "description": "projects.configs.bevformer.bevformer_base",
        "peekOfCode": "log_config = dict(\n    interval=50,\n    hooks=[\n        dict(type='TextLoggerHook'),\n        dict(type='TensorboardLoggerHook')\n    ])\ncheckpoint_config = dict(interval=1)",
        "detail": "projects.configs.bevformer.bevformer_base",
        "documentation": {}
    },
    {
        "label": "checkpoint_config",
        "kind": 5,
        "importPath": "projects.configs.bevformer.bevformer_base",
        "description": "projects.configs.bevformer.bevformer_base",
        "peekOfCode": "checkpoint_config = dict(interval=1)",
        "detail": "projects.configs.bevformer.bevformer_base",
        "documentation": {}
    },
    {
        "label": "_base_",
        "kind": 5,
        "importPath": "projects.configs.bevformer.bevformer_small",
        "description": "projects.configs.bevformer.bevformer_small",
        "peekOfCode": "_base_ = [\n    '../datasets/custom_nus-3d.py',\n    '../_base_/default_runtime.py'\n]\n#\nplugin = True\nplugin_dir = 'projects/mmdet3d_plugin/'\n# If point cloud range is changed, the models should also change their point\n# cloud range accordingly\npoint_cloud_range = [-51.2, -51.2, -5.0, 51.2, 51.2, 3.0]",
        "detail": "projects.configs.bevformer.bevformer_small",
        "documentation": {}
    },
    {
        "label": "plugin",
        "kind": 5,
        "importPath": "projects.configs.bevformer.bevformer_small",
        "description": "projects.configs.bevformer.bevformer_small",
        "peekOfCode": "plugin = True\nplugin_dir = 'projects/mmdet3d_plugin/'\n# If point cloud range is changed, the models should also change their point\n# cloud range accordingly\npoint_cloud_range = [-51.2, -51.2, -5.0, 51.2, 51.2, 3.0]\nvoxel_size = [0.2, 0.2, 8]\nimg_norm_cfg = dict(\n    mean=[103.530, 116.280, 123.675], std=[1.0, 1.0, 1.0], to_rgb=False)\n# For nuScenes we usually do 10-class detection\nclass_names = [",
        "detail": "projects.configs.bevformer.bevformer_small",
        "documentation": {}
    },
    {
        "label": "plugin_dir",
        "kind": 5,
        "importPath": "projects.configs.bevformer.bevformer_small",
        "description": "projects.configs.bevformer.bevformer_small",
        "peekOfCode": "plugin_dir = 'projects/mmdet3d_plugin/'\n# If point cloud range is changed, the models should also change their point\n# cloud range accordingly\npoint_cloud_range = [-51.2, -51.2, -5.0, 51.2, 51.2, 3.0]\nvoxel_size = [0.2, 0.2, 8]\nimg_norm_cfg = dict(\n    mean=[103.530, 116.280, 123.675], std=[1.0, 1.0, 1.0], to_rgb=False)\n# For nuScenes we usually do 10-class detection\nclass_names = [\n    'car', 'truck', 'construction_vehicle', 'bus', 'trailer', 'barrier',",
        "detail": "projects.configs.bevformer.bevformer_small",
        "documentation": {}
    },
    {
        "label": "point_cloud_range",
        "kind": 5,
        "importPath": "projects.configs.bevformer.bevformer_small",
        "description": "projects.configs.bevformer.bevformer_small",
        "peekOfCode": "point_cloud_range = [-51.2, -51.2, -5.0, 51.2, 51.2, 3.0]\nvoxel_size = [0.2, 0.2, 8]\nimg_norm_cfg = dict(\n    mean=[103.530, 116.280, 123.675], std=[1.0, 1.0, 1.0], to_rgb=False)\n# For nuScenes we usually do 10-class detection\nclass_names = [\n    'car', 'truck', 'construction_vehicle', 'bus', 'trailer', 'barrier',\n    'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone'\n]\ninput_modality = dict(",
        "detail": "projects.configs.bevformer.bevformer_small",
        "documentation": {}
    },
    {
        "label": "voxel_size",
        "kind": 5,
        "importPath": "projects.configs.bevformer.bevformer_small",
        "description": "projects.configs.bevformer.bevformer_small",
        "peekOfCode": "voxel_size = [0.2, 0.2, 8]\nimg_norm_cfg = dict(\n    mean=[103.530, 116.280, 123.675], std=[1.0, 1.0, 1.0], to_rgb=False)\n# For nuScenes we usually do 10-class detection\nclass_names = [\n    'car', 'truck', 'construction_vehicle', 'bus', 'trailer', 'barrier',\n    'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone'\n]\ninput_modality = dict(\n    use_lidar=False,",
        "detail": "projects.configs.bevformer.bevformer_small",
        "documentation": {}
    },
    {
        "label": "img_norm_cfg",
        "kind": 5,
        "importPath": "projects.configs.bevformer.bevformer_small",
        "description": "projects.configs.bevformer.bevformer_small",
        "peekOfCode": "img_norm_cfg = dict(\n    mean=[103.530, 116.280, 123.675], std=[1.0, 1.0, 1.0], to_rgb=False)\n# For nuScenes we usually do 10-class detection\nclass_names = [\n    'car', 'truck', 'construction_vehicle', 'bus', 'trailer', 'barrier',\n    'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone'\n]\ninput_modality = dict(\n    use_lidar=False,\n    use_camera=True,",
        "detail": "projects.configs.bevformer.bevformer_small",
        "documentation": {}
    },
    {
        "label": "class_names",
        "kind": 5,
        "importPath": "projects.configs.bevformer.bevformer_small",
        "description": "projects.configs.bevformer.bevformer_small",
        "peekOfCode": "class_names = [\n    'car', 'truck', 'construction_vehicle', 'bus', 'trailer', 'barrier',\n    'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone'\n]\ninput_modality = dict(\n    use_lidar=False,\n    use_camera=True,\n    use_radar=False,\n    use_map=False,\n    use_external=True)",
        "detail": "projects.configs.bevformer.bevformer_small",
        "documentation": {}
    },
    {
        "label": "input_modality",
        "kind": 5,
        "importPath": "projects.configs.bevformer.bevformer_small",
        "description": "projects.configs.bevformer.bevformer_small",
        "peekOfCode": "input_modality = dict(\n    use_lidar=False,\n    use_camera=True,\n    use_radar=False,\n    use_map=False,\n    use_external=True)\n_dim_ = 256\n_pos_dim_ = _dim_//2\n_ffn_dim_ = _dim_*2\n_num_levels_ = 1",
        "detail": "projects.configs.bevformer.bevformer_small",
        "documentation": {}
    },
    {
        "label": "_dim_",
        "kind": 5,
        "importPath": "projects.configs.bevformer.bevformer_small",
        "description": "projects.configs.bevformer.bevformer_small",
        "peekOfCode": "_dim_ = 256\n_pos_dim_ = _dim_//2\n_ffn_dim_ = _dim_*2\n_num_levels_ = 1\nbev_h_ = 150\nbev_w_ = 150\nqueue_length = 3 # each sequence contains `queue_length` frames.\nmodel = dict(\n    type='BEVFormer',\n    use_grid_mask=True,",
        "detail": "projects.configs.bevformer.bevformer_small",
        "documentation": {}
    },
    {
        "label": "_pos_dim_",
        "kind": 5,
        "importPath": "projects.configs.bevformer.bevformer_small",
        "description": "projects.configs.bevformer.bevformer_small",
        "peekOfCode": "_pos_dim_ = _dim_//2\n_ffn_dim_ = _dim_*2\n_num_levels_ = 1\nbev_h_ = 150\nbev_w_ = 150\nqueue_length = 3 # each sequence contains `queue_length` frames.\nmodel = dict(\n    type='BEVFormer',\n    use_grid_mask=True,\n    video_test_mode=True,",
        "detail": "projects.configs.bevformer.bevformer_small",
        "documentation": {}
    },
    {
        "label": "_ffn_dim_",
        "kind": 5,
        "importPath": "projects.configs.bevformer.bevformer_small",
        "description": "projects.configs.bevformer.bevformer_small",
        "peekOfCode": "_ffn_dim_ = _dim_*2\n_num_levels_ = 1\nbev_h_ = 150\nbev_w_ = 150\nqueue_length = 3 # each sequence contains `queue_length` frames.\nmodel = dict(\n    type='BEVFormer',\n    use_grid_mask=True,\n    video_test_mode=True,\n    img_backbone=dict(",
        "detail": "projects.configs.bevformer.bevformer_small",
        "documentation": {}
    },
    {
        "label": "_num_levels_",
        "kind": 5,
        "importPath": "projects.configs.bevformer.bevformer_small",
        "description": "projects.configs.bevformer.bevformer_small",
        "peekOfCode": "_num_levels_ = 1\nbev_h_ = 150\nbev_w_ = 150\nqueue_length = 3 # each sequence contains `queue_length` frames.\nmodel = dict(\n    type='BEVFormer',\n    use_grid_mask=True,\n    video_test_mode=True,\n    img_backbone=dict(\n        type='ResNet',",
        "detail": "projects.configs.bevformer.bevformer_small",
        "documentation": {}
    },
    {
        "label": "bev_h_",
        "kind": 5,
        "importPath": "projects.configs.bevformer.bevformer_small",
        "description": "projects.configs.bevformer.bevformer_small",
        "peekOfCode": "bev_h_ = 150\nbev_w_ = 150\nqueue_length = 3 # each sequence contains `queue_length` frames.\nmodel = dict(\n    type='BEVFormer',\n    use_grid_mask=True,\n    video_test_mode=True,\n    img_backbone=dict(\n        type='ResNet',\n        depth=101,",
        "detail": "projects.configs.bevformer.bevformer_small",
        "documentation": {}
    },
    {
        "label": "bev_w_",
        "kind": 5,
        "importPath": "projects.configs.bevformer.bevformer_small",
        "description": "projects.configs.bevformer.bevformer_small",
        "peekOfCode": "bev_w_ = 150\nqueue_length = 3 # each sequence contains `queue_length` frames.\nmodel = dict(\n    type='BEVFormer',\n    use_grid_mask=True,\n    video_test_mode=True,\n    img_backbone=dict(\n        type='ResNet',\n        depth=101,\n        num_stages=4,",
        "detail": "projects.configs.bevformer.bevformer_small",
        "documentation": {}
    },
    {
        "label": "queue_length",
        "kind": 5,
        "importPath": "projects.configs.bevformer.bevformer_small",
        "description": "projects.configs.bevformer.bevformer_small",
        "peekOfCode": "queue_length = 3 # each sequence contains `queue_length` frames.\nmodel = dict(\n    type='BEVFormer',\n    use_grid_mask=True,\n    video_test_mode=True,\n    img_backbone=dict(\n        type='ResNet',\n        depth=101,\n        num_stages=4,\n        out_indices=(3,),",
        "detail": "projects.configs.bevformer.bevformer_small",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "projects.configs.bevformer.bevformer_small",
        "description": "projects.configs.bevformer.bevformer_small",
        "peekOfCode": "model = dict(\n    type='BEVFormer',\n    use_grid_mask=True,\n    video_test_mode=True,\n    img_backbone=dict(\n        type='ResNet',\n        depth=101,\n        num_stages=4,\n        out_indices=(3,),\n        frozen_stages=1,",
        "detail": "projects.configs.bevformer.bevformer_small",
        "documentation": {}
    },
    {
        "label": "dataset_type",
        "kind": 5,
        "importPath": "projects.configs.bevformer.bevformer_small",
        "description": "projects.configs.bevformer.bevformer_small",
        "peekOfCode": "dataset_type = 'CustomNuScenesDataset'\ndata_root = 'data/nuscenes/'\nfile_client_args = dict(backend='disk')\ntrain_pipeline = [\n    dict(type='LoadMultiViewImageFromFiles', to_float32=True),\n    dict(type='PhotoMetricDistortionMultiViewImage'),\n    dict(type='LoadAnnotations3D', with_bbox_3d=True, with_label_3d=True, with_attr_label=False),\n    dict(type='ObjectRangeFilter', point_cloud_range=point_cloud_range),\n    dict(type='ObjectNameFilter', classes=class_names),\n    dict(type='NormalizeMultiviewImage', **img_norm_cfg),",
        "detail": "projects.configs.bevformer.bevformer_small",
        "documentation": {}
    },
    {
        "label": "data_root",
        "kind": 5,
        "importPath": "projects.configs.bevformer.bevformer_small",
        "description": "projects.configs.bevformer.bevformer_small",
        "peekOfCode": "data_root = 'data/nuscenes/'\nfile_client_args = dict(backend='disk')\ntrain_pipeline = [\n    dict(type='LoadMultiViewImageFromFiles', to_float32=True),\n    dict(type='PhotoMetricDistortionMultiViewImage'),\n    dict(type='LoadAnnotations3D', with_bbox_3d=True, with_label_3d=True, with_attr_label=False),\n    dict(type='ObjectRangeFilter', point_cloud_range=point_cloud_range),\n    dict(type='ObjectNameFilter', classes=class_names),\n    dict(type='NormalizeMultiviewImage', **img_norm_cfg),\n    dict(type='RandomScaleImageMultiViewImage', scales=[0.8]),",
        "detail": "projects.configs.bevformer.bevformer_small",
        "documentation": {}
    },
    {
        "label": "file_client_args",
        "kind": 5,
        "importPath": "projects.configs.bevformer.bevformer_small",
        "description": "projects.configs.bevformer.bevformer_small",
        "peekOfCode": "file_client_args = dict(backend='disk')\ntrain_pipeline = [\n    dict(type='LoadMultiViewImageFromFiles', to_float32=True),\n    dict(type='PhotoMetricDistortionMultiViewImage'),\n    dict(type='LoadAnnotations3D', with_bbox_3d=True, with_label_3d=True, with_attr_label=False),\n    dict(type='ObjectRangeFilter', point_cloud_range=point_cloud_range),\n    dict(type='ObjectNameFilter', classes=class_names),\n    dict(type='NormalizeMultiviewImage', **img_norm_cfg),\n    dict(type='RandomScaleImageMultiViewImage', scales=[0.8]),\n    dict(type='PadMultiViewImage', size_divisor=32),",
        "detail": "projects.configs.bevformer.bevformer_small",
        "documentation": {}
    },
    {
        "label": "train_pipeline",
        "kind": 5,
        "importPath": "projects.configs.bevformer.bevformer_small",
        "description": "projects.configs.bevformer.bevformer_small",
        "peekOfCode": "train_pipeline = [\n    dict(type='LoadMultiViewImageFromFiles', to_float32=True),\n    dict(type='PhotoMetricDistortionMultiViewImage'),\n    dict(type='LoadAnnotations3D', with_bbox_3d=True, with_label_3d=True, with_attr_label=False),\n    dict(type='ObjectRangeFilter', point_cloud_range=point_cloud_range),\n    dict(type='ObjectNameFilter', classes=class_names),\n    dict(type='NormalizeMultiviewImage', **img_norm_cfg),\n    dict(type='RandomScaleImageMultiViewImage', scales=[0.8]),\n    dict(type='PadMultiViewImage', size_divisor=32),\n    dict(type='DefaultFormatBundle3D', class_names=class_names),",
        "detail": "projects.configs.bevformer.bevformer_small",
        "documentation": {}
    },
    {
        "label": "test_pipeline",
        "kind": 5,
        "importPath": "projects.configs.bevformer.bevformer_small",
        "description": "projects.configs.bevformer.bevformer_small",
        "peekOfCode": "test_pipeline = [\n    dict(type='LoadMultiViewImageFromFiles', to_float32=True),\n    dict(type='NormalizeMultiviewImage', **img_norm_cfg),\n    # dict(type='PadMultiViewImage', size_divisor=32),\n    dict(\n        type='MultiScaleFlipAug3D',\n        img_scale=(1600, 900),\n        pts_scale_ratio=1,\n        flip=False,\n        transforms=[",
        "detail": "projects.configs.bevformer.bevformer_small",
        "documentation": {}
    },
    {
        "label": "data",
        "kind": 5,
        "importPath": "projects.configs.bevformer.bevformer_small",
        "description": "projects.configs.bevformer.bevformer_small",
        "peekOfCode": "data = dict(\n    samples_per_gpu=1,\n    workers_per_gpu=4,\n    train=dict(\n        type=dataset_type,\n        data_root=data_root,\n        ann_file=data_root + 'nuscenes_infos_temporal_train.pkl',\n        pipeline=train_pipeline,\n        classes=class_names,\n        modality=input_modality,",
        "detail": "projects.configs.bevformer.bevformer_small",
        "documentation": {}
    },
    {
        "label": "optimizer",
        "kind": 5,
        "importPath": "projects.configs.bevformer.bevformer_small",
        "description": "projects.configs.bevformer.bevformer_small",
        "peekOfCode": "optimizer = dict(\n    type='AdamW',\n    lr=2e-4,\n    paramwise_cfg=dict(\n        custom_keys={\n            'img_backbone': dict(lr_mult=0.1),\n        }),\n    weight_decay=0.01)\noptimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))\n# learning policy",
        "detail": "projects.configs.bevformer.bevformer_small",
        "documentation": {}
    },
    {
        "label": "optimizer_config",
        "kind": 5,
        "importPath": "projects.configs.bevformer.bevformer_small",
        "description": "projects.configs.bevformer.bevformer_small",
        "peekOfCode": "optimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))\n# learning policy\nlr_config = dict(\n    policy='CosineAnnealing',\n    warmup='linear',\n    warmup_iters=500,\n    warmup_ratio=1.0 / 3,\n    min_lr_ratio=1e-3)\ntotal_epochs = 24\nevaluation = dict(interval=1, pipeline=test_pipeline)",
        "detail": "projects.configs.bevformer.bevformer_small",
        "documentation": {}
    },
    {
        "label": "lr_config",
        "kind": 5,
        "importPath": "projects.configs.bevformer.bevformer_small",
        "description": "projects.configs.bevformer.bevformer_small",
        "peekOfCode": "lr_config = dict(\n    policy='CosineAnnealing',\n    warmup='linear',\n    warmup_iters=500,\n    warmup_ratio=1.0 / 3,\n    min_lr_ratio=1e-3)\ntotal_epochs = 24\nevaluation = dict(interval=1, pipeline=test_pipeline)\nrunner = dict(type='EpochBasedRunner', max_epochs=total_epochs)\nload_from = 'ckpts/r101_dcn_fcos3d_pretrain.pth'",
        "detail": "projects.configs.bevformer.bevformer_small",
        "documentation": {}
    },
    {
        "label": "total_epochs",
        "kind": 5,
        "importPath": "projects.configs.bevformer.bevformer_small",
        "description": "projects.configs.bevformer.bevformer_small",
        "peekOfCode": "total_epochs = 24\nevaluation = dict(interval=1, pipeline=test_pipeline)\nrunner = dict(type='EpochBasedRunner', max_epochs=total_epochs)\nload_from = 'ckpts/r101_dcn_fcos3d_pretrain.pth'\nlog_config = dict(\n    interval=50,\n    hooks=[\n        dict(type='TextLoggerHook'),\n        dict(type='TensorboardLoggerHook')\n    ])",
        "detail": "projects.configs.bevformer.bevformer_small",
        "documentation": {}
    },
    {
        "label": "evaluation",
        "kind": 5,
        "importPath": "projects.configs.bevformer.bevformer_small",
        "description": "projects.configs.bevformer.bevformer_small",
        "peekOfCode": "evaluation = dict(interval=1, pipeline=test_pipeline)\nrunner = dict(type='EpochBasedRunner', max_epochs=total_epochs)\nload_from = 'ckpts/r101_dcn_fcos3d_pretrain.pth'\nlog_config = dict(\n    interval=50,\n    hooks=[\n        dict(type='TextLoggerHook'),\n        dict(type='TensorboardLoggerHook')\n    ])\ncheckpoint_config = dict(interval=1)",
        "detail": "projects.configs.bevformer.bevformer_small",
        "documentation": {}
    },
    {
        "label": "runner",
        "kind": 5,
        "importPath": "projects.configs.bevformer.bevformer_small",
        "description": "projects.configs.bevformer.bevformer_small",
        "peekOfCode": "runner = dict(type='EpochBasedRunner', max_epochs=total_epochs)\nload_from = 'ckpts/r101_dcn_fcos3d_pretrain.pth'\nlog_config = dict(\n    interval=50,\n    hooks=[\n        dict(type='TextLoggerHook'),\n        dict(type='TensorboardLoggerHook')\n    ])\ncheckpoint_config = dict(interval=1)",
        "detail": "projects.configs.bevformer.bevformer_small",
        "documentation": {}
    },
    {
        "label": "load_from",
        "kind": 5,
        "importPath": "projects.configs.bevformer.bevformer_small",
        "description": "projects.configs.bevformer.bevformer_small",
        "peekOfCode": "load_from = 'ckpts/r101_dcn_fcos3d_pretrain.pth'\nlog_config = dict(\n    interval=50,\n    hooks=[\n        dict(type='TextLoggerHook'),\n        dict(type='TensorboardLoggerHook')\n    ])\ncheckpoint_config = dict(interval=1)",
        "detail": "projects.configs.bevformer.bevformer_small",
        "documentation": {}
    },
    {
        "label": "log_config",
        "kind": 5,
        "importPath": "projects.configs.bevformer.bevformer_small",
        "description": "projects.configs.bevformer.bevformer_small",
        "peekOfCode": "log_config = dict(\n    interval=50,\n    hooks=[\n        dict(type='TextLoggerHook'),\n        dict(type='TensorboardLoggerHook')\n    ])\ncheckpoint_config = dict(interval=1)",
        "detail": "projects.configs.bevformer.bevformer_small",
        "documentation": {}
    },
    {
        "label": "checkpoint_config",
        "kind": 5,
        "importPath": "projects.configs.bevformer.bevformer_small",
        "description": "projects.configs.bevformer.bevformer_small",
        "peekOfCode": "checkpoint_config = dict(interval=1)",
        "detail": "projects.configs.bevformer.bevformer_small",
        "documentation": {}
    },
    {
        "label": "_base_",
        "kind": 5,
        "importPath": "projects.configs.bevformer.bevformer_tiny",
        "description": "projects.configs.bevformer.bevformer_tiny",
        "peekOfCode": "_base_ = [\n    '../datasets/custom_nus-3d.py',\n    '../_base_/default_runtime.py'\n]\n#\nplugin = True\nplugin_dir = 'projects/mmdet3d_plugin/'\n# If point cloud range is changed, the models should also change their point\n# cloud range accordingly\npoint_cloud_range = [-51.2, -51.2, -5.0, 51.2, 51.2, 3.0]",
        "detail": "projects.configs.bevformer.bevformer_tiny",
        "documentation": {}
    },
    {
        "label": "plugin",
        "kind": 5,
        "importPath": "projects.configs.bevformer.bevformer_tiny",
        "description": "projects.configs.bevformer.bevformer_tiny",
        "peekOfCode": "plugin = True\nplugin_dir = 'projects/mmdet3d_plugin/'\n# If point cloud range is changed, the models should also change their point\n# cloud range accordingly\npoint_cloud_range = [-51.2, -51.2, -5.0, 51.2, 51.2, 3.0]\nvoxel_size = [0.2, 0.2, 8]\nimg_norm_cfg = dict(\n    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n# For nuScenes we usually do 10-class detection\nclass_names = [",
        "detail": "projects.configs.bevformer.bevformer_tiny",
        "documentation": {}
    },
    {
        "label": "plugin_dir",
        "kind": 5,
        "importPath": "projects.configs.bevformer.bevformer_tiny",
        "description": "projects.configs.bevformer.bevformer_tiny",
        "peekOfCode": "plugin_dir = 'projects/mmdet3d_plugin/'\n# If point cloud range is changed, the models should also change their point\n# cloud range accordingly\npoint_cloud_range = [-51.2, -51.2, -5.0, 51.2, 51.2, 3.0]\nvoxel_size = [0.2, 0.2, 8]\nimg_norm_cfg = dict(\n    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n# For nuScenes we usually do 10-class detection\nclass_names = [\n    'car', 'truck', 'construction_vehicle', 'bus', 'trailer', 'barrier',",
        "detail": "projects.configs.bevformer.bevformer_tiny",
        "documentation": {}
    },
    {
        "label": "point_cloud_range",
        "kind": 5,
        "importPath": "projects.configs.bevformer.bevformer_tiny",
        "description": "projects.configs.bevformer.bevformer_tiny",
        "peekOfCode": "point_cloud_range = [-51.2, -51.2, -5.0, 51.2, 51.2, 3.0]\nvoxel_size = [0.2, 0.2, 8]\nimg_norm_cfg = dict(\n    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n# For nuScenes we usually do 10-class detection\nclass_names = [\n    'car', 'truck', 'construction_vehicle', 'bus', 'trailer', 'barrier',\n    'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone'\n]\ninput_modality = dict(",
        "detail": "projects.configs.bevformer.bevformer_tiny",
        "documentation": {}
    },
    {
        "label": "voxel_size",
        "kind": 5,
        "importPath": "projects.configs.bevformer.bevformer_tiny",
        "description": "projects.configs.bevformer.bevformer_tiny",
        "peekOfCode": "voxel_size = [0.2, 0.2, 8]\nimg_norm_cfg = dict(\n    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n# For nuScenes we usually do 10-class detection\nclass_names = [\n    'car', 'truck', 'construction_vehicle', 'bus', 'trailer', 'barrier',\n    'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone'\n]\ninput_modality = dict(\n    use_lidar=False,",
        "detail": "projects.configs.bevformer.bevformer_tiny",
        "documentation": {}
    },
    {
        "label": "img_norm_cfg",
        "kind": 5,
        "importPath": "projects.configs.bevformer.bevformer_tiny",
        "description": "projects.configs.bevformer.bevformer_tiny",
        "peekOfCode": "img_norm_cfg = dict(\n    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n# For nuScenes we usually do 10-class detection\nclass_names = [\n    'car', 'truck', 'construction_vehicle', 'bus', 'trailer', 'barrier',\n    'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone'\n]\ninput_modality = dict(\n    use_lidar=False,\n    use_camera=True,",
        "detail": "projects.configs.bevformer.bevformer_tiny",
        "documentation": {}
    },
    {
        "label": "class_names",
        "kind": 5,
        "importPath": "projects.configs.bevformer.bevformer_tiny",
        "description": "projects.configs.bevformer.bevformer_tiny",
        "peekOfCode": "class_names = [\n    'car', 'truck', 'construction_vehicle', 'bus', 'trailer', 'barrier',\n    'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone'\n]\ninput_modality = dict(\n    use_lidar=False,\n    use_camera=True,\n    use_radar=False,\n    use_map=False,\n    use_external=True)",
        "detail": "projects.configs.bevformer.bevformer_tiny",
        "documentation": {}
    },
    {
        "label": "input_modality",
        "kind": 5,
        "importPath": "projects.configs.bevformer.bevformer_tiny",
        "description": "projects.configs.bevformer.bevformer_tiny",
        "peekOfCode": "input_modality = dict(\n    use_lidar=False,\n    use_camera=True,\n    use_radar=False,\n    use_map=False,\n    use_external=True)\n_dim_ = 256\n_pos_dim_ = _dim_//2\n_ffn_dim_ = _dim_*2\n_num_levels_ = 1",
        "detail": "projects.configs.bevformer.bevformer_tiny",
        "documentation": {}
    },
    {
        "label": "_dim_",
        "kind": 5,
        "importPath": "projects.configs.bevformer.bevformer_tiny",
        "description": "projects.configs.bevformer.bevformer_tiny",
        "peekOfCode": "_dim_ = 256\n_pos_dim_ = _dim_//2\n_ffn_dim_ = _dim_*2\n_num_levels_ = 1\nbev_h_ = 50\nbev_w_ = 50\nqueue_length = 3 # each sequence contains `queue_length` frames.\nmodel = dict(\n    type='BEVFormer',\n    use_grid_mask=True,",
        "detail": "projects.configs.bevformer.bevformer_tiny",
        "documentation": {}
    },
    {
        "label": "_pos_dim_",
        "kind": 5,
        "importPath": "projects.configs.bevformer.bevformer_tiny",
        "description": "projects.configs.bevformer.bevformer_tiny",
        "peekOfCode": "_pos_dim_ = _dim_//2\n_ffn_dim_ = _dim_*2\n_num_levels_ = 1\nbev_h_ = 50\nbev_w_ = 50\nqueue_length = 3 # each sequence contains `queue_length` frames.\nmodel = dict(\n    type='BEVFormer',\n    use_grid_mask=True,\n    video_test_mode=True,",
        "detail": "projects.configs.bevformer.bevformer_tiny",
        "documentation": {}
    },
    {
        "label": "_ffn_dim_",
        "kind": 5,
        "importPath": "projects.configs.bevformer.bevformer_tiny",
        "description": "projects.configs.bevformer.bevformer_tiny",
        "peekOfCode": "_ffn_dim_ = _dim_*2\n_num_levels_ = 1\nbev_h_ = 50\nbev_w_ = 50\nqueue_length = 3 # each sequence contains `queue_length` frames.\nmodel = dict(\n    type='BEVFormer',\n    use_grid_mask=True,\n    video_test_mode=True,\n    pretrained=dict(img='torchvision://resnet50'),",
        "detail": "projects.configs.bevformer.bevformer_tiny",
        "documentation": {}
    },
    {
        "label": "_num_levels_",
        "kind": 5,
        "importPath": "projects.configs.bevformer.bevformer_tiny",
        "description": "projects.configs.bevformer.bevformer_tiny",
        "peekOfCode": "_num_levels_ = 1\nbev_h_ = 50\nbev_w_ = 50\nqueue_length = 3 # each sequence contains `queue_length` frames.\nmodel = dict(\n    type='BEVFormer',\n    use_grid_mask=True,\n    video_test_mode=True,\n    pretrained=dict(img='torchvision://resnet50'),\n    img_backbone=dict(",
        "detail": "projects.configs.bevformer.bevformer_tiny",
        "documentation": {}
    },
    {
        "label": "bev_h_",
        "kind": 5,
        "importPath": "projects.configs.bevformer.bevformer_tiny",
        "description": "projects.configs.bevformer.bevformer_tiny",
        "peekOfCode": "bev_h_ = 50\nbev_w_ = 50\nqueue_length = 3 # each sequence contains `queue_length` frames.\nmodel = dict(\n    type='BEVFormer',\n    use_grid_mask=True,\n    video_test_mode=True,\n    pretrained=dict(img='torchvision://resnet50'),\n    img_backbone=dict(\n        type='ResNet',",
        "detail": "projects.configs.bevformer.bevformer_tiny",
        "documentation": {}
    },
    {
        "label": "bev_w_",
        "kind": 5,
        "importPath": "projects.configs.bevformer.bevformer_tiny",
        "description": "projects.configs.bevformer.bevformer_tiny",
        "peekOfCode": "bev_w_ = 50\nqueue_length = 3 # each sequence contains `queue_length` frames.\nmodel = dict(\n    type='BEVFormer',\n    use_grid_mask=True,\n    video_test_mode=True,\n    pretrained=dict(img='torchvision://resnet50'),\n    img_backbone=dict(\n        type='ResNet',\n        depth=50,",
        "detail": "projects.configs.bevformer.bevformer_tiny",
        "documentation": {}
    },
    {
        "label": "queue_length",
        "kind": 5,
        "importPath": "projects.configs.bevformer.bevformer_tiny",
        "description": "projects.configs.bevformer.bevformer_tiny",
        "peekOfCode": "queue_length = 3 # each sequence contains `queue_length` frames.\nmodel = dict(\n    type='BEVFormer',\n    use_grid_mask=True,\n    video_test_mode=True,\n    pretrained=dict(img='torchvision://resnet50'),\n    img_backbone=dict(\n        type='ResNet',\n        depth=50,\n        num_stages=4,",
        "detail": "projects.configs.bevformer.bevformer_tiny",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "projects.configs.bevformer.bevformer_tiny",
        "description": "projects.configs.bevformer.bevformer_tiny",
        "peekOfCode": "model = dict(\n    type='BEVFormer',\n    use_grid_mask=True,\n    video_test_mode=True,\n    pretrained=dict(img='torchvision://resnet50'),\n    img_backbone=dict(\n        type='ResNet',\n        depth=50,\n        num_stages=4,\n        out_indices=(3,),",
        "detail": "projects.configs.bevformer.bevformer_tiny",
        "documentation": {}
    },
    {
        "label": "dataset_type",
        "kind": 5,
        "importPath": "projects.configs.bevformer.bevformer_tiny",
        "description": "projects.configs.bevformer.bevformer_tiny",
        "peekOfCode": "dataset_type = 'CustomNuScenesDataset'\ndata_root = '/data/nuscenes/'\nfile_client_args = dict(backend='disk')\ntrain_pipeline = [\n    dict(type='LoadMultiViewImageFromFiles', to_float32=True),\n    dict(type='PhotoMetricDistortionMultiViewImage'),\n    dict(type='LoadAnnotations3D', with_bbox_3d=True, with_label_3d=True, with_attr_label=False),\n    dict(type='ObjectRangeFilter', point_cloud_range=point_cloud_range),\n    dict(type='ObjectNameFilter', classes=class_names),\n    dict(type='NormalizeMultiviewImage', **img_norm_cfg),",
        "detail": "projects.configs.bevformer.bevformer_tiny",
        "documentation": {}
    },
    {
        "label": "data_root",
        "kind": 5,
        "importPath": "projects.configs.bevformer.bevformer_tiny",
        "description": "projects.configs.bevformer.bevformer_tiny",
        "peekOfCode": "data_root = '/data/nuscenes/'\nfile_client_args = dict(backend='disk')\ntrain_pipeline = [\n    dict(type='LoadMultiViewImageFromFiles', to_float32=True),\n    dict(type='PhotoMetricDistortionMultiViewImage'),\n    dict(type='LoadAnnotations3D', with_bbox_3d=True, with_label_3d=True, with_attr_label=False),\n    dict(type='ObjectRangeFilter', point_cloud_range=point_cloud_range),\n    dict(type='ObjectNameFilter', classes=class_names),\n    dict(type='NormalizeMultiviewImage', **img_norm_cfg),\n    dict(type='RandomScaleImageMultiViewImage', scales=[0.5]),",
        "detail": "projects.configs.bevformer.bevformer_tiny",
        "documentation": {}
    },
    {
        "label": "file_client_args",
        "kind": 5,
        "importPath": "projects.configs.bevformer.bevformer_tiny",
        "description": "projects.configs.bevformer.bevformer_tiny",
        "peekOfCode": "file_client_args = dict(backend='disk')\ntrain_pipeline = [\n    dict(type='LoadMultiViewImageFromFiles', to_float32=True),\n    dict(type='PhotoMetricDistortionMultiViewImage'),\n    dict(type='LoadAnnotations3D', with_bbox_3d=True, with_label_3d=True, with_attr_label=False),\n    dict(type='ObjectRangeFilter', point_cloud_range=point_cloud_range),\n    dict(type='ObjectNameFilter', classes=class_names),\n    dict(type='NormalizeMultiviewImage', **img_norm_cfg),\n    dict(type='RandomScaleImageMultiViewImage', scales=[0.5]),\n    dict(type='PadMultiViewImage', size_divisor=32),",
        "detail": "projects.configs.bevformer.bevformer_tiny",
        "documentation": {}
    },
    {
        "label": "train_pipeline",
        "kind": 5,
        "importPath": "projects.configs.bevformer.bevformer_tiny",
        "description": "projects.configs.bevformer.bevformer_tiny",
        "peekOfCode": "train_pipeline = [\n    dict(type='LoadMultiViewImageFromFiles', to_float32=True),\n    dict(type='PhotoMetricDistortionMultiViewImage'),\n    dict(type='LoadAnnotations3D', with_bbox_3d=True, with_label_3d=True, with_attr_label=False),\n    dict(type='ObjectRangeFilter', point_cloud_range=point_cloud_range),\n    dict(type='ObjectNameFilter', classes=class_names),\n    dict(type='NormalizeMultiviewImage', **img_norm_cfg),\n    dict(type='RandomScaleImageMultiViewImage', scales=[0.5]),\n    dict(type='PadMultiViewImage', size_divisor=32),\n    dict(type='DefaultFormatBundle3D', class_names=class_names),",
        "detail": "projects.configs.bevformer.bevformer_tiny",
        "documentation": {}
    },
    {
        "label": "test_pipeline",
        "kind": 5,
        "importPath": "projects.configs.bevformer.bevformer_tiny",
        "description": "projects.configs.bevformer.bevformer_tiny",
        "peekOfCode": "test_pipeline = [\n    dict(type='LoadMultiViewImageFromFiles', to_float32=True),\n    dict(type='NormalizeMultiviewImage', **img_norm_cfg),\n    dict(\n        type='MultiScaleFlipAug3D',\n        img_scale=(1600, 900),\n        pts_scale_ratio=1,\n        flip=False,\n        transforms=[\n            dict(type='RandomScaleImageMultiViewImage', scales=[0.5]),",
        "detail": "projects.configs.bevformer.bevformer_tiny",
        "documentation": {}
    },
    {
        "label": "data",
        "kind": 5,
        "importPath": "projects.configs.bevformer.bevformer_tiny",
        "description": "projects.configs.bevformer.bevformer_tiny",
        "peekOfCode": "data = dict(\n    samples_per_gpu=1,\n    workers_per_gpu=2,\n    train=dict(\n        type=dataset_type,\n        data_root=data_root,\n        ann_file=data_root + 'nuscenes_infos_temporal_train.pkl',\n        pipeline=train_pipeline,\n        classes=class_names,\n        modality=input_modality,",
        "detail": "projects.configs.bevformer.bevformer_tiny",
        "documentation": {}
    },
    {
        "label": "optimizer",
        "kind": 5,
        "importPath": "projects.configs.bevformer.bevformer_tiny",
        "description": "projects.configs.bevformer.bevformer_tiny",
        "peekOfCode": "optimizer = dict(\n    type='AdamW',\n    lr=2e-4,\n    paramwise_cfg=dict(\n        custom_keys={\n            'img_backbone': dict(lr_mult=0.1),\n        }),\n    weight_decay=0.01)\noptimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))\n# learning policy",
        "detail": "projects.configs.bevformer.bevformer_tiny",
        "documentation": {}
    },
    {
        "label": "optimizer_config",
        "kind": 5,
        "importPath": "projects.configs.bevformer.bevformer_tiny",
        "description": "projects.configs.bevformer.bevformer_tiny",
        "peekOfCode": "optimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))\n# learning policy\nlr_config = dict(\n    policy='CosineAnnealing',\n    warmup='linear',\n    warmup_iters=500,\n    warmup_ratio=1.0 / 3,\n    min_lr_ratio=1e-3)\ntotal_epochs = 24\nevaluation = dict(interval=1, pipeline=test_pipeline)",
        "detail": "projects.configs.bevformer.bevformer_tiny",
        "documentation": {}
    },
    {
        "label": "lr_config",
        "kind": 5,
        "importPath": "projects.configs.bevformer.bevformer_tiny",
        "description": "projects.configs.bevformer.bevformer_tiny",
        "peekOfCode": "lr_config = dict(\n    policy='CosineAnnealing',\n    warmup='linear',\n    warmup_iters=500,\n    warmup_ratio=1.0 / 3,\n    min_lr_ratio=1e-3)\ntotal_epochs = 24\nevaluation = dict(interval=1, pipeline=test_pipeline)\nrunner = dict(type='EpochBasedRunner', max_epochs=total_epochs)\nlog_config = dict(",
        "detail": "projects.configs.bevformer.bevformer_tiny",
        "documentation": {}
    },
    {
        "label": "total_epochs",
        "kind": 5,
        "importPath": "projects.configs.bevformer.bevformer_tiny",
        "description": "projects.configs.bevformer.bevformer_tiny",
        "peekOfCode": "total_epochs = 24\nevaluation = dict(interval=1, pipeline=test_pipeline)\nrunner = dict(type='EpochBasedRunner', max_epochs=total_epochs)\nlog_config = dict(\n    interval=50,\n    hooks=[\n        dict(type='TextLoggerHook'),\n        dict(type='TensorboardLoggerHook')\n    ])\ncheckpoint_config = dict(interval=1)",
        "detail": "projects.configs.bevformer.bevformer_tiny",
        "documentation": {}
    },
    {
        "label": "evaluation",
        "kind": 5,
        "importPath": "projects.configs.bevformer.bevformer_tiny",
        "description": "projects.configs.bevformer.bevformer_tiny",
        "peekOfCode": "evaluation = dict(interval=1, pipeline=test_pipeline)\nrunner = dict(type='EpochBasedRunner', max_epochs=total_epochs)\nlog_config = dict(\n    interval=50,\n    hooks=[\n        dict(type='TextLoggerHook'),\n        dict(type='TensorboardLoggerHook')\n    ])\ncheckpoint_config = dict(interval=1)",
        "detail": "projects.configs.bevformer.bevformer_tiny",
        "documentation": {}
    },
    {
        "label": "runner",
        "kind": 5,
        "importPath": "projects.configs.bevformer.bevformer_tiny",
        "description": "projects.configs.bevformer.bevformer_tiny",
        "peekOfCode": "runner = dict(type='EpochBasedRunner', max_epochs=total_epochs)\nlog_config = dict(\n    interval=50,\n    hooks=[\n        dict(type='TextLoggerHook'),\n        dict(type='TensorboardLoggerHook')\n    ])\ncheckpoint_config = dict(interval=1)",
        "detail": "projects.configs.bevformer.bevformer_tiny",
        "documentation": {}
    },
    {
        "label": "log_config",
        "kind": 5,
        "importPath": "projects.configs.bevformer.bevformer_tiny",
        "description": "projects.configs.bevformer.bevformer_tiny",
        "peekOfCode": "log_config = dict(\n    interval=50,\n    hooks=[\n        dict(type='TextLoggerHook'),\n        dict(type='TensorboardLoggerHook')\n    ])\ncheckpoint_config = dict(interval=1)",
        "detail": "projects.configs.bevformer.bevformer_tiny",
        "documentation": {}
    },
    {
        "label": "checkpoint_config",
        "kind": 5,
        "importPath": "projects.configs.bevformer.bevformer_tiny",
        "description": "projects.configs.bevformer.bevformer_tiny",
        "peekOfCode": "checkpoint_config = dict(interval=1)",
        "detail": "projects.configs.bevformer.bevformer_tiny",
        "documentation": {}
    },
    {
        "label": "_base_",
        "kind": 5,
        "importPath": "projects.configs.bevformer_fp16.bevformer_tiny_fp16",
        "description": "projects.configs.bevformer_fp16.bevformer_tiny_fp16",
        "peekOfCode": "_base_ = [\n    '../datasets/custom_nus-3d.py',\n    '../_base_/default_runtime.py'\n]\n#\nplugin = True\nplugin_dir = 'projects/mmdet3d_plugin/'\n# If point cloud range is changed, the models should also change their point\n# cloud range accordingly\npoint_cloud_range = [-51.2, -51.2, -5.0, 51.2, 51.2, 3.0]",
        "detail": "projects.configs.bevformer_fp16.bevformer_tiny_fp16",
        "documentation": {}
    },
    {
        "label": "plugin",
        "kind": 5,
        "importPath": "projects.configs.bevformer_fp16.bevformer_tiny_fp16",
        "description": "projects.configs.bevformer_fp16.bevformer_tiny_fp16",
        "peekOfCode": "plugin = True\nplugin_dir = 'projects/mmdet3d_plugin/'\n# If point cloud range is changed, the models should also change their point\n# cloud range accordingly\npoint_cloud_range = [-51.2, -51.2, -5.0, 51.2, 51.2, 3.0]\nvoxel_size = [0.2, 0.2, 8]\nimg_norm_cfg = dict(\n    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n# For nuScenes we usually do 10-class detection\nclass_names = [",
        "detail": "projects.configs.bevformer_fp16.bevformer_tiny_fp16",
        "documentation": {}
    },
    {
        "label": "plugin_dir",
        "kind": 5,
        "importPath": "projects.configs.bevformer_fp16.bevformer_tiny_fp16",
        "description": "projects.configs.bevformer_fp16.bevformer_tiny_fp16",
        "peekOfCode": "plugin_dir = 'projects/mmdet3d_plugin/'\n# If point cloud range is changed, the models should also change their point\n# cloud range accordingly\npoint_cloud_range = [-51.2, -51.2, -5.0, 51.2, 51.2, 3.0]\nvoxel_size = [0.2, 0.2, 8]\nimg_norm_cfg = dict(\n    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n# For nuScenes we usually do 10-class detection\nclass_names = [\n    'car', 'truck', 'construction_vehicle', 'bus', 'trailer', 'barrier',",
        "detail": "projects.configs.bevformer_fp16.bevformer_tiny_fp16",
        "documentation": {}
    },
    {
        "label": "point_cloud_range",
        "kind": 5,
        "importPath": "projects.configs.bevformer_fp16.bevformer_tiny_fp16",
        "description": "projects.configs.bevformer_fp16.bevformer_tiny_fp16",
        "peekOfCode": "point_cloud_range = [-51.2, -51.2, -5.0, 51.2, 51.2, 3.0]\nvoxel_size = [0.2, 0.2, 8]\nimg_norm_cfg = dict(\n    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n# For nuScenes we usually do 10-class detection\nclass_names = [\n    'car', 'truck', 'construction_vehicle', 'bus', 'trailer', 'barrier',\n    'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone'\n]\ninput_modality = dict(",
        "detail": "projects.configs.bevformer_fp16.bevformer_tiny_fp16",
        "documentation": {}
    },
    {
        "label": "voxel_size",
        "kind": 5,
        "importPath": "projects.configs.bevformer_fp16.bevformer_tiny_fp16",
        "description": "projects.configs.bevformer_fp16.bevformer_tiny_fp16",
        "peekOfCode": "voxel_size = [0.2, 0.2, 8]\nimg_norm_cfg = dict(\n    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n# For nuScenes we usually do 10-class detection\nclass_names = [\n    'car', 'truck', 'construction_vehicle', 'bus', 'trailer', 'barrier',\n    'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone'\n]\ninput_modality = dict(\n    use_lidar=False,",
        "detail": "projects.configs.bevformer_fp16.bevformer_tiny_fp16",
        "documentation": {}
    },
    {
        "label": "img_norm_cfg",
        "kind": 5,
        "importPath": "projects.configs.bevformer_fp16.bevformer_tiny_fp16",
        "description": "projects.configs.bevformer_fp16.bevformer_tiny_fp16",
        "peekOfCode": "img_norm_cfg = dict(\n    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n# For nuScenes we usually do 10-class detection\nclass_names = [\n    'car', 'truck', 'construction_vehicle', 'bus', 'trailer', 'barrier',\n    'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone'\n]\ninput_modality = dict(\n    use_lidar=False,\n    use_camera=True,",
        "detail": "projects.configs.bevformer_fp16.bevformer_tiny_fp16",
        "documentation": {}
    },
    {
        "label": "class_names",
        "kind": 5,
        "importPath": "projects.configs.bevformer_fp16.bevformer_tiny_fp16",
        "description": "projects.configs.bevformer_fp16.bevformer_tiny_fp16",
        "peekOfCode": "class_names = [\n    'car', 'truck', 'construction_vehicle', 'bus', 'trailer', 'barrier',\n    'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone'\n]\ninput_modality = dict(\n    use_lidar=False,\n    use_camera=True,\n    use_radar=False,\n    use_map=False,\n    use_external=True)",
        "detail": "projects.configs.bevformer_fp16.bevformer_tiny_fp16",
        "documentation": {}
    },
    {
        "label": "input_modality",
        "kind": 5,
        "importPath": "projects.configs.bevformer_fp16.bevformer_tiny_fp16",
        "description": "projects.configs.bevformer_fp16.bevformer_tiny_fp16",
        "peekOfCode": "input_modality = dict(\n    use_lidar=False,\n    use_camera=True,\n    use_radar=False,\n    use_map=False,\n    use_external=True)\n_dim_ = 256\n_pos_dim_ = _dim_//2\n_ffn_dim_ = _dim_*2\n_num_levels_ = 1",
        "detail": "projects.configs.bevformer_fp16.bevformer_tiny_fp16",
        "documentation": {}
    },
    {
        "label": "_dim_",
        "kind": 5,
        "importPath": "projects.configs.bevformer_fp16.bevformer_tiny_fp16",
        "description": "projects.configs.bevformer_fp16.bevformer_tiny_fp16",
        "peekOfCode": "_dim_ = 256\n_pos_dim_ = _dim_//2\n_ffn_dim_ = _dim_*2\n_num_levels_ = 1\nbev_h_ = 50\nbev_w_ = 50\nqueue_length = 3 # each sequence contains `queue_length` frames.\nmodel = dict(\n    type='BEVFormer_fp16',\n    use_grid_mask=True,",
        "detail": "projects.configs.bevformer_fp16.bevformer_tiny_fp16",
        "documentation": {}
    },
    {
        "label": "_pos_dim_",
        "kind": 5,
        "importPath": "projects.configs.bevformer_fp16.bevformer_tiny_fp16",
        "description": "projects.configs.bevformer_fp16.bevformer_tiny_fp16",
        "peekOfCode": "_pos_dim_ = _dim_//2\n_ffn_dim_ = _dim_*2\n_num_levels_ = 1\nbev_h_ = 50\nbev_w_ = 50\nqueue_length = 3 # each sequence contains `queue_length` frames.\nmodel = dict(\n    type='BEVFormer_fp16',\n    use_grid_mask=True,\n    video_test_mode=True,",
        "detail": "projects.configs.bevformer_fp16.bevformer_tiny_fp16",
        "documentation": {}
    },
    {
        "label": "_ffn_dim_",
        "kind": 5,
        "importPath": "projects.configs.bevformer_fp16.bevformer_tiny_fp16",
        "description": "projects.configs.bevformer_fp16.bevformer_tiny_fp16",
        "peekOfCode": "_ffn_dim_ = _dim_*2\n_num_levels_ = 1\nbev_h_ = 50\nbev_w_ = 50\nqueue_length = 3 # each sequence contains `queue_length` frames.\nmodel = dict(\n    type='BEVFormer_fp16',\n    use_grid_mask=True,\n    video_test_mode=True,\n    pretrained=dict(img='torchvision://resnet50'),",
        "detail": "projects.configs.bevformer_fp16.bevformer_tiny_fp16",
        "documentation": {}
    },
    {
        "label": "_num_levels_",
        "kind": 5,
        "importPath": "projects.configs.bevformer_fp16.bevformer_tiny_fp16",
        "description": "projects.configs.bevformer_fp16.bevformer_tiny_fp16",
        "peekOfCode": "_num_levels_ = 1\nbev_h_ = 50\nbev_w_ = 50\nqueue_length = 3 # each sequence contains `queue_length` frames.\nmodel = dict(\n    type='BEVFormer_fp16',\n    use_grid_mask=True,\n    video_test_mode=True,\n    pretrained=dict(img='torchvision://resnet50'),\n    img_backbone=dict(",
        "detail": "projects.configs.bevformer_fp16.bevformer_tiny_fp16",
        "documentation": {}
    },
    {
        "label": "bev_h_",
        "kind": 5,
        "importPath": "projects.configs.bevformer_fp16.bevformer_tiny_fp16",
        "description": "projects.configs.bevformer_fp16.bevformer_tiny_fp16",
        "peekOfCode": "bev_h_ = 50\nbev_w_ = 50\nqueue_length = 3 # each sequence contains `queue_length` frames.\nmodel = dict(\n    type='BEVFormer_fp16',\n    use_grid_mask=True,\n    video_test_mode=True,\n    pretrained=dict(img='torchvision://resnet50'),\n    img_backbone=dict(\n        type='ResNet',",
        "detail": "projects.configs.bevformer_fp16.bevformer_tiny_fp16",
        "documentation": {}
    },
    {
        "label": "bev_w_",
        "kind": 5,
        "importPath": "projects.configs.bevformer_fp16.bevformer_tiny_fp16",
        "description": "projects.configs.bevformer_fp16.bevformer_tiny_fp16",
        "peekOfCode": "bev_w_ = 50\nqueue_length = 3 # each sequence contains `queue_length` frames.\nmodel = dict(\n    type='BEVFormer_fp16',\n    use_grid_mask=True,\n    video_test_mode=True,\n    pretrained=dict(img='torchvision://resnet50'),\n    img_backbone=dict(\n        type='ResNet',\n        depth=50,",
        "detail": "projects.configs.bevformer_fp16.bevformer_tiny_fp16",
        "documentation": {}
    },
    {
        "label": "queue_length",
        "kind": 5,
        "importPath": "projects.configs.bevformer_fp16.bevformer_tiny_fp16",
        "description": "projects.configs.bevformer_fp16.bevformer_tiny_fp16",
        "peekOfCode": "queue_length = 3 # each sequence contains `queue_length` frames.\nmodel = dict(\n    type='BEVFormer_fp16',\n    use_grid_mask=True,\n    video_test_mode=True,\n    pretrained=dict(img='torchvision://resnet50'),\n    img_backbone=dict(\n        type='ResNet',\n        depth=50,\n        num_stages=4,",
        "detail": "projects.configs.bevformer_fp16.bevformer_tiny_fp16",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "projects.configs.bevformer_fp16.bevformer_tiny_fp16",
        "description": "projects.configs.bevformer_fp16.bevformer_tiny_fp16",
        "peekOfCode": "model = dict(\n    type='BEVFormer_fp16',\n    use_grid_mask=True,\n    video_test_mode=True,\n    pretrained=dict(img='torchvision://resnet50'),\n    img_backbone=dict(\n        type='ResNet',\n        depth=50,\n        num_stages=4,\n        out_indices=(3,),",
        "detail": "projects.configs.bevformer_fp16.bevformer_tiny_fp16",
        "documentation": {}
    },
    {
        "label": "dataset_type",
        "kind": 5,
        "importPath": "projects.configs.bevformer_fp16.bevformer_tiny_fp16",
        "description": "projects.configs.bevformer_fp16.bevformer_tiny_fp16",
        "peekOfCode": "dataset_type = 'CustomNuScenesDataset'\ndata_root = 'data/nuscenes/'\nfile_client_args = dict(backend='disk')\ntrain_pipeline = [\n    dict(type='LoadMultiViewImageFromFiles', to_float32=True),\n    dict(type='PhotoMetricDistortionMultiViewImage'),\n    dict(type='LoadAnnotations3D', with_bbox_3d=True, with_label_3d=True, with_attr_label=False),\n    dict(type='ObjectRangeFilter', point_cloud_range=point_cloud_range),\n    dict(type='ObjectNameFilter', classes=class_names),\n    dict(type='NormalizeMultiviewImage', **img_norm_cfg),",
        "detail": "projects.configs.bevformer_fp16.bevformer_tiny_fp16",
        "documentation": {}
    },
    {
        "label": "data_root",
        "kind": 5,
        "importPath": "projects.configs.bevformer_fp16.bevformer_tiny_fp16",
        "description": "projects.configs.bevformer_fp16.bevformer_tiny_fp16",
        "peekOfCode": "data_root = 'data/nuscenes/'\nfile_client_args = dict(backend='disk')\ntrain_pipeline = [\n    dict(type='LoadMultiViewImageFromFiles', to_float32=True),\n    dict(type='PhotoMetricDistortionMultiViewImage'),\n    dict(type='LoadAnnotations3D', with_bbox_3d=True, with_label_3d=True, with_attr_label=False),\n    dict(type='ObjectRangeFilter', point_cloud_range=point_cloud_range),\n    dict(type='ObjectNameFilter', classes=class_names),\n    dict(type='NormalizeMultiviewImage', **img_norm_cfg),\n    dict(type='RandomScaleImageMultiViewImage', scales=[0.5]),",
        "detail": "projects.configs.bevformer_fp16.bevformer_tiny_fp16",
        "documentation": {}
    },
    {
        "label": "file_client_args",
        "kind": 5,
        "importPath": "projects.configs.bevformer_fp16.bevformer_tiny_fp16",
        "description": "projects.configs.bevformer_fp16.bevformer_tiny_fp16",
        "peekOfCode": "file_client_args = dict(backend='disk')\ntrain_pipeline = [\n    dict(type='LoadMultiViewImageFromFiles', to_float32=True),\n    dict(type='PhotoMetricDistortionMultiViewImage'),\n    dict(type='LoadAnnotations3D', with_bbox_3d=True, with_label_3d=True, with_attr_label=False),\n    dict(type='ObjectRangeFilter', point_cloud_range=point_cloud_range),\n    dict(type='ObjectNameFilter', classes=class_names),\n    dict(type='NormalizeMultiviewImage', **img_norm_cfg),\n    dict(type='RandomScaleImageMultiViewImage', scales=[0.5]),\n    dict(type='PadMultiViewImage', size_divisor=32),",
        "detail": "projects.configs.bevformer_fp16.bevformer_tiny_fp16",
        "documentation": {}
    },
    {
        "label": "train_pipeline",
        "kind": 5,
        "importPath": "projects.configs.bevformer_fp16.bevformer_tiny_fp16",
        "description": "projects.configs.bevformer_fp16.bevformer_tiny_fp16",
        "peekOfCode": "train_pipeline = [\n    dict(type='LoadMultiViewImageFromFiles', to_float32=True),\n    dict(type='PhotoMetricDistortionMultiViewImage'),\n    dict(type='LoadAnnotations3D', with_bbox_3d=True, with_label_3d=True, with_attr_label=False),\n    dict(type='ObjectRangeFilter', point_cloud_range=point_cloud_range),\n    dict(type='ObjectNameFilter', classes=class_names),\n    dict(type='NormalizeMultiviewImage', **img_norm_cfg),\n    dict(type='RandomScaleImageMultiViewImage', scales=[0.5]),\n    dict(type='PadMultiViewImage', size_divisor=32),\n    dict(type='DefaultFormatBundle3D', class_names=class_names),",
        "detail": "projects.configs.bevformer_fp16.bevformer_tiny_fp16",
        "documentation": {}
    },
    {
        "label": "test_pipeline",
        "kind": 5,
        "importPath": "projects.configs.bevformer_fp16.bevformer_tiny_fp16",
        "description": "projects.configs.bevformer_fp16.bevformer_tiny_fp16",
        "peekOfCode": "test_pipeline = [\n    dict(type='LoadMultiViewImageFromFiles', to_float32=True),\n    dict(type='NormalizeMultiviewImage', **img_norm_cfg),\n    dict(\n        type='MultiScaleFlipAug3D',\n        img_scale=(1600, 900),\n        pts_scale_ratio=1,\n        flip=False,\n        transforms=[\n            dict(type='RandomScaleImageMultiViewImage', scales=[0.5]),",
        "detail": "projects.configs.bevformer_fp16.bevformer_tiny_fp16",
        "documentation": {}
    },
    {
        "label": "data",
        "kind": 5,
        "importPath": "projects.configs.bevformer_fp16.bevformer_tiny_fp16",
        "description": "projects.configs.bevformer_fp16.bevformer_tiny_fp16",
        "peekOfCode": "data = dict(\n    samples_per_gpu=2,\n    workers_per_gpu=8,\n    train=dict(\n        type=dataset_type,\n        data_root=data_root,\n        ann_file=data_root + 'nuscenes_infos_temporal_train.pkl',\n        pipeline=train_pipeline,\n        classes=class_names,\n        modality=input_modality,",
        "detail": "projects.configs.bevformer_fp16.bevformer_tiny_fp16",
        "documentation": {}
    },
    {
        "label": "optimizer",
        "kind": 5,
        "importPath": "projects.configs.bevformer_fp16.bevformer_tiny_fp16",
        "description": "projects.configs.bevformer_fp16.bevformer_tiny_fp16",
        "peekOfCode": "optimizer = dict(\n    type='AdamW',\n    lr=2.8e-4,\n    paramwise_cfg=dict(\n        custom_keys={\n            'img_backbone': dict(lr_mult=0.1),\n        }),\n    weight_decay=0.01)\noptimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))\n# learning policy",
        "detail": "projects.configs.bevformer_fp16.bevformer_tiny_fp16",
        "documentation": {}
    },
    {
        "label": "optimizer_config",
        "kind": 5,
        "importPath": "projects.configs.bevformer_fp16.bevformer_tiny_fp16",
        "description": "projects.configs.bevformer_fp16.bevformer_tiny_fp16",
        "peekOfCode": "optimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))\n# learning policy\nlr_config = dict(\n    policy='CosineAnnealing',\n    warmup='linear',\n    warmup_iters=500,\n    warmup_ratio=1.0 / 3,\n    min_lr_ratio=1e-3)\ntotal_epochs = 24\nevaluation = dict(interval=1, pipeline=test_pipeline)",
        "detail": "projects.configs.bevformer_fp16.bevformer_tiny_fp16",
        "documentation": {}
    },
    {
        "label": "lr_config",
        "kind": 5,
        "importPath": "projects.configs.bevformer_fp16.bevformer_tiny_fp16",
        "description": "projects.configs.bevformer_fp16.bevformer_tiny_fp16",
        "peekOfCode": "lr_config = dict(\n    policy='CosineAnnealing',\n    warmup='linear',\n    warmup_iters=500,\n    warmup_ratio=1.0 / 3,\n    min_lr_ratio=1e-3)\ntotal_epochs = 24\nevaluation = dict(interval=1, pipeline=test_pipeline)\nrunner = dict(type='EpochBasedRunner_video', max_epochs=total_epochs)\nlog_config = dict(",
        "detail": "projects.configs.bevformer_fp16.bevformer_tiny_fp16",
        "documentation": {}
    },
    {
        "label": "total_epochs",
        "kind": 5,
        "importPath": "projects.configs.bevformer_fp16.bevformer_tiny_fp16",
        "description": "projects.configs.bevformer_fp16.bevformer_tiny_fp16",
        "peekOfCode": "total_epochs = 24\nevaluation = dict(interval=1, pipeline=test_pipeline)\nrunner = dict(type='EpochBasedRunner_video', max_epochs=total_epochs)\nlog_config = dict(\n    interval=50,\n    hooks=[\n        dict(type='TextLoggerHook'),\n        dict(type='TensorboardLoggerHook')\n    ])\nfp16 = dict(loss_scale=512.)",
        "detail": "projects.configs.bevformer_fp16.bevformer_tiny_fp16",
        "documentation": {}
    },
    {
        "label": "evaluation",
        "kind": 5,
        "importPath": "projects.configs.bevformer_fp16.bevformer_tiny_fp16",
        "description": "projects.configs.bevformer_fp16.bevformer_tiny_fp16",
        "peekOfCode": "evaluation = dict(interval=1, pipeline=test_pipeline)\nrunner = dict(type='EpochBasedRunner_video', max_epochs=total_epochs)\nlog_config = dict(\n    interval=50,\n    hooks=[\n        dict(type='TextLoggerHook'),\n        dict(type='TensorboardLoggerHook')\n    ])\nfp16 = dict(loss_scale=512.)\ncheckpoint_config = dict(interval=1)",
        "detail": "projects.configs.bevformer_fp16.bevformer_tiny_fp16",
        "documentation": {}
    },
    {
        "label": "runner",
        "kind": 5,
        "importPath": "projects.configs.bevformer_fp16.bevformer_tiny_fp16",
        "description": "projects.configs.bevformer_fp16.bevformer_tiny_fp16",
        "peekOfCode": "runner = dict(type='EpochBasedRunner_video', max_epochs=total_epochs)\nlog_config = dict(\n    interval=50,\n    hooks=[\n        dict(type='TextLoggerHook'),\n        dict(type='TensorboardLoggerHook')\n    ])\nfp16 = dict(loss_scale=512.)\ncheckpoint_config = dict(interval=1)\ncustom_hooks = [dict(type='TransferWeight',priority='LOWEST')]",
        "detail": "projects.configs.bevformer_fp16.bevformer_tiny_fp16",
        "documentation": {}
    },
    {
        "label": "log_config",
        "kind": 5,
        "importPath": "projects.configs.bevformer_fp16.bevformer_tiny_fp16",
        "description": "projects.configs.bevformer_fp16.bevformer_tiny_fp16",
        "peekOfCode": "log_config = dict(\n    interval=50,\n    hooks=[\n        dict(type='TextLoggerHook'),\n        dict(type='TensorboardLoggerHook')\n    ])\nfp16 = dict(loss_scale=512.)\ncheckpoint_config = dict(interval=1)\ncustom_hooks = [dict(type='TransferWeight',priority='LOWEST')]",
        "detail": "projects.configs.bevformer_fp16.bevformer_tiny_fp16",
        "documentation": {}
    },
    {
        "label": "fp16",
        "kind": 5,
        "importPath": "projects.configs.bevformer_fp16.bevformer_tiny_fp16",
        "description": "projects.configs.bevformer_fp16.bevformer_tiny_fp16",
        "peekOfCode": "fp16 = dict(loss_scale=512.)\ncheckpoint_config = dict(interval=1)\ncustom_hooks = [dict(type='TransferWeight',priority='LOWEST')]",
        "detail": "projects.configs.bevformer_fp16.bevformer_tiny_fp16",
        "documentation": {}
    },
    {
        "label": "checkpoint_config",
        "kind": 5,
        "importPath": "projects.configs.bevformer_fp16.bevformer_tiny_fp16",
        "description": "projects.configs.bevformer_fp16.bevformer_tiny_fp16",
        "peekOfCode": "checkpoint_config = dict(interval=1)\ncustom_hooks = [dict(type='TransferWeight',priority='LOWEST')]",
        "detail": "projects.configs.bevformer_fp16.bevformer_tiny_fp16",
        "documentation": {}
    },
    {
        "label": "custom_hooks",
        "kind": 5,
        "importPath": "projects.configs.bevformer_fp16.bevformer_tiny_fp16",
        "description": "projects.configs.bevformer_fp16.bevformer_tiny_fp16",
        "peekOfCode": "custom_hooks = [dict(type='TransferWeight',priority='LOWEST')]",
        "detail": "projects.configs.bevformer_fp16.bevformer_tiny_fp16",
        "documentation": {}
    },
    {
        "label": "_base_",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-24ep",
        "peekOfCode": "_base_ = [\n    '../_base_/default_runtime.py'\n]\n# Dataset\n# If point cloud range is changed, the models should also change their point\n# cloud range accordingly\npoint_cloud_range = [-51.2, -51.2, -5.0, 51.2, 51.2, 3.0]\n# For nuScenes we usually do 10-class detection\nclass_names = [\n    'barrier', 'bicycle', 'bus', 'car', 'construction_vehicle', 'motorcycle',",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-24ep",
        "documentation": {}
    },
    {
        "label": "point_cloud_range",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-24ep",
        "peekOfCode": "point_cloud_range = [-51.2, -51.2, -5.0, 51.2, 51.2, 3.0]\n# For nuScenes we usually do 10-class detection\nclass_names = [\n    'barrier', 'bicycle', 'bus', 'car', 'construction_vehicle', 'motorcycle',\n    'pedestrian', 'traffic_cone', 'trailer', 'truck'\n]\ndataset_type = 'CustomNuScenesDatasetV2'\ndata_root = 'data/nuscenes/'\n# Input modality for nuScenes dataset, this is consistent with the submission\n# format which requires the information in input_modality.",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-24ep",
        "documentation": {}
    },
    {
        "label": "class_names",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-24ep",
        "peekOfCode": "class_names = [\n    'barrier', 'bicycle', 'bus', 'car', 'construction_vehicle', 'motorcycle',\n    'pedestrian', 'traffic_cone', 'trailer', 'truck'\n]\ndataset_type = 'CustomNuScenesDatasetV2'\ndata_root = 'data/nuscenes/'\n# Input modality for nuScenes dataset, this is consistent with the submission\n# format which requires the information in input_modality.\ninput_modality = dict(\n    use_lidar=False,",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-24ep",
        "documentation": {}
    },
    {
        "label": "dataset_type",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-24ep",
        "peekOfCode": "dataset_type = 'CustomNuScenesDatasetV2'\ndata_root = 'data/nuscenes/'\n# Input modality for nuScenes dataset, this is consistent with the submission\n# format which requires the information in input_modality.\ninput_modality = dict(\n    use_lidar=False,\n    use_camera=True,\n    use_radar=False,\n    use_map=False,\n    use_external=False)",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-24ep",
        "documentation": {}
    },
    {
        "label": "data_root",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-24ep",
        "peekOfCode": "data_root = 'data/nuscenes/'\n# Input modality for nuScenes dataset, this is consistent with the submission\n# format which requires the information in input_modality.\ninput_modality = dict(\n    use_lidar=False,\n    use_camera=True,\n    use_radar=False,\n    use_map=False,\n    use_external=False)\nimg_norm_cfg = dict(mean=[103.53, 116.28, 123.675], std=[1, 1, 1], to_rgb=False)",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-24ep",
        "documentation": {}
    },
    {
        "label": "input_modality",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-24ep",
        "peekOfCode": "input_modality = dict(\n    use_lidar=False,\n    use_camera=True,\n    use_radar=False,\n    use_map=False,\n    use_external=False)\nimg_norm_cfg = dict(mean=[103.53, 116.28, 123.675], std=[1, 1, 1], to_rgb=False)\nbev_h_ = 200\nbev_w_ = 200\nframes = (0,)",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-24ep",
        "documentation": {}
    },
    {
        "label": "img_norm_cfg",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-24ep",
        "peekOfCode": "img_norm_cfg = dict(mean=[103.53, 116.28, 123.675], std=[1, 1, 1], to_rgb=False)\nbev_h_ = 200\nbev_w_ = 200\nframes = (0,)\ngroup_detr = 11\nvoxel_size = [102.4 / bev_h_, 102.4 / bev_w_, 8]\nida_aug_conf = {\n    \"reisze\": [512, 544, 576, 608, 640, 672, 704, 736, 768],  #  (0.8, 1.2)\n    \"crop\": (0, 260, 1600, 900),\n    \"H\": 900,",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-24ep",
        "documentation": {}
    },
    {
        "label": "bev_h_",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-24ep",
        "peekOfCode": "bev_h_ = 200\nbev_w_ = 200\nframes = (0,)\ngroup_detr = 11\nvoxel_size = [102.4 / bev_h_, 102.4 / bev_w_, 8]\nida_aug_conf = {\n    \"reisze\": [512, 544, 576, 608, 640, 672, 704, 736, 768],  #  (0.8, 1.2)\n    \"crop\": (0, 260, 1600, 900),\n    \"H\": 900,\n    \"W\": 1600,",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-24ep",
        "documentation": {}
    },
    {
        "label": "bev_w_",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-24ep",
        "peekOfCode": "bev_w_ = 200\nframes = (0,)\ngroup_detr = 11\nvoxel_size = [102.4 / bev_h_, 102.4 / bev_w_, 8]\nida_aug_conf = {\n    \"reisze\": [512, 544, 576, 608, 640, 672, 704, 736, 768],  #  (0.8, 1.2)\n    \"crop\": (0, 260, 1600, 900),\n    \"H\": 900,\n    \"W\": 1600,\n    \"rand_flip\": True,",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-24ep",
        "documentation": {}
    },
    {
        "label": "frames",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-24ep",
        "peekOfCode": "frames = (0,)\ngroup_detr = 11\nvoxel_size = [102.4 / bev_h_, 102.4 / bev_w_, 8]\nida_aug_conf = {\n    \"reisze\": [512, 544, 576, 608, 640, 672, 704, 736, 768],  #  (0.8, 1.2)\n    \"crop\": (0, 260, 1600, 900),\n    \"H\": 900,\n    \"W\": 1600,\n    \"rand_flip\": True,\n}",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-24ep",
        "documentation": {}
    },
    {
        "label": "group_detr",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-24ep",
        "peekOfCode": "group_detr = 11\nvoxel_size = [102.4 / bev_h_, 102.4 / bev_w_, 8]\nida_aug_conf = {\n    \"reisze\": [512, 544, 576, 608, 640, 672, 704, 736, 768],  #  (0.8, 1.2)\n    \"crop\": (0, 260, 1600, 900),\n    \"H\": 900,\n    \"W\": 1600,\n    \"rand_flip\": True,\n}\nida_aug_conf_eval = {",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-24ep",
        "documentation": {}
    },
    {
        "label": "voxel_size",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-24ep",
        "peekOfCode": "voxel_size = [102.4 / bev_h_, 102.4 / bev_w_, 8]\nida_aug_conf = {\n    \"reisze\": [512, 544, 576, 608, 640, 672, 704, 736, 768],  #  (0.8, 1.2)\n    \"crop\": (0, 260, 1600, 900),\n    \"H\": 900,\n    \"W\": 1600,\n    \"rand_flip\": True,\n}\nida_aug_conf_eval = {\n    \"reisze\": [640, ],",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-24ep",
        "documentation": {}
    },
    {
        "label": "ida_aug_conf",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-24ep",
        "peekOfCode": "ida_aug_conf = {\n    \"reisze\": [512, 544, 576, 608, 640, 672, 704, 736, 768],  #  (0.8, 1.2)\n    \"crop\": (0, 260, 1600, 900),\n    \"H\": 900,\n    \"W\": 1600,\n    \"rand_flip\": True,\n}\nida_aug_conf_eval = {\n    \"reisze\": [640, ],\n    \"crop\": (0, 260, 1600, 900),",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-24ep",
        "documentation": {}
    },
    {
        "label": "ida_aug_conf_eval",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-24ep",
        "peekOfCode": "ida_aug_conf_eval = {\n    \"reisze\": [640, ],\n    \"crop\": (0, 260, 1600, 900),\n    \"H\": 900,\n    \"W\": 1600,\n    \"rand_flip\": False,\n}\n# file_client_args = dict(backend='disk')\n# Uncomment the following if use ceph or other file clients.\n# See https://mmcv.readthedocs.io/en/latest/api.html#mmcv.fileio.FileClient",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-24ep",
        "documentation": {}
    },
    {
        "label": "train_pipeline",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-24ep",
        "peekOfCode": "train_pipeline = [\n    dict(type='LoadMultiViewImageFromFiles', to_float32=True),\n    dict(type='PhotoMetricDistortionMultiViewImage'),\n    dict(type='LoadAnnotations3D', with_bbox_3d=True, with_label_3d=True, with_attr_label=False),\n    dict(type='GlobalRotScaleTransImage',\n        rot_range=[-22.5, 22.5],\n        scale_ratio_range=[0.95, 1.05],\n        translation_std=[0, 0, 0],\n        reverse_angle=True,\n        training=True,",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-24ep",
        "documentation": {}
    },
    {
        "label": "eval_pipeline",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-24ep",
        "peekOfCode": "eval_pipeline = [\n    dict(type='LoadMultiViewImageFromFiles', to_float32=True, ),\n    dict(type='CropResizeFlipImage', data_aug_conf=ida_aug_conf_eval, training=False, debug=False),\n    dict(type='NormalizeMultiviewImage', **img_norm_cfg),\n    dict(type='PadMultiViewImage', size_divisor=32),\n    dict(\n        type='MultiScaleFlipAug3D',\n        img_scale=(1600, 640),\n        pts_scale_ratio=1,\n        flip=False,",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-24ep",
        "documentation": {}
    },
    {
        "label": "data",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-24ep",
        "peekOfCode": "data = dict(\n    samples_per_gpu=1,\n    workers_per_gpu=4,\n    persistent_workers=True,\n    train=dict(\n        type='CustomNuScenesDatasetV2',\n        frames=frames,\n        data_root=data_root,\n        ann_file=data_root + 'nuscenes_infos_temporal_train.pkl',\n        pipeline=train_pipeline,",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-24ep",
        "documentation": {}
    },
    {
        "label": "evaluation",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-24ep",
        "peekOfCode": "evaluation = dict(interval=4, pipeline=eval_pipeline)\n# model\nload_from = './ckpts/fcos_r50_coco_2mmdet.pth'\nplugin = True\nplugin_dir = 'projects/mmdet3d_plugin/'\n_dim_ = 256\n_pos_dim_ = 128\n_ffn_dim_ = 512\n_num_levels_ = 4\n_num_mono_levels_ = 5",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-24ep",
        "documentation": {}
    },
    {
        "label": "load_from",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-24ep",
        "peekOfCode": "load_from = './ckpts/fcos_r50_coco_2mmdet.pth'\nplugin = True\nplugin_dir = 'projects/mmdet3d_plugin/'\n_dim_ = 256\n_pos_dim_ = 128\n_ffn_dim_ = 512\n_num_levels_ = 4\n_num_mono_levels_ = 5\nmodel = dict(\n    type='BEVFormerV2',",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-24ep",
        "documentation": {}
    },
    {
        "label": "plugin",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-24ep",
        "peekOfCode": "plugin = True\nplugin_dir = 'projects/mmdet3d_plugin/'\n_dim_ = 256\n_pos_dim_ = 128\n_ffn_dim_ = 512\n_num_levels_ = 4\n_num_mono_levels_ = 5\nmodel = dict(\n    type='BEVFormerV2',\n    use_grid_mask=True,",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-24ep",
        "documentation": {}
    },
    {
        "label": "plugin_dir",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-24ep",
        "peekOfCode": "plugin_dir = 'projects/mmdet3d_plugin/'\n_dim_ = 256\n_pos_dim_ = 128\n_ffn_dim_ = 512\n_num_levels_ = 4\n_num_mono_levels_ = 5\nmodel = dict(\n    type='BEVFormerV2',\n    use_grid_mask=True,\n    video_test_mode=False,",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-24ep",
        "documentation": {}
    },
    {
        "label": "_dim_",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-24ep",
        "peekOfCode": "_dim_ = 256\n_pos_dim_ = 128\n_ffn_dim_ = 512\n_num_levels_ = 4\n_num_mono_levels_ = 5\nmodel = dict(\n    type='BEVFormerV2',\n    use_grid_mask=True,\n    video_test_mode=False,\n    num_levels=_num_levels_,",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-24ep",
        "documentation": {}
    },
    {
        "label": "_pos_dim_",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-24ep",
        "peekOfCode": "_pos_dim_ = 128\n_ffn_dim_ = 512\n_num_levels_ = 4\n_num_mono_levels_ = 5\nmodel = dict(\n    type='BEVFormerV2',\n    use_grid_mask=True,\n    video_test_mode=False,\n    num_levels=_num_levels_,\n    num_mono_levels=_num_mono_levels_,",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-24ep",
        "documentation": {}
    },
    {
        "label": "_ffn_dim_",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-24ep",
        "peekOfCode": "_ffn_dim_ = 512\n_num_levels_ = 4\n_num_mono_levels_ = 5\nmodel = dict(\n    type='BEVFormerV2',\n    use_grid_mask=True,\n    video_test_mode=False,\n    num_levels=_num_levels_,\n    num_mono_levels=_num_mono_levels_,\n    mono_loss_weight=1.0,",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-24ep",
        "documentation": {}
    },
    {
        "label": "_num_levels_",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-24ep",
        "peekOfCode": "_num_levels_ = 4\n_num_mono_levels_ = 5\nmodel = dict(\n    type='BEVFormerV2',\n    use_grid_mask=True,\n    video_test_mode=False,\n    num_levels=_num_levels_,\n    num_mono_levels=_num_mono_levels_,\n    mono_loss_weight=1.0,\n    frames=frames,",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-24ep",
        "documentation": {}
    },
    {
        "label": "_num_mono_levels_",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-24ep",
        "peekOfCode": "_num_mono_levels_ = 5\nmodel = dict(\n    type='BEVFormerV2',\n    use_grid_mask=True,\n    video_test_mode=False,\n    num_levels=_num_levels_,\n    num_mono_levels=_num_mono_levels_,\n    mono_loss_weight=1.0,\n    frames=frames,\n    img_backbone=dict(",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-24ep",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-24ep",
        "peekOfCode": "model = dict(\n    type='BEVFormerV2',\n    use_grid_mask=True,\n    video_test_mode=False,\n    num_levels=_num_levels_,\n    num_mono_levels=_num_mono_levels_,\n    mono_loss_weight=1.0,\n    frames=frames,\n    img_backbone=dict(\n        type='ResNet',",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-24ep",
        "documentation": {}
    },
    {
        "label": "optimizer",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-24ep",
        "peekOfCode": "optimizer = dict(\n    type='AdamW',\n    lr=4e-4,\n    paramwise_cfg=dict(\n        custom_keys=dict(\n            img_backbone=dict(lr_mult=0.5),\n        )),\n    weight_decay=0.01)\noptimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))\n# learning policy",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-24ep",
        "documentation": {}
    },
    {
        "label": "optimizer_config",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-24ep",
        "peekOfCode": "optimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))\n# learning policy\nlr_config = dict(\n    policy='step',\n    warmup='linear',\n    warmup_iters=2000,\n    warmup_ratio=1.0 / 3,\n    step=[20, ])\ntotal_epochs = 24\nrunner = dict(type='EpochBasedRunner', max_epochs=total_epochs)",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-24ep",
        "documentation": {}
    },
    {
        "label": "lr_config",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-24ep",
        "peekOfCode": "lr_config = dict(\n    policy='step',\n    warmup='linear',\n    warmup_iters=2000,\n    warmup_ratio=1.0 / 3,\n    step=[20, ])\ntotal_epochs = 24\nrunner = dict(type='EpochBasedRunner', max_epochs=total_epochs)",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-24ep",
        "documentation": {}
    },
    {
        "label": "total_epochs",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-24ep",
        "peekOfCode": "total_epochs = 24\nrunner = dict(type='EpochBasedRunner', max_epochs=total_epochs)",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-24ep",
        "documentation": {}
    },
    {
        "label": "runner",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-24ep",
        "peekOfCode": "runner = dict(type='EpochBasedRunner', max_epochs=total_epochs)",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-24ep",
        "documentation": {}
    },
    {
        "label": "_base_",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-48ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-48ep",
        "peekOfCode": "_base_ = [\n    '../_base_/default_runtime.py'\n]\n# Dataset\n# If point cloud range is changed, the models should also change their point\n# cloud range accordingly\npoint_cloud_range = [-51.2, -51.2, -5.0, 51.2, 51.2, 3.0]\n# For nuScenes we usually do 10-class detection\nclass_names = [\n    'barrier', 'bicycle', 'bus', 'car', 'construction_vehicle', 'motorcycle',",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-48ep",
        "documentation": {}
    },
    {
        "label": "point_cloud_range",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-48ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-48ep",
        "peekOfCode": "point_cloud_range = [-51.2, -51.2, -5.0, 51.2, 51.2, 3.0]\n# For nuScenes we usually do 10-class detection\nclass_names = [\n    'barrier', 'bicycle', 'bus', 'car', 'construction_vehicle', 'motorcycle',\n    'pedestrian', 'traffic_cone', 'trailer', 'truck'\n]\ndataset_type = 'CustomNuScenesDatasetV2'\ndata_root = 'data/nuscenes/'\n# Input modality for nuScenes dataset, this is consistent with the submission\n# format which requires the information in input_modality.",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-48ep",
        "documentation": {}
    },
    {
        "label": "class_names",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-48ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-48ep",
        "peekOfCode": "class_names = [\n    'barrier', 'bicycle', 'bus', 'car', 'construction_vehicle', 'motorcycle',\n    'pedestrian', 'traffic_cone', 'trailer', 'truck'\n]\ndataset_type = 'CustomNuScenesDatasetV2'\ndata_root = 'data/nuscenes/'\n# Input modality for nuScenes dataset, this is consistent with the submission\n# format which requires the information in input_modality.\ninput_modality = dict(\n    use_lidar=False,",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-48ep",
        "documentation": {}
    },
    {
        "label": "dataset_type",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-48ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-48ep",
        "peekOfCode": "dataset_type = 'CustomNuScenesDatasetV2'\ndata_root = 'data/nuscenes/'\n# Input modality for nuScenes dataset, this is consistent with the submission\n# format which requires the information in input_modality.\ninput_modality = dict(\n    use_lidar=False,\n    use_camera=True,\n    use_radar=False,\n    use_map=False,\n    use_external=False)",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-48ep",
        "documentation": {}
    },
    {
        "label": "data_root",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-48ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-48ep",
        "peekOfCode": "data_root = 'data/nuscenes/'\n# Input modality for nuScenes dataset, this is consistent with the submission\n# format which requires the information in input_modality.\ninput_modality = dict(\n    use_lidar=False,\n    use_camera=True,\n    use_radar=False,\n    use_map=False,\n    use_external=False)\nimg_norm_cfg = dict(mean=[103.53, 116.28, 123.675], std=[1, 1, 1], to_rgb=False)",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-48ep",
        "documentation": {}
    },
    {
        "label": "input_modality",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-48ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-48ep",
        "peekOfCode": "input_modality = dict(\n    use_lidar=False,\n    use_camera=True,\n    use_radar=False,\n    use_map=False,\n    use_external=False)\nimg_norm_cfg = dict(mean=[103.53, 116.28, 123.675], std=[1, 1, 1], to_rgb=False)\nbev_h_ = 200\nbev_w_ = 200\nframes = (0,)",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-48ep",
        "documentation": {}
    },
    {
        "label": "img_norm_cfg",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-48ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-48ep",
        "peekOfCode": "img_norm_cfg = dict(mean=[103.53, 116.28, 123.675], std=[1, 1, 1], to_rgb=False)\nbev_h_ = 200\nbev_w_ = 200\nframes = (0,)\ngroup_detr = 11\nvoxel_size = [102.4 / bev_h_, 102.4 / bev_w_, 8]\nida_aug_conf = {\n    \"reisze\": [512, 544, 576, 608, 640, 672, 704, 736, 768],  #  (0.8, 1.2)\n    \"crop\": (0, 260, 1600, 900),\n    \"H\": 900,",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-48ep",
        "documentation": {}
    },
    {
        "label": "bev_h_",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-48ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-48ep",
        "peekOfCode": "bev_h_ = 200\nbev_w_ = 200\nframes = (0,)\ngroup_detr = 11\nvoxel_size = [102.4 / bev_h_, 102.4 / bev_w_, 8]\nida_aug_conf = {\n    \"reisze\": [512, 544, 576, 608, 640, 672, 704, 736, 768],  #  (0.8, 1.2)\n    \"crop\": (0, 260, 1600, 900),\n    \"H\": 900,\n    \"W\": 1600,",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-48ep",
        "documentation": {}
    },
    {
        "label": "bev_w_",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-48ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-48ep",
        "peekOfCode": "bev_w_ = 200\nframes = (0,)\ngroup_detr = 11\nvoxel_size = [102.4 / bev_h_, 102.4 / bev_w_, 8]\nida_aug_conf = {\n    \"reisze\": [512, 544, 576, 608, 640, 672, 704, 736, 768],  #  (0.8, 1.2)\n    \"crop\": (0, 260, 1600, 900),\n    \"H\": 900,\n    \"W\": 1600,\n    \"rand_flip\": True,",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-48ep",
        "documentation": {}
    },
    {
        "label": "frames",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-48ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-48ep",
        "peekOfCode": "frames = (0,)\ngroup_detr = 11\nvoxel_size = [102.4 / bev_h_, 102.4 / bev_w_, 8]\nida_aug_conf = {\n    \"reisze\": [512, 544, 576, 608, 640, 672, 704, 736, 768],  #  (0.8, 1.2)\n    \"crop\": (0, 260, 1600, 900),\n    \"H\": 900,\n    \"W\": 1600,\n    \"rand_flip\": True,\n}",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-48ep",
        "documentation": {}
    },
    {
        "label": "group_detr",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-48ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-48ep",
        "peekOfCode": "group_detr = 11\nvoxel_size = [102.4 / bev_h_, 102.4 / bev_w_, 8]\nida_aug_conf = {\n    \"reisze\": [512, 544, 576, 608, 640, 672, 704, 736, 768],  #  (0.8, 1.2)\n    \"crop\": (0, 260, 1600, 900),\n    \"H\": 900,\n    \"W\": 1600,\n    \"rand_flip\": True,\n}\nida_aug_conf_eval = {",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-48ep",
        "documentation": {}
    },
    {
        "label": "voxel_size",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-48ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-48ep",
        "peekOfCode": "voxel_size = [102.4 / bev_h_, 102.4 / bev_w_, 8]\nida_aug_conf = {\n    \"reisze\": [512, 544, 576, 608, 640, 672, 704, 736, 768],  #  (0.8, 1.2)\n    \"crop\": (0, 260, 1600, 900),\n    \"H\": 900,\n    \"W\": 1600,\n    \"rand_flip\": True,\n}\nida_aug_conf_eval = {\n    \"reisze\": [640, ],",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-48ep",
        "documentation": {}
    },
    {
        "label": "ida_aug_conf",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-48ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-48ep",
        "peekOfCode": "ida_aug_conf = {\n    \"reisze\": [512, 544, 576, 608, 640, 672, 704, 736, 768],  #  (0.8, 1.2)\n    \"crop\": (0, 260, 1600, 900),\n    \"H\": 900,\n    \"W\": 1600,\n    \"rand_flip\": True,\n}\nida_aug_conf_eval = {\n    \"reisze\": [640, ],\n    \"crop\": (0, 260, 1600, 900),",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-48ep",
        "documentation": {}
    },
    {
        "label": "ida_aug_conf_eval",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-48ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-48ep",
        "peekOfCode": "ida_aug_conf_eval = {\n    \"reisze\": [640, ],\n    \"crop\": (0, 260, 1600, 900),\n    \"H\": 900,\n    \"W\": 1600,\n    \"rand_flip\": False,\n}\n# file_client_args = dict(backend='disk')\n# Uncomment the following if use ceph or other file clients.\n# See https://mmcv.readthedocs.io/en/latest/api.html#mmcv.fileio.FileClient",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-48ep",
        "documentation": {}
    },
    {
        "label": "train_pipeline",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-48ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-48ep",
        "peekOfCode": "train_pipeline = [\n    dict(type='LoadMultiViewImageFromFiles', to_float32=True),\n    dict(type='PhotoMetricDistortionMultiViewImage'),\n    dict(type='LoadAnnotations3D', with_bbox_3d=True, with_label_3d=True, with_attr_label=False),\n    dict(type='GlobalRotScaleTransImage',\n        rot_range=[-22.5, 22.5],\n        scale_ratio_range=[0.95, 1.05],\n        translation_std=[0, 0, 0],\n        reverse_angle=True,\n        training=True,",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-48ep",
        "documentation": {}
    },
    {
        "label": "eval_pipeline",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-48ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-48ep",
        "peekOfCode": "eval_pipeline = [\n    dict(type='LoadMultiViewImageFromFiles', to_float32=True, ),\n    dict(type='CropResizeFlipImage', data_aug_conf=ida_aug_conf_eval, training=False, debug=False),\n    dict(type='NormalizeMultiviewImage', **img_norm_cfg),\n    dict(type='PadMultiViewImage', size_divisor=32),\n    dict(\n        type='MultiScaleFlipAug3D',\n        img_scale=(1600, 640),\n        pts_scale_ratio=1,\n        flip=False,",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-48ep",
        "documentation": {}
    },
    {
        "label": "data",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-48ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-48ep",
        "peekOfCode": "data = dict(\n    samples_per_gpu=1,\n    workers_per_gpu=4,\n    persistent_workers=True,\n    train=dict(\n        type='CustomNuScenesDatasetV2',\n        frames=frames,\n        data_root=data_root,\n        ann_file=data_root + 'nuscenes_infos_temporal_train.pkl',\n        pipeline=train_pipeline,",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-48ep",
        "documentation": {}
    },
    {
        "label": "evaluation",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-48ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-48ep",
        "peekOfCode": "evaluation = dict(interval=4, pipeline=eval_pipeline)\n# model\nload_from = './ckpts/fcos_r50_coco_2mmdet.pth'\nplugin = True\nplugin_dir = 'projects/mmdet3d_plugin/'\n_dim_ = 256\n_pos_dim_ = 128\n_ffn_dim_ = 512\n_num_levels_ = 4\n_num_mono_levels_ = 5",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-48ep",
        "documentation": {}
    },
    {
        "label": "load_from",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-48ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-48ep",
        "peekOfCode": "load_from = './ckpts/fcos_r50_coco_2mmdet.pth'\nplugin = True\nplugin_dir = 'projects/mmdet3d_plugin/'\n_dim_ = 256\n_pos_dim_ = 128\n_ffn_dim_ = 512\n_num_levels_ = 4\n_num_mono_levels_ = 5\nmodel = dict(\n    type='BEVFormerV2',",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-48ep",
        "documentation": {}
    },
    {
        "label": "plugin",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-48ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-48ep",
        "peekOfCode": "plugin = True\nplugin_dir = 'projects/mmdet3d_plugin/'\n_dim_ = 256\n_pos_dim_ = 128\n_ffn_dim_ = 512\n_num_levels_ = 4\n_num_mono_levels_ = 5\nmodel = dict(\n    type='BEVFormerV2',\n    use_grid_mask=True,",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-48ep",
        "documentation": {}
    },
    {
        "label": "plugin_dir",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-48ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-48ep",
        "peekOfCode": "plugin_dir = 'projects/mmdet3d_plugin/'\n_dim_ = 256\n_pos_dim_ = 128\n_ffn_dim_ = 512\n_num_levels_ = 4\n_num_mono_levels_ = 5\nmodel = dict(\n    type='BEVFormerV2',\n    use_grid_mask=True,\n    video_test_mode=False,",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-48ep",
        "documentation": {}
    },
    {
        "label": "_dim_",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-48ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-48ep",
        "peekOfCode": "_dim_ = 256\n_pos_dim_ = 128\n_ffn_dim_ = 512\n_num_levels_ = 4\n_num_mono_levels_ = 5\nmodel = dict(\n    type='BEVFormerV2',\n    use_grid_mask=True,\n    video_test_mode=False,\n    num_levels=_num_levels_,",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-48ep",
        "documentation": {}
    },
    {
        "label": "_pos_dim_",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-48ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-48ep",
        "peekOfCode": "_pos_dim_ = 128\n_ffn_dim_ = 512\n_num_levels_ = 4\n_num_mono_levels_ = 5\nmodel = dict(\n    type='BEVFormerV2',\n    use_grid_mask=True,\n    video_test_mode=False,\n    num_levels=_num_levels_,\n    num_mono_levels=_num_mono_levels_,",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-48ep",
        "documentation": {}
    },
    {
        "label": "_ffn_dim_",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-48ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-48ep",
        "peekOfCode": "_ffn_dim_ = 512\n_num_levels_ = 4\n_num_mono_levels_ = 5\nmodel = dict(\n    type='BEVFormerV2',\n    use_grid_mask=True,\n    video_test_mode=False,\n    num_levels=_num_levels_,\n    num_mono_levels=_num_mono_levels_,\n    mono_loss_weight=1.0,",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-48ep",
        "documentation": {}
    },
    {
        "label": "_num_levels_",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-48ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-48ep",
        "peekOfCode": "_num_levels_ = 4\n_num_mono_levels_ = 5\nmodel = dict(\n    type='BEVFormerV2',\n    use_grid_mask=True,\n    video_test_mode=False,\n    num_levels=_num_levels_,\n    num_mono_levels=_num_mono_levels_,\n    mono_loss_weight=1.0,\n    frames=frames,",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-48ep",
        "documentation": {}
    },
    {
        "label": "_num_mono_levels_",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-48ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-48ep",
        "peekOfCode": "_num_mono_levels_ = 5\nmodel = dict(\n    type='BEVFormerV2',\n    use_grid_mask=True,\n    video_test_mode=False,\n    num_levels=_num_levels_,\n    num_mono_levels=_num_mono_levels_,\n    mono_loss_weight=1.0,\n    frames=frames,\n    img_backbone=dict(",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-48ep",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-48ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-48ep",
        "peekOfCode": "model = dict(\n    type='BEVFormerV2',\n    use_grid_mask=True,\n    video_test_mode=False,\n    num_levels=_num_levels_,\n    num_mono_levels=_num_mono_levels_,\n    mono_loss_weight=1.0,\n    frames=frames,\n    img_backbone=dict(\n        type='ResNet',",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-48ep",
        "documentation": {}
    },
    {
        "label": "optimizer",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-48ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-48ep",
        "peekOfCode": "optimizer = dict(\n    type='AdamW',\n    lr=4e-4,\n    paramwise_cfg=dict(\n        custom_keys=dict(\n            img_backbone=dict(lr_mult=0.5),\n        )),\n    weight_decay=0.01)\noptimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))\n# learning policy",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-48ep",
        "documentation": {}
    },
    {
        "label": "optimizer_config",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-48ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-48ep",
        "peekOfCode": "optimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))\n# learning policy\nlr_config = dict(\n    policy='step',\n    warmup='linear',\n    warmup_iters=2000,\n    warmup_ratio=1.0 / 3,\n    step=[44, ])\ntotal_epochs = 48\nrunner = dict(type='EpochBasedRunner', max_epochs=total_epochs)",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-48ep",
        "documentation": {}
    },
    {
        "label": "lr_config",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-48ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-48ep",
        "peekOfCode": "lr_config = dict(\n    policy='step',\n    warmup='linear',\n    warmup_iters=2000,\n    warmup_ratio=1.0 / 3,\n    step=[44, ])\ntotal_epochs = 48\nrunner = dict(type='EpochBasedRunner', max_epochs=total_epochs)",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-48ep",
        "documentation": {}
    },
    {
        "label": "total_epochs",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-48ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-48ep",
        "peekOfCode": "total_epochs = 48\nrunner = dict(type='EpochBasedRunner', max_epochs=total_epochs)",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-48ep",
        "documentation": {}
    },
    {
        "label": "runner",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-48ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-48ep",
        "peekOfCode": "runner = dict(type='EpochBasedRunner', max_epochs=total_epochs)",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-48ep",
        "documentation": {}
    },
    {
        "label": "_base_",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-24ep",
        "peekOfCode": "_base_ = [\n    '../_base_/default_runtime.py'\n]\n# Dataset\n# If point cloud range is changed, the models should also change their point\n# cloud range accordingly\npoint_cloud_range = [-51.2, -51.2, -5.0, 51.2, 51.2, 3.0]\n# For nuScenes we usually do 10-class detection\nclass_names = [\n    'barrier', 'bicycle', 'bus', 'car', 'construction_vehicle', 'motorcycle',",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-24ep",
        "documentation": {}
    },
    {
        "label": "point_cloud_range",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-24ep",
        "peekOfCode": "point_cloud_range = [-51.2, -51.2, -5.0, 51.2, 51.2, 3.0]\n# For nuScenes we usually do 10-class detection\nclass_names = [\n    'barrier', 'bicycle', 'bus', 'car', 'construction_vehicle', 'motorcycle',\n    'pedestrian', 'traffic_cone', 'trailer', 'truck'\n]\ndataset_type = 'CustomNuScenesDatasetV2'\ndata_root = 'data/nuscenes/'\n# Input modality for nuScenes dataset, this is consistent with the submission\n# format which requires the information in input_modality.",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-24ep",
        "documentation": {}
    },
    {
        "label": "class_names",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-24ep",
        "peekOfCode": "class_names = [\n    'barrier', 'bicycle', 'bus', 'car', 'construction_vehicle', 'motorcycle',\n    'pedestrian', 'traffic_cone', 'trailer', 'truck'\n]\ndataset_type = 'CustomNuScenesDatasetV2'\ndata_root = 'data/nuscenes/'\n# Input modality for nuScenes dataset, this is consistent with the submission\n# format which requires the information in input_modality.\ninput_modality = dict(\n    use_lidar=False,",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-24ep",
        "documentation": {}
    },
    {
        "label": "dataset_type",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-24ep",
        "peekOfCode": "dataset_type = 'CustomNuScenesDatasetV2'\ndata_root = 'data/nuscenes/'\n# Input modality for nuScenes dataset, this is consistent with the submission\n# format which requires the information in input_modality.\ninput_modality = dict(\n    use_lidar=False,\n    use_camera=True,\n    use_radar=False,\n    use_map=False,\n    use_external=False)",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-24ep",
        "documentation": {}
    },
    {
        "label": "data_root",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-24ep",
        "peekOfCode": "data_root = 'data/nuscenes/'\n# Input modality for nuScenes dataset, this is consistent with the submission\n# format which requires the information in input_modality.\ninput_modality = dict(\n    use_lidar=False,\n    use_camera=True,\n    use_radar=False,\n    use_map=False,\n    use_external=False)\nimg_norm_cfg = dict(mean=[103.53, 116.28, 123.675], std=[1, 1, 1], to_rgb=False)",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-24ep",
        "documentation": {}
    },
    {
        "label": "input_modality",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-24ep",
        "peekOfCode": "input_modality = dict(\n    use_lidar=False,\n    use_camera=True,\n    use_radar=False,\n    use_map=False,\n    use_external=False)\nimg_norm_cfg = dict(mean=[103.53, 116.28, 123.675], std=[1, 1, 1], to_rgb=False)\nbev_h_ = 200\nbev_w_ = 200\nframes = (0,)",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-24ep",
        "documentation": {}
    },
    {
        "label": "img_norm_cfg",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-24ep",
        "peekOfCode": "img_norm_cfg = dict(mean=[103.53, 116.28, 123.675], std=[1, 1, 1], to_rgb=False)\nbev_h_ = 200\nbev_w_ = 200\nframes = (0,)\nvoxel_size = [102.4 / bev_h_, 102.4 / bev_w_, 8]\nida_aug_conf = {\n    \"reisze\": [640, ],\n    \"crop\": (0, 260, 1600, 900),\n    \"H\": 900,\n    \"W\": 1600,",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-24ep",
        "documentation": {}
    },
    {
        "label": "bev_h_",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-24ep",
        "peekOfCode": "bev_h_ = 200\nbev_w_ = 200\nframes = (0,)\nvoxel_size = [102.4 / bev_h_, 102.4 / bev_w_, 8]\nida_aug_conf = {\n    \"reisze\": [640, ],\n    \"crop\": (0, 260, 1600, 900),\n    \"H\": 900,\n    \"W\": 1600,\n    \"rand_flip\": False,",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-24ep",
        "documentation": {}
    },
    {
        "label": "bev_w_",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-24ep",
        "peekOfCode": "bev_w_ = 200\nframes = (0,)\nvoxel_size = [102.4 / bev_h_, 102.4 / bev_w_, 8]\nida_aug_conf = {\n    \"reisze\": [640, ],\n    \"crop\": (0, 260, 1600, 900),\n    \"H\": 900,\n    \"W\": 1600,\n    \"rand_flip\": False,\n}",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-24ep",
        "documentation": {}
    },
    {
        "label": "frames",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-24ep",
        "peekOfCode": "frames = (0,)\nvoxel_size = [102.4 / bev_h_, 102.4 / bev_w_, 8]\nida_aug_conf = {\n    \"reisze\": [640, ],\n    \"crop\": (0, 260, 1600, 900),\n    \"H\": 900,\n    \"W\": 1600,\n    \"rand_flip\": False,\n}\nida_aug_conf_eval = {",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-24ep",
        "documentation": {}
    },
    {
        "label": "voxel_size",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-24ep",
        "peekOfCode": "voxel_size = [102.4 / bev_h_, 102.4 / bev_w_, 8]\nida_aug_conf = {\n    \"reisze\": [640, ],\n    \"crop\": (0, 260, 1600, 900),\n    \"H\": 900,\n    \"W\": 1600,\n    \"rand_flip\": False,\n}\nida_aug_conf_eval = {\n    \"reisze\": [640, ],",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-24ep",
        "documentation": {}
    },
    {
        "label": "ida_aug_conf",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-24ep",
        "peekOfCode": "ida_aug_conf = {\n    \"reisze\": [640, ],\n    \"crop\": (0, 260, 1600, 900),\n    \"H\": 900,\n    \"W\": 1600,\n    \"rand_flip\": False,\n}\nida_aug_conf_eval = {\n    \"reisze\": [640, ],\n    \"crop\": (0, 260, 1600, 900),",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-24ep",
        "documentation": {}
    },
    {
        "label": "ida_aug_conf_eval",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-24ep",
        "peekOfCode": "ida_aug_conf_eval = {\n    \"reisze\": [640, ],\n    \"crop\": (0, 260, 1600, 900),\n    \"H\": 900,\n    \"W\": 1600,\n    \"rand_flip\": False,\n}\n# file_client_args = dict(backend='disk')\n# Uncomment the following if use ceph or other file clients.\n# See https://mmcv.readthedocs.io/en/latest/api.html#mmcv.fileio.FileClient",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-24ep",
        "documentation": {}
    },
    {
        "label": "train_pipeline",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-24ep",
        "peekOfCode": "train_pipeline = [\n    dict(type='LoadMultiViewImageFromFiles', to_float32=True),\n    dict(type='PhotoMetricDistortionMultiViewImage'),\n    dict(type='LoadAnnotations3D', with_bbox_3d=True, with_label_3d=True, with_attr_label=False),\n    dict(\n        type='ObjectRangeFilter',\n        point_cloud_range=point_cloud_range),\n    dict(\n        type='ObjectNameFilter',\n        classes=class_names),",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-24ep",
        "documentation": {}
    },
    {
        "label": "eval_pipeline",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-24ep",
        "peekOfCode": "eval_pipeline = [\n    dict(type='LoadMultiViewImageFromFiles', to_float32=True, ),\n    dict(type='CropResizeFlipImage', data_aug_conf=ida_aug_conf_eval, training=False, debug=False),\n    dict(type='NormalizeMultiviewImage', **img_norm_cfg),\n    dict(type='PadMultiViewImage', size_divisor=32),\n    dict(\n        type='MultiScaleFlipAug3D',\n        img_scale=(1600, 640),\n        pts_scale_ratio=1,\n        flip=False,",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-24ep",
        "documentation": {}
    },
    {
        "label": "data",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-24ep",
        "peekOfCode": "data = dict(\n    samples_per_gpu=1,\n    workers_per_gpu=4,\n    persistent_workers=True,\n    train=dict(\n        type='CustomNuScenesDatasetV2',\n        frames=frames,\n        data_root=data_root,\n        ann_file=data_root + 'nuscenes_infos_temporal_train.pkl',\n        pipeline=train_pipeline,",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-24ep",
        "documentation": {}
    },
    {
        "label": "evaluation",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-24ep",
        "peekOfCode": "evaluation = dict(interval=4, pipeline=eval_pipeline)\n# model\nload_from = './ckpts/fcos_r50_coco_2mmdet.pth'\nplugin = True\nplugin_dir = 'projects/mmdet3d_plugin/'\n_dim_ = 256\n_pos_dim_ = 128\n_ffn_dim_ = 512\n_num_levels_ = 4\n_num_mono_levels_ = 5",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-24ep",
        "documentation": {}
    },
    {
        "label": "load_from",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-24ep",
        "peekOfCode": "load_from = './ckpts/fcos_r50_coco_2mmdet.pth'\nplugin = True\nplugin_dir = 'projects/mmdet3d_plugin/'\n_dim_ = 256\n_pos_dim_ = 128\n_ffn_dim_ = 512\n_num_levels_ = 4\n_num_mono_levels_ = 5\nmodel = dict(\n    type='BEVFormerV2',",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-24ep",
        "documentation": {}
    },
    {
        "label": "plugin",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-24ep",
        "peekOfCode": "plugin = True\nplugin_dir = 'projects/mmdet3d_plugin/'\n_dim_ = 256\n_pos_dim_ = 128\n_ffn_dim_ = 512\n_num_levels_ = 4\n_num_mono_levels_ = 5\nmodel = dict(\n    type='BEVFormerV2',\n    use_grid_mask=True,",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-24ep",
        "documentation": {}
    },
    {
        "label": "plugin_dir",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-24ep",
        "peekOfCode": "plugin_dir = 'projects/mmdet3d_plugin/'\n_dim_ = 256\n_pos_dim_ = 128\n_ffn_dim_ = 512\n_num_levels_ = 4\n_num_mono_levels_ = 5\nmodel = dict(\n    type='BEVFormerV2',\n    use_grid_mask=True,\n    video_test_mode=False,",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-24ep",
        "documentation": {}
    },
    {
        "label": "_dim_",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-24ep",
        "peekOfCode": "_dim_ = 256\n_pos_dim_ = 128\n_ffn_dim_ = 512\n_num_levels_ = 4\n_num_mono_levels_ = 5\nmodel = dict(\n    type='BEVFormerV2',\n    use_grid_mask=True,\n    video_test_mode=False,\n    num_levels=_num_levels_,",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-24ep",
        "documentation": {}
    },
    {
        "label": "_pos_dim_",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-24ep",
        "peekOfCode": "_pos_dim_ = 128\n_ffn_dim_ = 512\n_num_levels_ = 4\n_num_mono_levels_ = 5\nmodel = dict(\n    type='BEVFormerV2',\n    use_grid_mask=True,\n    video_test_mode=False,\n    num_levels=_num_levels_,\n    num_mono_levels=_num_mono_levels_,",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-24ep",
        "documentation": {}
    },
    {
        "label": "_ffn_dim_",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-24ep",
        "peekOfCode": "_ffn_dim_ = 512\n_num_levels_ = 4\n_num_mono_levels_ = 5\nmodel = dict(\n    type='BEVFormerV2',\n    use_grid_mask=True,\n    video_test_mode=False,\n    num_levels=_num_levels_,\n    num_mono_levels=_num_mono_levels_,\n    mono_loss_weight=1.0,",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-24ep",
        "documentation": {}
    },
    {
        "label": "_num_levels_",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-24ep",
        "peekOfCode": "_num_levels_ = 4\n_num_mono_levels_ = 5\nmodel = dict(\n    type='BEVFormerV2',\n    use_grid_mask=True,\n    video_test_mode=False,\n    num_levels=_num_levels_,\n    num_mono_levels=_num_mono_levels_,\n    mono_loss_weight=1.0,\n    frames=frames,",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-24ep",
        "documentation": {}
    },
    {
        "label": "_num_mono_levels_",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-24ep",
        "peekOfCode": "_num_mono_levels_ = 5\nmodel = dict(\n    type='BEVFormerV2',\n    use_grid_mask=True,\n    video_test_mode=False,\n    num_levels=_num_levels_,\n    num_mono_levels=_num_mono_levels_,\n    mono_loss_weight=1.0,\n    frames=frames,\n    img_backbone=dict(",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-24ep",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-24ep",
        "peekOfCode": "model = dict(\n    type='BEVFormerV2',\n    use_grid_mask=True,\n    video_test_mode=False,\n    num_levels=_num_levels_,\n    num_mono_levels=_num_mono_levels_,\n    mono_loss_weight=1.0,\n    frames=frames,\n    img_backbone=dict(\n        type='ResNet',",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-24ep",
        "documentation": {}
    },
    {
        "label": "optimizer",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-24ep",
        "peekOfCode": "optimizer = dict(\n    type='AdamW',\n    lr=4e-4,\n    paramwise_cfg=dict(\n        custom_keys=dict(\n            img_backbone=dict(lr_mult=0.5),\n        )),\n    weight_decay=0.01)\noptimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))\n# learning policy",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-24ep",
        "documentation": {}
    },
    {
        "label": "optimizer_config",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-24ep",
        "peekOfCode": "optimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))\n# learning policy\nlr_config = dict(\n    policy='step',\n    warmup='linear',\n    warmup_iters=2000,\n    warmup_ratio=1.0 / 3,\n    step=[20, ])\ntotal_epochs = 24\nrunner = dict(type='EpochBasedRunner', max_epochs=total_epochs)",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-24ep",
        "documentation": {}
    },
    {
        "label": "lr_config",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-24ep",
        "peekOfCode": "lr_config = dict(\n    policy='step',\n    warmup='linear',\n    warmup_iters=2000,\n    warmup_ratio=1.0 / 3,\n    step=[20, ])\ntotal_epochs = 24\nrunner = dict(type='EpochBasedRunner', max_epochs=total_epochs)",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-24ep",
        "documentation": {}
    },
    {
        "label": "total_epochs",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-24ep",
        "peekOfCode": "total_epochs = 24\nrunner = dict(type='EpochBasedRunner', max_epochs=total_epochs)",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-24ep",
        "documentation": {}
    },
    {
        "label": "runner",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-24ep",
        "peekOfCode": "runner = dict(type='EpochBasedRunner', max_epochs=total_epochs)",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-24ep",
        "documentation": {}
    },
    {
        "label": "_base_",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-48ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-48ep",
        "peekOfCode": "_base_ = [\n    '../_base_/default_runtime.py'\n]\n# Dataset\n# If point cloud range is changed, the models should also change their point\n# cloud range accordingly\npoint_cloud_range = [-51.2, -51.2, -5.0, 51.2, 51.2, 3.0]\n# For nuScenes we usually do 10-class detection\nclass_names = [\n    'barrier', 'bicycle', 'bus', 'car', 'construction_vehicle', 'motorcycle',",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-48ep",
        "documentation": {}
    },
    {
        "label": "point_cloud_range",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-48ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-48ep",
        "peekOfCode": "point_cloud_range = [-51.2, -51.2, -5.0, 51.2, 51.2, 3.0]\n# For nuScenes we usually do 10-class detection\nclass_names = [\n    'barrier', 'bicycle', 'bus', 'car', 'construction_vehicle', 'motorcycle',\n    'pedestrian', 'traffic_cone', 'trailer', 'truck'\n]\ndataset_type = 'CustomNuScenesDatasetV2'\ndata_root = 'data/nuscenes/'\n# Input modality for nuScenes dataset, this is consistent with the submission\n# format which requires the information in input_modality.",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-48ep",
        "documentation": {}
    },
    {
        "label": "class_names",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-48ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-48ep",
        "peekOfCode": "class_names = [\n    'barrier', 'bicycle', 'bus', 'car', 'construction_vehicle', 'motorcycle',\n    'pedestrian', 'traffic_cone', 'trailer', 'truck'\n]\ndataset_type = 'CustomNuScenesDatasetV2'\ndata_root = 'data/nuscenes/'\n# Input modality for nuScenes dataset, this is consistent with the submission\n# format which requires the information in input_modality.\ninput_modality = dict(\n    use_lidar=False,",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-48ep",
        "documentation": {}
    },
    {
        "label": "dataset_type",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-48ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-48ep",
        "peekOfCode": "dataset_type = 'CustomNuScenesDatasetV2'\ndata_root = 'data/nuscenes/'\n# Input modality for nuScenes dataset, this is consistent with the submission\n# format which requires the information in input_modality.\ninput_modality = dict(\n    use_lidar=False,\n    use_camera=True,\n    use_radar=False,\n    use_map=False,\n    use_external=False)",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-48ep",
        "documentation": {}
    },
    {
        "label": "data_root",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-48ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-48ep",
        "peekOfCode": "data_root = 'data/nuscenes/'\n# Input modality for nuScenes dataset, this is consistent with the submission\n# format which requires the information in input_modality.\ninput_modality = dict(\n    use_lidar=False,\n    use_camera=True,\n    use_radar=False,\n    use_map=False,\n    use_external=False)\nimg_norm_cfg = dict(mean=[103.53, 116.28, 123.675], std=[1, 1, 1], to_rgb=False)",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-48ep",
        "documentation": {}
    },
    {
        "label": "input_modality",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-48ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-48ep",
        "peekOfCode": "input_modality = dict(\n    use_lidar=False,\n    use_camera=True,\n    use_radar=False,\n    use_map=False,\n    use_external=False)\nimg_norm_cfg = dict(mean=[103.53, 116.28, 123.675], std=[1, 1, 1], to_rgb=False)\nbev_h_ = 200\nbev_w_ = 200\nframes = (0,)",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-48ep",
        "documentation": {}
    },
    {
        "label": "img_norm_cfg",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-48ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-48ep",
        "peekOfCode": "img_norm_cfg = dict(mean=[103.53, 116.28, 123.675], std=[1, 1, 1], to_rgb=False)\nbev_h_ = 200\nbev_w_ = 200\nframes = (0,)\nvoxel_size = [102.4 / bev_h_, 102.4 / bev_w_, 8]\nida_aug_conf = {\n    \"reisze\": [640, ],\n    \"crop\": (0, 260, 1600, 900),\n    \"H\": 900,\n    \"W\": 1600,",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-48ep",
        "documentation": {}
    },
    {
        "label": "bev_h_",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-48ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-48ep",
        "peekOfCode": "bev_h_ = 200\nbev_w_ = 200\nframes = (0,)\nvoxel_size = [102.4 / bev_h_, 102.4 / bev_w_, 8]\nida_aug_conf = {\n    \"reisze\": [640, ],\n    \"crop\": (0, 260, 1600, 900),\n    \"H\": 900,\n    \"W\": 1600,\n    \"rand_flip\": False,",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-48ep",
        "documentation": {}
    },
    {
        "label": "bev_w_",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-48ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-48ep",
        "peekOfCode": "bev_w_ = 200\nframes = (0,)\nvoxel_size = [102.4 / bev_h_, 102.4 / bev_w_, 8]\nida_aug_conf = {\n    \"reisze\": [640, ],\n    \"crop\": (0, 260, 1600, 900),\n    \"H\": 900,\n    \"W\": 1600,\n    \"rand_flip\": False,\n}",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-48ep",
        "documentation": {}
    },
    {
        "label": "frames",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-48ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-48ep",
        "peekOfCode": "frames = (0,)\nvoxel_size = [102.4 / bev_h_, 102.4 / bev_w_, 8]\nida_aug_conf = {\n    \"reisze\": [640, ],\n    \"crop\": (0, 260, 1600, 900),\n    \"H\": 900,\n    \"W\": 1600,\n    \"rand_flip\": False,\n}\nida_aug_conf_eval = {",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-48ep",
        "documentation": {}
    },
    {
        "label": "voxel_size",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-48ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-48ep",
        "peekOfCode": "voxel_size = [102.4 / bev_h_, 102.4 / bev_w_, 8]\nida_aug_conf = {\n    \"reisze\": [640, ],\n    \"crop\": (0, 260, 1600, 900),\n    \"H\": 900,\n    \"W\": 1600,\n    \"rand_flip\": False,\n}\nida_aug_conf_eval = {\n    \"reisze\": [640, ],",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-48ep",
        "documentation": {}
    },
    {
        "label": "ida_aug_conf",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-48ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-48ep",
        "peekOfCode": "ida_aug_conf = {\n    \"reisze\": [640, ],\n    \"crop\": (0, 260, 1600, 900),\n    \"H\": 900,\n    \"W\": 1600,\n    \"rand_flip\": False,\n}\nida_aug_conf_eval = {\n    \"reisze\": [640, ],\n    \"crop\": (0, 260, 1600, 900),",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-48ep",
        "documentation": {}
    },
    {
        "label": "ida_aug_conf_eval",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-48ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-48ep",
        "peekOfCode": "ida_aug_conf_eval = {\n    \"reisze\": [640, ],\n    \"crop\": (0, 260, 1600, 900),\n    \"H\": 900,\n    \"W\": 1600,\n    \"rand_flip\": False,\n}\n# file_client_args = dict(backend='disk')\n# Uncomment the following if use ceph or other file clients.\n# See https://mmcv.readthedocs.io/en/latest/api.html#mmcv.fileio.FileClient",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-48ep",
        "documentation": {}
    },
    {
        "label": "train_pipeline",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-48ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-48ep",
        "peekOfCode": "train_pipeline = [\n    dict(type='LoadMultiViewImageFromFiles', to_float32=True),\n    dict(type='PhotoMetricDistortionMultiViewImage'),\n    dict(type='LoadAnnotations3D', with_bbox_3d=True, with_label_3d=True, with_attr_label=False),\n    dict(\n        type='ObjectRangeFilter',\n        point_cloud_range=point_cloud_range),\n    dict(\n        type='ObjectNameFilter',\n        classes=class_names),",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-48ep",
        "documentation": {}
    },
    {
        "label": "eval_pipeline",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-48ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-48ep",
        "peekOfCode": "eval_pipeline = [\n    dict(type='LoadMultiViewImageFromFiles', to_float32=True, ),\n    dict(type='CropResizeFlipImage', data_aug_conf=ida_aug_conf_eval, training=False, debug=False),\n    dict(type='NormalizeMultiviewImage', **img_norm_cfg),\n    dict(type='PadMultiViewImage', size_divisor=32),\n    dict(\n        type='MultiScaleFlipAug3D',\n        img_scale=(1600, 640),\n        pts_scale_ratio=1,\n        flip=False,",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-48ep",
        "documentation": {}
    },
    {
        "label": "data",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-48ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-48ep",
        "peekOfCode": "data = dict(\n    samples_per_gpu=1,\n    workers_per_gpu=4,\n    persistent_workers=True,\n    train=dict(\n        type='CustomNuScenesDatasetV2',\n        frames=frames,\n        data_root=data_root,\n        ann_file=data_root + 'nuscenes_infos_temporal_train.pkl',\n        pipeline=train_pipeline,",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-48ep",
        "documentation": {}
    },
    {
        "label": "evaluation",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-48ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-48ep",
        "peekOfCode": "evaluation = dict(interval=4, pipeline=eval_pipeline)\n# model\nload_from = './ckpts/fcos_r50_coco_2mmdet.pth'\nplugin = True\nplugin_dir = 'projects/mmdet3d_plugin/'\n_dim_ = 256\n_pos_dim_ = 128\n_ffn_dim_ = 512\n_num_levels_ = 4\n_num_mono_levels_ = 5",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-48ep",
        "documentation": {}
    },
    {
        "label": "load_from",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-48ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-48ep",
        "peekOfCode": "load_from = './ckpts/fcos_r50_coco_2mmdet.pth'\nplugin = True\nplugin_dir = 'projects/mmdet3d_plugin/'\n_dim_ = 256\n_pos_dim_ = 128\n_ffn_dim_ = 512\n_num_levels_ = 4\n_num_mono_levels_ = 5\nmodel = dict(\n    type='BEVFormerV2',",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-48ep",
        "documentation": {}
    },
    {
        "label": "plugin",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-48ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-48ep",
        "peekOfCode": "plugin = True\nplugin_dir = 'projects/mmdet3d_plugin/'\n_dim_ = 256\n_pos_dim_ = 128\n_ffn_dim_ = 512\n_num_levels_ = 4\n_num_mono_levels_ = 5\nmodel = dict(\n    type='BEVFormerV2',\n    use_grid_mask=True,",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-48ep",
        "documentation": {}
    },
    {
        "label": "plugin_dir",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-48ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-48ep",
        "peekOfCode": "plugin_dir = 'projects/mmdet3d_plugin/'\n_dim_ = 256\n_pos_dim_ = 128\n_ffn_dim_ = 512\n_num_levels_ = 4\n_num_mono_levels_ = 5\nmodel = dict(\n    type='BEVFormerV2',\n    use_grid_mask=True,\n    video_test_mode=False,",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-48ep",
        "documentation": {}
    },
    {
        "label": "_dim_",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-48ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-48ep",
        "peekOfCode": "_dim_ = 256\n_pos_dim_ = 128\n_ffn_dim_ = 512\n_num_levels_ = 4\n_num_mono_levels_ = 5\nmodel = dict(\n    type='BEVFormerV2',\n    use_grid_mask=True,\n    video_test_mode=False,\n    num_levels=_num_levels_,",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-48ep",
        "documentation": {}
    },
    {
        "label": "_pos_dim_",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-48ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-48ep",
        "peekOfCode": "_pos_dim_ = 128\n_ffn_dim_ = 512\n_num_levels_ = 4\n_num_mono_levels_ = 5\nmodel = dict(\n    type='BEVFormerV2',\n    use_grid_mask=True,\n    video_test_mode=False,\n    num_levels=_num_levels_,\n    num_mono_levels=_num_mono_levels_,",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-48ep",
        "documentation": {}
    },
    {
        "label": "_ffn_dim_",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-48ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-48ep",
        "peekOfCode": "_ffn_dim_ = 512\n_num_levels_ = 4\n_num_mono_levels_ = 5\nmodel = dict(\n    type='BEVFormerV2',\n    use_grid_mask=True,\n    video_test_mode=False,\n    num_levels=_num_levels_,\n    num_mono_levels=_num_mono_levels_,\n    mono_loss_weight=1.0,",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-48ep",
        "documentation": {}
    },
    {
        "label": "_num_levels_",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-48ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-48ep",
        "peekOfCode": "_num_levels_ = 4\n_num_mono_levels_ = 5\nmodel = dict(\n    type='BEVFormerV2',\n    use_grid_mask=True,\n    video_test_mode=False,\n    num_levels=_num_levels_,\n    num_mono_levels=_num_mono_levels_,\n    mono_loss_weight=1.0,\n    frames=frames,",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-48ep",
        "documentation": {}
    },
    {
        "label": "_num_mono_levels_",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-48ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-48ep",
        "peekOfCode": "_num_mono_levels_ = 5\nmodel = dict(\n    type='BEVFormerV2',\n    use_grid_mask=True,\n    video_test_mode=False,\n    num_levels=_num_levels_,\n    num_mono_levels=_num_mono_levels_,\n    mono_loss_weight=1.0,\n    frames=frames,\n    img_backbone=dict(",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-48ep",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-48ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-48ep",
        "peekOfCode": "model = dict(\n    type='BEVFormerV2',\n    use_grid_mask=True,\n    video_test_mode=False,\n    num_levels=_num_levels_,\n    num_mono_levels=_num_mono_levels_,\n    mono_loss_weight=1.0,\n    frames=frames,\n    img_backbone=dict(\n        type='ResNet',",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-48ep",
        "documentation": {}
    },
    {
        "label": "optimizer",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-48ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-48ep",
        "peekOfCode": "optimizer = dict(\n    type='AdamW',\n    lr=4e-4,\n    paramwise_cfg=dict(\n        custom_keys=dict(\n            img_backbone=dict(lr_mult=0.5),\n        )),\n    weight_decay=0.01)\noptimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))\n# learning policy",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-48ep",
        "documentation": {}
    },
    {
        "label": "optimizer_config",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-48ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-48ep",
        "peekOfCode": "optimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))\n# learning policy\nlr_config = dict(\n    policy='step',\n    warmup='linear',\n    warmup_iters=2000,\n    warmup_ratio=1.0 / 3,\n    step=[44, ])\ntotal_epochs = 48\nrunner = dict(type='EpochBasedRunner', max_epochs=total_epochs)",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-48ep",
        "documentation": {}
    },
    {
        "label": "lr_config",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-48ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-48ep",
        "peekOfCode": "lr_config = dict(\n    policy='step',\n    warmup='linear',\n    warmup_iters=2000,\n    warmup_ratio=1.0 / 3,\n    step=[44, ])\ntotal_epochs = 48\nrunner = dict(type='EpochBasedRunner', max_epochs=total_epochs)",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-48ep",
        "documentation": {}
    },
    {
        "label": "total_epochs",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-48ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-48ep",
        "peekOfCode": "total_epochs = 48\nrunner = dict(type='EpochBasedRunner', max_epochs=total_epochs)",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-48ep",
        "documentation": {}
    },
    {
        "label": "runner",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-48ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-48ep",
        "peekOfCode": "runner = dict(type='EpochBasedRunner', max_epochs=total_epochs)",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t1-base-48ep",
        "documentation": {}
    },
    {
        "label": "_base_",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t2-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t2-24ep",
        "peekOfCode": "_base_ = [\n    '../_base_/default_runtime.py'\n]\n# Dataset\n# If point cloud range is changed, the models should also change their point\n# cloud range accordingly\npoint_cloud_range = [-51.2, -51.2, -5.0, 51.2, 51.2, 3.0]\n# For nuScenes we usually do 10-class detection\nclass_names = [\n    'barrier', 'bicycle', 'bus', 'car', 'construction_vehicle', 'motorcycle',",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t2-24ep",
        "documentation": {}
    },
    {
        "label": "point_cloud_range",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t2-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t2-24ep",
        "peekOfCode": "point_cloud_range = [-51.2, -51.2, -5.0, 51.2, 51.2, 3.0]\n# For nuScenes we usually do 10-class detection\nclass_names = [\n    'barrier', 'bicycle', 'bus', 'car', 'construction_vehicle', 'motorcycle',\n    'pedestrian', 'traffic_cone', 'trailer', 'truck'\n]\ndataset_type = 'CustomNuScenesDatasetV2'\ndata_root = 'data/nuscenes/'\n# Input modality for nuScenes dataset, this is consistent with the submission\n# format which requires the information in input_modality.",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t2-24ep",
        "documentation": {}
    },
    {
        "label": "class_names",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t2-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t2-24ep",
        "peekOfCode": "class_names = [\n    'barrier', 'bicycle', 'bus', 'car', 'construction_vehicle', 'motorcycle',\n    'pedestrian', 'traffic_cone', 'trailer', 'truck'\n]\ndataset_type = 'CustomNuScenesDatasetV2'\ndata_root = 'data/nuscenes/'\n# Input modality for nuScenes dataset, this is consistent with the submission\n# format which requires the information in input_modality.\ninput_modality = dict(\n    use_lidar=False,",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t2-24ep",
        "documentation": {}
    },
    {
        "label": "dataset_type",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t2-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t2-24ep",
        "peekOfCode": "dataset_type = 'CustomNuScenesDatasetV2'\ndata_root = 'data/nuscenes/'\n# Input modality for nuScenes dataset, this is consistent with the submission\n# format which requires the information in input_modality.\ninput_modality = dict(\n    use_lidar=False,\n    use_camera=True,\n    use_radar=False,\n    use_map=False,\n    use_external=False)",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t2-24ep",
        "documentation": {}
    },
    {
        "label": "data_root",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t2-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t2-24ep",
        "peekOfCode": "data_root = 'data/nuscenes/'\n# Input modality for nuScenes dataset, this is consistent with the submission\n# format which requires the information in input_modality.\ninput_modality = dict(\n    use_lidar=False,\n    use_camera=True,\n    use_radar=False,\n    use_map=False,\n    use_external=False)\nimg_norm_cfg = dict(mean=[103.53, 116.28, 123.675], std=[1, 1, 1], to_rgb=False)",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t2-24ep",
        "documentation": {}
    },
    {
        "label": "input_modality",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t2-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t2-24ep",
        "peekOfCode": "input_modality = dict(\n    use_lidar=False,\n    use_camera=True,\n    use_radar=False,\n    use_map=False,\n    use_external=False)\nimg_norm_cfg = dict(mean=[103.53, 116.28, 123.675], std=[1, 1, 1], to_rgb=False)\nbev_h_ = 200\nbev_w_ = 200\nframes = (-1, 0,)",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t2-24ep",
        "documentation": {}
    },
    {
        "label": "img_norm_cfg",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t2-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t2-24ep",
        "peekOfCode": "img_norm_cfg = dict(mean=[103.53, 116.28, 123.675], std=[1, 1, 1], to_rgb=False)\nbev_h_ = 200\nbev_w_ = 200\nframes = (-1, 0,)\ngroup_detr = 11\nvoxel_size = [102.4 / bev_h_, 102.4 / bev_w_, 8]\nida_aug_conf = {\n    \"reisze\": [512, 544, 576, 608, 640, 672, 704, 736, 768],  #  (0.8, 1.2)\n    \"crop\": (0, 260, 1600, 900),\n    \"H\": 900,",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t2-24ep",
        "documentation": {}
    },
    {
        "label": "bev_h_",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t2-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t2-24ep",
        "peekOfCode": "bev_h_ = 200\nbev_w_ = 200\nframes = (-1, 0,)\ngroup_detr = 11\nvoxel_size = [102.4 / bev_h_, 102.4 / bev_w_, 8]\nida_aug_conf = {\n    \"reisze\": [512, 544, 576, 608, 640, 672, 704, 736, 768],  #  (0.8, 1.2)\n    \"crop\": (0, 260, 1600, 900),\n    \"H\": 900,\n    \"W\": 1600,",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t2-24ep",
        "documentation": {}
    },
    {
        "label": "bev_w_",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t2-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t2-24ep",
        "peekOfCode": "bev_w_ = 200\nframes = (-1, 0,)\ngroup_detr = 11\nvoxel_size = [102.4 / bev_h_, 102.4 / bev_w_, 8]\nida_aug_conf = {\n    \"reisze\": [512, 544, 576, 608, 640, 672, 704, 736, 768],  #  (0.8, 1.2)\n    \"crop\": (0, 260, 1600, 900),\n    \"H\": 900,\n    \"W\": 1600,\n    \"rand_flip\": True,",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t2-24ep",
        "documentation": {}
    },
    {
        "label": "frames",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t2-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t2-24ep",
        "peekOfCode": "frames = (-1, 0,)\ngroup_detr = 11\nvoxel_size = [102.4 / bev_h_, 102.4 / bev_w_, 8]\nida_aug_conf = {\n    \"reisze\": [512, 544, 576, 608, 640, 672, 704, 736, 768],  #  (0.8, 1.2)\n    \"crop\": (0, 260, 1600, 900),\n    \"H\": 900,\n    \"W\": 1600,\n    \"rand_flip\": True,\n}",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t2-24ep",
        "documentation": {}
    },
    {
        "label": "group_detr",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t2-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t2-24ep",
        "peekOfCode": "group_detr = 11\nvoxel_size = [102.4 / bev_h_, 102.4 / bev_w_, 8]\nida_aug_conf = {\n    \"reisze\": [512, 544, 576, 608, 640, 672, 704, 736, 768],  #  (0.8, 1.2)\n    \"crop\": (0, 260, 1600, 900),\n    \"H\": 900,\n    \"W\": 1600,\n    \"rand_flip\": True,\n}\nida_aug_conf_eval = {",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t2-24ep",
        "documentation": {}
    },
    {
        "label": "voxel_size",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t2-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t2-24ep",
        "peekOfCode": "voxel_size = [102.4 / bev_h_, 102.4 / bev_w_, 8]\nida_aug_conf = {\n    \"reisze\": [512, 544, 576, 608, 640, 672, 704, 736, 768],  #  (0.8, 1.2)\n    \"crop\": (0, 260, 1600, 900),\n    \"H\": 900,\n    \"W\": 1600,\n    \"rand_flip\": True,\n}\nida_aug_conf_eval = {\n    \"reisze\": [640, ],",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t2-24ep",
        "documentation": {}
    },
    {
        "label": "ida_aug_conf",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t2-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t2-24ep",
        "peekOfCode": "ida_aug_conf = {\n    \"reisze\": [512, 544, 576, 608, 640, 672, 704, 736, 768],  #  (0.8, 1.2)\n    \"crop\": (0, 260, 1600, 900),\n    \"H\": 900,\n    \"W\": 1600,\n    \"rand_flip\": True,\n}\nida_aug_conf_eval = {\n    \"reisze\": [640, ],\n    \"crop\": (0, 260, 1600, 900),",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t2-24ep",
        "documentation": {}
    },
    {
        "label": "ida_aug_conf_eval",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t2-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t2-24ep",
        "peekOfCode": "ida_aug_conf_eval = {\n    \"reisze\": [640, ],\n    \"crop\": (0, 260, 1600, 900),\n    \"H\": 900,\n    \"W\": 1600,\n    \"rand_flip\": False,\n}\n# file_client_args = dict(backend='disk')\n# Uncomment the following if use ceph or other file clients.\n# See https://mmcv.readthedocs.io/en/latest/api.html#mmcv.fileio.FileClient",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t2-24ep",
        "documentation": {}
    },
    {
        "label": "train_pipeline",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t2-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t2-24ep",
        "peekOfCode": "train_pipeline = [\n    dict(type='LoadMultiViewImageFromFiles', to_float32=True),\n    dict(type='PhotoMetricDistortionMultiViewImage'),\n    dict(type='LoadAnnotations3D', with_bbox_3d=True, with_label_3d=True, with_attr_label=False),\n    dict(type='GlobalRotScaleTransImage',\n        rot_range=[-22.5, 22.5],\n        scale_ratio_range=[0.95, 1.05],\n        translation_std=[0, 0, 0],\n        reverse_angle=True,\n        training=True,",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t2-24ep",
        "documentation": {}
    },
    {
        "label": "eval_pipeline",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t2-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t2-24ep",
        "peekOfCode": "eval_pipeline = [\n    dict(type='LoadMultiViewImageFromFiles', to_float32=True, ),\n    dict(type='CropResizeFlipImage', data_aug_conf=ida_aug_conf_eval, training=False, debug=False),\n    dict(type='NormalizeMultiviewImage', **img_norm_cfg),\n    dict(type='PadMultiViewImage', size_divisor=32),\n    dict(\n        type='MultiScaleFlipAug3D',\n        img_scale=(1600, 640),\n        pts_scale_ratio=1,\n        flip=False,",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t2-24ep",
        "documentation": {}
    },
    {
        "label": "data",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t2-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t2-24ep",
        "peekOfCode": "data = dict(\n    samples_per_gpu=1,\n    workers_per_gpu=4,\n    persistent_workers=True,\n    train=dict(\n        type='CustomNuScenesDatasetV2',\n        frames=frames,\n        data_root=data_root,\n        ann_file=data_root + 'nuscenes_infos_temporal_train.pkl',\n        pipeline=train_pipeline,",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t2-24ep",
        "documentation": {}
    },
    {
        "label": "evaluation",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t2-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t2-24ep",
        "peekOfCode": "evaluation = dict(interval=4, pipeline=eval_pipeline)\n# model\nload_from = './ckpts/fcos_r50_coco_2mmdet.pth'\nplugin = True\nplugin_dir = 'projects/mmdet3d_plugin/'\n_dim_ = 256\n_pos_dim_ = 128\n_ffn_dim_ = 512\n_num_levels_ = 4\n_num_mono_levels_ = 5",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t2-24ep",
        "documentation": {}
    },
    {
        "label": "load_from",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t2-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t2-24ep",
        "peekOfCode": "load_from = './ckpts/fcos_r50_coco_2mmdet.pth'\nplugin = True\nplugin_dir = 'projects/mmdet3d_plugin/'\n_dim_ = 256\n_pos_dim_ = 128\n_ffn_dim_ = 512\n_num_levels_ = 4\n_num_mono_levels_ = 5\nmodel = dict(\n    type='BEVFormerV2',",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t2-24ep",
        "documentation": {}
    },
    {
        "label": "plugin",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t2-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t2-24ep",
        "peekOfCode": "plugin = True\nplugin_dir = 'projects/mmdet3d_plugin/'\n_dim_ = 256\n_pos_dim_ = 128\n_ffn_dim_ = 512\n_num_levels_ = 4\n_num_mono_levels_ = 5\nmodel = dict(\n    type='BEVFormerV2',\n    use_grid_mask=True,",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t2-24ep",
        "documentation": {}
    },
    {
        "label": "plugin_dir",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t2-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t2-24ep",
        "peekOfCode": "plugin_dir = 'projects/mmdet3d_plugin/'\n_dim_ = 256\n_pos_dim_ = 128\n_ffn_dim_ = 512\n_num_levels_ = 4\n_num_mono_levels_ = 5\nmodel = dict(\n    type='BEVFormerV2',\n    use_grid_mask=True,\n    video_test_mode=False,",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t2-24ep",
        "documentation": {}
    },
    {
        "label": "_dim_",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t2-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t2-24ep",
        "peekOfCode": "_dim_ = 256\n_pos_dim_ = 128\n_ffn_dim_ = 512\n_num_levels_ = 4\n_num_mono_levels_ = 5\nmodel = dict(\n    type='BEVFormerV2',\n    use_grid_mask=True,\n    video_test_mode=False,\n    num_levels=_num_levels_,",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t2-24ep",
        "documentation": {}
    },
    {
        "label": "_pos_dim_",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t2-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t2-24ep",
        "peekOfCode": "_pos_dim_ = 128\n_ffn_dim_ = 512\n_num_levels_ = 4\n_num_mono_levels_ = 5\nmodel = dict(\n    type='BEVFormerV2',\n    use_grid_mask=True,\n    video_test_mode=False,\n    num_levels=_num_levels_,\n    num_mono_levels=_num_mono_levels_,",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t2-24ep",
        "documentation": {}
    },
    {
        "label": "_ffn_dim_",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t2-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t2-24ep",
        "peekOfCode": "_ffn_dim_ = 512\n_num_levels_ = 4\n_num_mono_levels_ = 5\nmodel = dict(\n    type='BEVFormerV2',\n    use_grid_mask=True,\n    video_test_mode=False,\n    num_levels=_num_levels_,\n    num_mono_levels=_num_mono_levels_,\n    mono_loss_weight=1.0,",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t2-24ep",
        "documentation": {}
    },
    {
        "label": "_num_levels_",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t2-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t2-24ep",
        "peekOfCode": "_num_levels_ = 4\n_num_mono_levels_ = 5\nmodel = dict(\n    type='BEVFormerV2',\n    use_grid_mask=True,\n    video_test_mode=False,\n    num_levels=_num_levels_,\n    num_mono_levels=_num_mono_levels_,\n    mono_loss_weight=1.0,\n    frames=frames,",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t2-24ep",
        "documentation": {}
    },
    {
        "label": "_num_mono_levels_",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t2-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t2-24ep",
        "peekOfCode": "_num_mono_levels_ = 5\nmodel = dict(\n    type='BEVFormerV2',\n    use_grid_mask=True,\n    video_test_mode=False,\n    num_levels=_num_levels_,\n    num_mono_levels=_num_mono_levels_,\n    mono_loss_weight=1.0,\n    frames=frames,\n    img_backbone=dict(",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t2-24ep",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t2-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t2-24ep",
        "peekOfCode": "model = dict(\n    type='BEVFormerV2',\n    use_grid_mask=True,\n    video_test_mode=False,\n    num_levels=_num_levels_,\n    num_mono_levels=_num_mono_levels_,\n    mono_loss_weight=1.0,\n    frames=frames,\n    img_backbone=dict(\n        type='ResNet',",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t2-24ep",
        "documentation": {}
    },
    {
        "label": "optimizer",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t2-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t2-24ep",
        "peekOfCode": "optimizer = dict(\n    type='AdamW',\n    lr=4e-4,\n    paramwise_cfg=dict(\n        custom_keys=dict(\n            img_backbone=dict(lr_mult=0.5),\n        )),\n    weight_decay=0.01)\noptimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))\n# learning policy",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t2-24ep",
        "documentation": {}
    },
    {
        "label": "optimizer_config",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t2-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t2-24ep",
        "peekOfCode": "optimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))\n# learning policy\nlr_config = dict(\n    policy='step',\n    warmup='linear',\n    warmup_iters=2000,\n    warmup_ratio=1.0 / 3,\n    step=[20, ])\ntotal_epochs = 24\nrunner = dict(type='EpochBasedRunner', max_epochs=total_epochs)",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t2-24ep",
        "documentation": {}
    },
    {
        "label": "lr_config",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t2-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t2-24ep",
        "peekOfCode": "lr_config = dict(\n    policy='step',\n    warmup='linear',\n    warmup_iters=2000,\n    warmup_ratio=1.0 / 3,\n    step=[20, ])\ntotal_epochs = 24\nrunner = dict(type='EpochBasedRunner', max_epochs=total_epochs)",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t2-24ep",
        "documentation": {}
    },
    {
        "label": "total_epochs",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t2-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t2-24ep",
        "peekOfCode": "total_epochs = 24\nrunner = dict(type='EpochBasedRunner', max_epochs=total_epochs)",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t2-24ep",
        "documentation": {}
    },
    {
        "label": "runner",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t2-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t2-24ep",
        "peekOfCode": "runner = dict(type='EpochBasedRunner', max_epochs=total_epochs)",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t2-24ep",
        "documentation": {}
    },
    {
        "label": "_base_",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t2-48ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t2-48ep",
        "peekOfCode": "_base_ = [\n    '../_base_/default_runtime.py'\n]\n# Dataset\n# If point cloud range is changed, the models should also change their point\n# cloud range accordingly\npoint_cloud_range = [-51.2, -51.2, -5.0, 51.2, 51.2, 3.0]\n# For nuScenes we usually do 10-class detection\nclass_names = [\n    'barrier', 'bicycle', 'bus', 'car', 'construction_vehicle', 'motorcycle',",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t2-48ep",
        "documentation": {}
    },
    {
        "label": "point_cloud_range",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t2-48ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t2-48ep",
        "peekOfCode": "point_cloud_range = [-51.2, -51.2, -5.0, 51.2, 51.2, 3.0]\n# For nuScenes we usually do 10-class detection\nclass_names = [\n    'barrier', 'bicycle', 'bus', 'car', 'construction_vehicle', 'motorcycle',\n    'pedestrian', 'traffic_cone', 'trailer', 'truck'\n]\ndataset_type = 'CustomNuScenesDatasetV2'\ndata_root = 'data/nuscenes/'\n# Input modality for nuScenes dataset, this is consistent with the submission\n# format which requires the information in input_modality.",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t2-48ep",
        "documentation": {}
    },
    {
        "label": "class_names",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t2-48ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t2-48ep",
        "peekOfCode": "class_names = [\n    'barrier', 'bicycle', 'bus', 'car', 'construction_vehicle', 'motorcycle',\n    'pedestrian', 'traffic_cone', 'trailer', 'truck'\n]\ndataset_type = 'CustomNuScenesDatasetV2'\ndata_root = 'data/nuscenes/'\n# Input modality for nuScenes dataset, this is consistent with the submission\n# format which requires the information in input_modality.\ninput_modality = dict(\n    use_lidar=False,",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t2-48ep",
        "documentation": {}
    },
    {
        "label": "dataset_type",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t2-48ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t2-48ep",
        "peekOfCode": "dataset_type = 'CustomNuScenesDatasetV2'\ndata_root = 'data/nuscenes/'\n# Input modality for nuScenes dataset, this is consistent with the submission\n# format which requires the information in input_modality.\ninput_modality = dict(\n    use_lidar=False,\n    use_camera=True,\n    use_radar=False,\n    use_map=False,\n    use_external=False)",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t2-48ep",
        "documentation": {}
    },
    {
        "label": "data_root",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t2-48ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t2-48ep",
        "peekOfCode": "data_root = 'data/nuscenes/'\n# Input modality for nuScenes dataset, this is consistent with the submission\n# format which requires the information in input_modality.\ninput_modality = dict(\n    use_lidar=False,\n    use_camera=True,\n    use_radar=False,\n    use_map=False,\n    use_external=False)\nimg_norm_cfg = dict(mean=[103.53, 116.28, 123.675], std=[1, 1, 1], to_rgb=False)",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t2-48ep",
        "documentation": {}
    },
    {
        "label": "input_modality",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t2-48ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t2-48ep",
        "peekOfCode": "input_modality = dict(\n    use_lidar=False,\n    use_camera=True,\n    use_radar=False,\n    use_map=False,\n    use_external=False)\nimg_norm_cfg = dict(mean=[103.53, 116.28, 123.675], std=[1, 1, 1], to_rgb=False)\nbev_h_ = 200\nbev_w_ = 200\nframes = (-1, 0,)",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t2-48ep",
        "documentation": {}
    },
    {
        "label": "img_norm_cfg",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t2-48ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t2-48ep",
        "peekOfCode": "img_norm_cfg = dict(mean=[103.53, 116.28, 123.675], std=[1, 1, 1], to_rgb=False)\nbev_h_ = 200\nbev_w_ = 200\nframes = (-1, 0,)\ngroup_detr = 11\nvoxel_size = [102.4 / bev_h_, 102.4 / bev_w_, 8]\nida_aug_conf = {\n    \"reisze\": [512, 544, 576, 608, 640, 672, 704, 736, 768],  #  (0.8, 1.2)\n    \"crop\": (0, 260, 1600, 900),\n    \"H\": 900,",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t2-48ep",
        "documentation": {}
    },
    {
        "label": "bev_h_",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t2-48ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t2-48ep",
        "peekOfCode": "bev_h_ = 200\nbev_w_ = 200\nframes = (-1, 0,)\ngroup_detr = 11\nvoxel_size = [102.4 / bev_h_, 102.4 / bev_w_, 8]\nida_aug_conf = {\n    \"reisze\": [512, 544, 576, 608, 640, 672, 704, 736, 768],  #  (0.8, 1.2)\n    \"crop\": (0, 260, 1600, 900),\n    \"H\": 900,\n    \"W\": 1600,",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t2-48ep",
        "documentation": {}
    },
    {
        "label": "bev_w_",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t2-48ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t2-48ep",
        "peekOfCode": "bev_w_ = 200\nframes = (-1, 0,)\ngroup_detr = 11\nvoxel_size = [102.4 / bev_h_, 102.4 / bev_w_, 8]\nida_aug_conf = {\n    \"reisze\": [512, 544, 576, 608, 640, 672, 704, 736, 768],  #  (0.8, 1.2)\n    \"crop\": (0, 260, 1600, 900),\n    \"H\": 900,\n    \"W\": 1600,\n    \"rand_flip\": True,",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t2-48ep",
        "documentation": {}
    },
    {
        "label": "frames",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t2-48ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t2-48ep",
        "peekOfCode": "frames = (-1, 0,)\ngroup_detr = 11\nvoxel_size = [102.4 / bev_h_, 102.4 / bev_w_, 8]\nida_aug_conf = {\n    \"reisze\": [512, 544, 576, 608, 640, 672, 704, 736, 768],  #  (0.8, 1.2)\n    \"crop\": (0, 260, 1600, 900),\n    \"H\": 900,\n    \"W\": 1600,\n    \"rand_flip\": True,\n}",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t2-48ep",
        "documentation": {}
    },
    {
        "label": "group_detr",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t2-48ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t2-48ep",
        "peekOfCode": "group_detr = 11\nvoxel_size = [102.4 / bev_h_, 102.4 / bev_w_, 8]\nida_aug_conf = {\n    \"reisze\": [512, 544, 576, 608, 640, 672, 704, 736, 768],  #  (0.8, 1.2)\n    \"crop\": (0, 260, 1600, 900),\n    \"H\": 900,\n    \"W\": 1600,\n    \"rand_flip\": True,\n}\nida_aug_conf_eval = {",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t2-48ep",
        "documentation": {}
    },
    {
        "label": "voxel_size",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t2-48ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t2-48ep",
        "peekOfCode": "voxel_size = [102.4 / bev_h_, 102.4 / bev_w_, 8]\nida_aug_conf = {\n    \"reisze\": [512, 544, 576, 608, 640, 672, 704, 736, 768],  #  (0.8, 1.2)\n    \"crop\": (0, 260, 1600, 900),\n    \"H\": 900,\n    \"W\": 1600,\n    \"rand_flip\": True,\n}\nida_aug_conf_eval = {\n    \"reisze\": [640, ],",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t2-48ep",
        "documentation": {}
    },
    {
        "label": "ida_aug_conf",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t2-48ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t2-48ep",
        "peekOfCode": "ida_aug_conf = {\n    \"reisze\": [512, 544, 576, 608, 640, 672, 704, 736, 768],  #  (0.8, 1.2)\n    \"crop\": (0, 260, 1600, 900),\n    \"H\": 900,\n    \"W\": 1600,\n    \"rand_flip\": True,\n}\nida_aug_conf_eval = {\n    \"reisze\": [640, ],\n    \"crop\": (0, 260, 1600, 900),",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t2-48ep",
        "documentation": {}
    },
    {
        "label": "ida_aug_conf_eval",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t2-48ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t2-48ep",
        "peekOfCode": "ida_aug_conf_eval = {\n    \"reisze\": [640, ],\n    \"crop\": (0, 260, 1600, 900),\n    \"H\": 900,\n    \"W\": 1600,\n    \"rand_flip\": False,\n}\n# file_client_args = dict(backend='disk')\n# Uncomment the following if use ceph or other file clients.\n# See https://mmcv.readthedocs.io/en/latest/api.html#mmcv.fileio.FileClient",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t2-48ep",
        "documentation": {}
    },
    {
        "label": "train_pipeline",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t2-48ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t2-48ep",
        "peekOfCode": "train_pipeline = [\n    dict(type='LoadMultiViewImageFromFiles', to_float32=True),\n    dict(type='PhotoMetricDistortionMultiViewImage'),\n    dict(type='LoadAnnotations3D', with_bbox_3d=True, with_label_3d=True, with_attr_label=False),\n    dict(type='GlobalRotScaleTransImage',\n        rot_range=[-22.5, 22.5],\n        scale_ratio_range=[0.95, 1.05],\n        translation_std=[0, 0, 0],\n        reverse_angle=True,\n        training=True,",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t2-48ep",
        "documentation": {}
    },
    {
        "label": "eval_pipeline",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t2-48ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t2-48ep",
        "peekOfCode": "eval_pipeline = [\n    dict(type='LoadMultiViewImageFromFiles', to_float32=True, ),\n    dict(type='CropResizeFlipImage', data_aug_conf=ida_aug_conf_eval, training=False, debug=False),\n    dict(type='NormalizeMultiviewImage', **img_norm_cfg),\n    dict(type='PadMultiViewImage', size_divisor=32),\n    dict(\n        type='MultiScaleFlipAug3D',\n        img_scale=(1600, 640),\n        pts_scale_ratio=1,\n        flip=False,",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t2-48ep",
        "documentation": {}
    },
    {
        "label": "data",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t2-48ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t2-48ep",
        "peekOfCode": "data = dict(\n    samples_per_gpu=1,\n    workers_per_gpu=4,\n    persistent_workers=True,\n    train=dict(\n        type='CustomNuScenesDatasetV2',\n        frames=frames,\n        data_root=data_root,\n        ann_file=data_root + 'nuscenes_infos_temporal_train.pkl',\n        pipeline=train_pipeline,",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t2-48ep",
        "documentation": {}
    },
    {
        "label": "evaluation",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t2-48ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t2-48ep",
        "peekOfCode": "evaluation = dict(interval=4, pipeline=eval_pipeline)\n# model\nload_from = './ckpts/fcos_r50_coco_2mmdet.pth'\nplugin = True\nplugin_dir = 'projects/mmdet3d_plugin/'\n_dim_ = 256\n_pos_dim_ = 128\n_ffn_dim_ = 512\n_num_levels_ = 4\n_num_mono_levels_ = 5",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t2-48ep",
        "documentation": {}
    },
    {
        "label": "load_from",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t2-48ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t2-48ep",
        "peekOfCode": "load_from = './ckpts/fcos_r50_coco_2mmdet.pth'\nplugin = True\nplugin_dir = 'projects/mmdet3d_plugin/'\n_dim_ = 256\n_pos_dim_ = 128\n_ffn_dim_ = 512\n_num_levels_ = 4\n_num_mono_levels_ = 5\nmodel = dict(\n    type='BEVFormerV2',",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t2-48ep",
        "documentation": {}
    },
    {
        "label": "plugin",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t2-48ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t2-48ep",
        "peekOfCode": "plugin = True\nplugin_dir = 'projects/mmdet3d_plugin/'\n_dim_ = 256\n_pos_dim_ = 128\n_ffn_dim_ = 512\n_num_levels_ = 4\n_num_mono_levels_ = 5\nmodel = dict(\n    type='BEVFormerV2',\n    use_grid_mask=True,",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t2-48ep",
        "documentation": {}
    },
    {
        "label": "plugin_dir",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t2-48ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t2-48ep",
        "peekOfCode": "plugin_dir = 'projects/mmdet3d_plugin/'\n_dim_ = 256\n_pos_dim_ = 128\n_ffn_dim_ = 512\n_num_levels_ = 4\n_num_mono_levels_ = 5\nmodel = dict(\n    type='BEVFormerV2',\n    use_grid_mask=True,\n    video_test_mode=False,",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t2-48ep",
        "documentation": {}
    },
    {
        "label": "_dim_",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t2-48ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t2-48ep",
        "peekOfCode": "_dim_ = 256\n_pos_dim_ = 128\n_ffn_dim_ = 512\n_num_levels_ = 4\n_num_mono_levels_ = 5\nmodel = dict(\n    type='BEVFormerV2',\n    use_grid_mask=True,\n    video_test_mode=False,\n    num_levels=_num_levels_,",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t2-48ep",
        "documentation": {}
    },
    {
        "label": "_pos_dim_",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t2-48ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t2-48ep",
        "peekOfCode": "_pos_dim_ = 128\n_ffn_dim_ = 512\n_num_levels_ = 4\n_num_mono_levels_ = 5\nmodel = dict(\n    type='BEVFormerV2',\n    use_grid_mask=True,\n    video_test_mode=False,\n    num_levels=_num_levels_,\n    num_mono_levels=_num_mono_levels_,",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t2-48ep",
        "documentation": {}
    },
    {
        "label": "_ffn_dim_",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t2-48ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t2-48ep",
        "peekOfCode": "_ffn_dim_ = 512\n_num_levels_ = 4\n_num_mono_levels_ = 5\nmodel = dict(\n    type='BEVFormerV2',\n    use_grid_mask=True,\n    video_test_mode=False,\n    num_levels=_num_levels_,\n    num_mono_levels=_num_mono_levels_,\n    mono_loss_weight=1.0,",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t2-48ep",
        "documentation": {}
    },
    {
        "label": "_num_levels_",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t2-48ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t2-48ep",
        "peekOfCode": "_num_levels_ = 4\n_num_mono_levels_ = 5\nmodel = dict(\n    type='BEVFormerV2',\n    use_grid_mask=True,\n    video_test_mode=False,\n    num_levels=_num_levels_,\n    num_mono_levels=_num_mono_levels_,\n    mono_loss_weight=1.0,\n    frames=frames,",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t2-48ep",
        "documentation": {}
    },
    {
        "label": "_num_mono_levels_",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t2-48ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t2-48ep",
        "peekOfCode": "_num_mono_levels_ = 5\nmodel = dict(\n    type='BEVFormerV2',\n    use_grid_mask=True,\n    video_test_mode=False,\n    num_levels=_num_levels_,\n    num_mono_levels=_num_mono_levels_,\n    mono_loss_weight=1.0,\n    frames=frames,\n    img_backbone=dict(",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t2-48ep",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t2-48ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t2-48ep",
        "peekOfCode": "model = dict(\n    type='BEVFormerV2',\n    use_grid_mask=True,\n    video_test_mode=False,\n    num_levels=_num_levels_,\n    num_mono_levels=_num_mono_levels_,\n    mono_loss_weight=1.0,\n    frames=frames,\n    img_backbone=dict(\n        type='ResNet',",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t2-48ep",
        "documentation": {}
    },
    {
        "label": "optimizer",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t2-48ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t2-48ep",
        "peekOfCode": "optimizer = dict(\n    type='AdamW',\n    lr=4e-4,\n    paramwise_cfg=dict(\n        custom_keys=dict(\n            img_backbone=dict(lr_mult=0.5),\n        )),\n    weight_decay=0.01)\noptimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))\n# learning policy",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t2-48ep",
        "documentation": {}
    },
    {
        "label": "optimizer_config",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t2-48ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t2-48ep",
        "peekOfCode": "optimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))\n# learning policy\nlr_config = dict(\n    policy='step',\n    warmup='linear',\n    warmup_iters=2000,\n    warmup_ratio=1.0 / 3,\n    step=[20, ])\ntotal_epochs = 24\nrunner = dict(type='EpochBasedRunner', max_epochs=total_epochs)",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t2-48ep",
        "documentation": {}
    },
    {
        "label": "lr_config",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t2-48ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t2-48ep",
        "peekOfCode": "lr_config = dict(\n    policy='step',\n    warmup='linear',\n    warmup_iters=2000,\n    warmup_ratio=1.0 / 3,\n    step=[20, ])\ntotal_epochs = 24\nrunner = dict(type='EpochBasedRunner', max_epochs=total_epochs)",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t2-48ep",
        "documentation": {}
    },
    {
        "label": "total_epochs",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t2-48ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t2-48ep",
        "peekOfCode": "total_epochs = 24\nrunner = dict(type='EpochBasedRunner', max_epochs=total_epochs)",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t2-48ep",
        "documentation": {}
    },
    {
        "label": "runner",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t2-48ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t2-48ep",
        "peekOfCode": "runner = dict(type='EpochBasedRunner', max_epochs=total_epochs)",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t2-48ep",
        "documentation": {}
    },
    {
        "label": "_base_",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t8-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t8-24ep",
        "peekOfCode": "_base_ = [\n    '../_base_/default_runtime.py'\n]\n# Dataset\n# If point cloud range is changed, the models should also change their point\n# cloud range accordingly\npoint_cloud_range = [-51.2, -51.2, -5.0, 51.2, 51.2, 3.0]\n# For nuScenes we usually do 10-class detection\nclass_names = [\n    'barrier', 'bicycle', 'bus', 'car', 'construction_vehicle', 'motorcycle',",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t8-24ep",
        "documentation": {}
    },
    {
        "label": "point_cloud_range",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t8-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t8-24ep",
        "peekOfCode": "point_cloud_range = [-51.2, -51.2, -5.0, 51.2, 51.2, 3.0]\n# For nuScenes we usually do 10-class detection\nclass_names = [\n    'barrier', 'bicycle', 'bus', 'car', 'construction_vehicle', 'motorcycle',\n    'pedestrian', 'traffic_cone', 'trailer', 'truck'\n]\ndataset_type = 'CustomNuScenesDatasetV2'\ndata_root = 'data/nuscenes/'\n# Input modality for nuScenes dataset, this is consistent with the submission\n# format which requires the information in input_modality.",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t8-24ep",
        "documentation": {}
    },
    {
        "label": "class_names",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t8-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t8-24ep",
        "peekOfCode": "class_names = [\n    'barrier', 'bicycle', 'bus', 'car', 'construction_vehicle', 'motorcycle',\n    'pedestrian', 'traffic_cone', 'trailer', 'truck'\n]\ndataset_type = 'CustomNuScenesDatasetV2'\ndata_root = 'data/nuscenes/'\n# Input modality for nuScenes dataset, this is consistent with the submission\n# format which requires the information in input_modality.\ninput_modality = dict(\n    use_lidar=False,",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t8-24ep",
        "documentation": {}
    },
    {
        "label": "dataset_type",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t8-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t8-24ep",
        "peekOfCode": "dataset_type = 'CustomNuScenesDatasetV2'\ndata_root = 'data/nuscenes/'\n# Input modality for nuScenes dataset, this is consistent with the submission\n# format which requires the information in input_modality.\ninput_modality = dict(\n    use_lidar=False,\n    use_camera=True,\n    use_radar=False,\n    use_map=False,\n    use_external=False)",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t8-24ep",
        "documentation": {}
    },
    {
        "label": "data_root",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t8-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t8-24ep",
        "peekOfCode": "data_root = 'data/nuscenes/'\n# Input modality for nuScenes dataset, this is consistent with the submission\n# format which requires the information in input_modality.\ninput_modality = dict(\n    use_lidar=False,\n    use_camera=True,\n    use_radar=False,\n    use_map=False,\n    use_external=False)\nimg_norm_cfg = dict(mean=[103.53, 116.28, 123.675], std=[1, 1, 1], to_rgb=False)",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t8-24ep",
        "documentation": {}
    },
    {
        "label": "input_modality",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t8-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t8-24ep",
        "peekOfCode": "input_modality = dict(\n    use_lidar=False,\n    use_camera=True,\n    use_radar=False,\n    use_map=False,\n    use_external=False)\nimg_norm_cfg = dict(mean=[103.53, 116.28, 123.675], std=[1, 1, 1], to_rgb=False)\nbev_h_ = 200\nbev_w_ = 200\nframes = (-7,-6,-5,-4,-3,-2,-1,0)",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t8-24ep",
        "documentation": {}
    },
    {
        "label": "img_norm_cfg",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t8-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t8-24ep",
        "peekOfCode": "img_norm_cfg = dict(mean=[103.53, 116.28, 123.675], std=[1, 1, 1], to_rgb=False)\nbev_h_ = 200\nbev_w_ = 200\nframes = (-7,-6,-5,-4,-3,-2,-1,0)\ngroup_detr = 11\nvoxel_size = [102.4 / bev_h_, 102.4 / bev_w_, 8]\nida_aug_conf = {\n    \"reisze\": [512, 544, 576, 608, 640, 672, 704, 736, 768],  #  (0.8, 1.2)\n    \"crop\": (0, 260, 1600, 900),\n    \"H\": 900,",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t8-24ep",
        "documentation": {}
    },
    {
        "label": "bev_h_",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t8-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t8-24ep",
        "peekOfCode": "bev_h_ = 200\nbev_w_ = 200\nframes = (-7,-6,-5,-4,-3,-2,-1,0)\ngroup_detr = 11\nvoxel_size = [102.4 / bev_h_, 102.4 / bev_w_, 8]\nida_aug_conf = {\n    \"reisze\": [512, 544, 576, 608, 640, 672, 704, 736, 768],  #  (0.8, 1.2)\n    \"crop\": (0, 260, 1600, 900),\n    \"H\": 900,\n    \"W\": 1600,",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t8-24ep",
        "documentation": {}
    },
    {
        "label": "bev_w_",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t8-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t8-24ep",
        "peekOfCode": "bev_w_ = 200\nframes = (-7,-6,-5,-4,-3,-2,-1,0)\ngroup_detr = 11\nvoxel_size = [102.4 / bev_h_, 102.4 / bev_w_, 8]\nida_aug_conf = {\n    \"reisze\": [512, 544, 576, 608, 640, 672, 704, 736, 768],  #  (0.8, 1.2)\n    \"crop\": (0, 260, 1600, 900),\n    \"H\": 900,\n    \"W\": 1600,\n    \"rand_flip\": True,",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t8-24ep",
        "documentation": {}
    },
    {
        "label": "frames",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t8-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t8-24ep",
        "peekOfCode": "frames = (-7,-6,-5,-4,-3,-2,-1,0)\ngroup_detr = 11\nvoxel_size = [102.4 / bev_h_, 102.4 / bev_w_, 8]\nida_aug_conf = {\n    \"reisze\": [512, 544, 576, 608, 640, 672, 704, 736, 768],  #  (0.8, 1.2)\n    \"crop\": (0, 260, 1600, 900),\n    \"H\": 900,\n    \"W\": 1600,\n    \"rand_flip\": True,\n}",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t8-24ep",
        "documentation": {}
    },
    {
        "label": "group_detr",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t8-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t8-24ep",
        "peekOfCode": "group_detr = 11\nvoxel_size = [102.4 / bev_h_, 102.4 / bev_w_, 8]\nida_aug_conf = {\n    \"reisze\": [512, 544, 576, 608, 640, 672, 704, 736, 768],  #  (0.8, 1.2)\n    \"crop\": (0, 260, 1600, 900),\n    \"H\": 900,\n    \"W\": 1600,\n    \"rand_flip\": True,\n}\nida_aug_conf_eval = {",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t8-24ep",
        "documentation": {}
    },
    {
        "label": "voxel_size",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t8-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t8-24ep",
        "peekOfCode": "voxel_size = [102.4 / bev_h_, 102.4 / bev_w_, 8]\nida_aug_conf = {\n    \"reisze\": [512, 544, 576, 608, 640, 672, 704, 736, 768],  #  (0.8, 1.2)\n    \"crop\": (0, 260, 1600, 900),\n    \"H\": 900,\n    \"W\": 1600,\n    \"rand_flip\": True,\n}\nida_aug_conf_eval = {\n    \"reisze\": [640, ],",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t8-24ep",
        "documentation": {}
    },
    {
        "label": "ida_aug_conf",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t8-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t8-24ep",
        "peekOfCode": "ida_aug_conf = {\n    \"reisze\": [512, 544, 576, 608, 640, 672, 704, 736, 768],  #  (0.8, 1.2)\n    \"crop\": (0, 260, 1600, 900),\n    \"H\": 900,\n    \"W\": 1600,\n    \"rand_flip\": True,\n}\nida_aug_conf_eval = {\n    \"reisze\": [640, ],\n    \"crop\": (0, 260, 1600, 900),",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t8-24ep",
        "documentation": {}
    },
    {
        "label": "ida_aug_conf_eval",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t8-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t8-24ep",
        "peekOfCode": "ida_aug_conf_eval = {\n    \"reisze\": [640, ],\n    \"crop\": (0, 260, 1600, 900),\n    \"H\": 900,\n    \"W\": 1600,\n    \"rand_flip\": False,\n}\n# file_client_args = dict(backend='disk')\n# Uncomment the following if use ceph or other file clients.\n# See https://mmcv.readthedocs.io/en/latest/api.html#mmcv.fileio.FileClient",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t8-24ep",
        "documentation": {}
    },
    {
        "label": "train_pipeline",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t8-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t8-24ep",
        "peekOfCode": "train_pipeline = [\n    dict(type='LoadMultiViewImageFromFiles', to_float32=True),\n    dict(type='PhotoMetricDistortionMultiViewImage'),\n    dict(type='LoadAnnotations3D', with_bbox_3d=True, with_label_3d=True, with_attr_label=False),\n    dict(type='GlobalRotScaleTransImage',\n        rot_range=[-22.5, 22.5],\n        scale_ratio_range=[0.95, 1.05],\n        translation_std=[0, 0, 0],\n        reverse_angle=True,\n        training=True,",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t8-24ep",
        "documentation": {}
    },
    {
        "label": "eval_pipeline",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t8-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t8-24ep",
        "peekOfCode": "eval_pipeline = [\n    dict(type='LoadMultiViewImageFromFiles', to_float32=True, ),\n    dict(type='CropResizeFlipImage', data_aug_conf=ida_aug_conf_eval, training=False, debug=False),\n    dict(type='NormalizeMultiviewImage', **img_norm_cfg),\n    dict(type='PadMultiViewImage', size_divisor=32),\n    dict(\n        type='MultiScaleFlipAug3D',\n        img_scale=(1600, 640),\n        pts_scale_ratio=1,\n        flip=False,",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t8-24ep",
        "documentation": {}
    },
    {
        "label": "data",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t8-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t8-24ep",
        "peekOfCode": "data = dict(\n    samples_per_gpu=1,\n    workers_per_gpu=4,\n    persistent_workers=True,\n    train=dict(\n        type='CustomNuScenesDatasetV2',\n        frames=frames,\n        data_root=data_root,\n        ann_file=data_root + 'nuscenes_infos_temporal_train.pkl',\n        pipeline=train_pipeline,",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t8-24ep",
        "documentation": {}
    },
    {
        "label": "evaluation",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t8-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t8-24ep",
        "peekOfCode": "evaluation = dict(interval=4, pipeline=eval_pipeline)\n# model\nload_from = './ckpts/fcos_r50_coco_2mmdet.pth'\nplugin = True\nplugin_dir = 'projects/mmdet3d_plugin/'\n_dim_ = 256\n_pos_dim_ = 128\n_ffn_dim_ = 512\n_num_levels_ = 4\n_num_mono_levels_ = 5",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t8-24ep",
        "documentation": {}
    },
    {
        "label": "load_from",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t8-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t8-24ep",
        "peekOfCode": "load_from = './ckpts/fcos_r50_coco_2mmdet.pth'\nplugin = True\nplugin_dir = 'projects/mmdet3d_plugin/'\n_dim_ = 256\n_pos_dim_ = 128\n_ffn_dim_ = 512\n_num_levels_ = 4\n_num_mono_levels_ = 5\nmodel = dict(\n    type='BEVFormerV2',",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t8-24ep",
        "documentation": {}
    },
    {
        "label": "plugin",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t8-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t8-24ep",
        "peekOfCode": "plugin = True\nplugin_dir = 'projects/mmdet3d_plugin/'\n_dim_ = 256\n_pos_dim_ = 128\n_ffn_dim_ = 512\n_num_levels_ = 4\n_num_mono_levels_ = 5\nmodel = dict(\n    type='BEVFormerV2',\n    use_grid_mask=True,",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t8-24ep",
        "documentation": {}
    },
    {
        "label": "plugin_dir",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t8-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t8-24ep",
        "peekOfCode": "plugin_dir = 'projects/mmdet3d_plugin/'\n_dim_ = 256\n_pos_dim_ = 128\n_ffn_dim_ = 512\n_num_levels_ = 4\n_num_mono_levels_ = 5\nmodel = dict(\n    type='BEVFormerV2',\n    use_grid_mask=True,\n    video_test_mode=False,",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t8-24ep",
        "documentation": {}
    },
    {
        "label": "_dim_",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t8-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t8-24ep",
        "peekOfCode": "_dim_ = 256\n_pos_dim_ = 128\n_ffn_dim_ = 512\n_num_levels_ = 4\n_num_mono_levels_ = 5\nmodel = dict(\n    type='BEVFormerV2',\n    use_grid_mask=True,\n    video_test_mode=False,\n    num_levels=_num_levels_,",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t8-24ep",
        "documentation": {}
    },
    {
        "label": "_pos_dim_",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t8-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t8-24ep",
        "peekOfCode": "_pos_dim_ = 128\n_ffn_dim_ = 512\n_num_levels_ = 4\n_num_mono_levels_ = 5\nmodel = dict(\n    type='BEVFormerV2',\n    use_grid_mask=True,\n    video_test_mode=False,\n    num_levels=_num_levels_,\n    num_mono_levels=_num_mono_levels_,",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t8-24ep",
        "documentation": {}
    },
    {
        "label": "_ffn_dim_",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t8-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t8-24ep",
        "peekOfCode": "_ffn_dim_ = 512\n_num_levels_ = 4\n_num_mono_levels_ = 5\nmodel = dict(\n    type='BEVFormerV2',\n    use_grid_mask=True,\n    video_test_mode=False,\n    num_levels=_num_levels_,\n    num_mono_levels=_num_mono_levels_,\n    mono_loss_weight=1.0,",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t8-24ep",
        "documentation": {}
    },
    {
        "label": "_num_levels_",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t8-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t8-24ep",
        "peekOfCode": "_num_levels_ = 4\n_num_mono_levels_ = 5\nmodel = dict(\n    type='BEVFormerV2',\n    use_grid_mask=True,\n    video_test_mode=False,\n    num_levels=_num_levels_,\n    num_mono_levels=_num_mono_levels_,\n    mono_loss_weight=1.0,\n    frames=frames,",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t8-24ep",
        "documentation": {}
    },
    {
        "label": "_num_mono_levels_",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t8-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t8-24ep",
        "peekOfCode": "_num_mono_levels_ = 5\nmodel = dict(\n    type='BEVFormerV2',\n    use_grid_mask=True,\n    video_test_mode=False,\n    num_levels=_num_levels_,\n    num_mono_levels=_num_mono_levels_,\n    mono_loss_weight=1.0,\n    frames=frames,\n    img_backbone=dict(",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t8-24ep",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t8-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t8-24ep",
        "peekOfCode": "model = dict(\n    type='BEVFormerV2',\n    use_grid_mask=True,\n    video_test_mode=False,\n    num_levels=_num_levels_,\n    num_mono_levels=_num_mono_levels_,\n    mono_loss_weight=1.0,\n    frames=frames,\n    img_backbone=dict(\n        type='ResNet',",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t8-24ep",
        "documentation": {}
    },
    {
        "label": "optimizer",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t8-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t8-24ep",
        "peekOfCode": "optimizer = dict(\n    type='AdamW',\n    lr=4e-4,\n    paramwise_cfg=dict(\n        custom_keys=dict(\n            img_backbone=dict(lr_mult=0.5),\n        )),\n    weight_decay=0.01)\noptimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))\n# learning policy",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t8-24ep",
        "documentation": {}
    },
    {
        "label": "optimizer_config",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t8-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t8-24ep",
        "peekOfCode": "optimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))\n# learning policy\nlr_config = dict(\n    policy='step',\n    warmup='linear',\n    warmup_iters=2000,\n    warmup_ratio=1.0 / 3,\n    step=[20, ])\ntotal_epochs = 24\nrunner = dict(type='EpochBasedRunner', max_epochs=total_epochs)",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t8-24ep",
        "documentation": {}
    },
    {
        "label": "lr_config",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t8-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t8-24ep",
        "peekOfCode": "lr_config = dict(\n    policy='step',\n    warmup='linear',\n    warmup_iters=2000,\n    warmup_ratio=1.0 / 3,\n    step=[20, ])\ntotal_epochs = 24\nrunner = dict(type='EpochBasedRunner', max_epochs=total_epochs)",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t8-24ep",
        "documentation": {}
    },
    {
        "label": "total_epochs",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t8-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t8-24ep",
        "peekOfCode": "total_epochs = 24\nrunner = dict(type='EpochBasedRunner', max_epochs=total_epochs)",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t8-24ep",
        "documentation": {}
    },
    {
        "label": "runner",
        "kind": 5,
        "importPath": "projects.configs.bevformerv2.bevformerv2-r50-t8-24ep",
        "description": "projects.configs.bevformerv2.bevformerv2-r50-t8-24ep",
        "peekOfCode": "runner = dict(type='EpochBasedRunner', max_epochs=total_epochs)",
        "detail": "projects.configs.bevformerv2.bevformerv2-r50-t8-24ep",
        "documentation": {}
    },
    {
        "label": "point_cloud_range",
        "kind": 5,
        "importPath": "projects.configs.datasets.custom_lyft-3d",
        "description": "projects.configs.datasets.custom_lyft-3d",
        "peekOfCode": "point_cloud_range = [-80, -80, -5, 80, 80, 3]\n# For Lyft we usually do 9-class detection\nclass_names = [\n    'car', 'truck', 'bus', 'emergency_vehicle', 'other_vehicle', 'motorcycle',\n    'bicycle', 'pedestrian', 'animal'\n]\ndataset_type = 'CustomLyftDataset'\ndata_root = 'data/lyft/'\n# Input modality for Lyft dataset, this is consistent with the submission\n# format which requires the information in input_modality.",
        "detail": "projects.configs.datasets.custom_lyft-3d",
        "documentation": {}
    },
    {
        "label": "class_names",
        "kind": 5,
        "importPath": "projects.configs.datasets.custom_lyft-3d",
        "description": "projects.configs.datasets.custom_lyft-3d",
        "peekOfCode": "class_names = [\n    'car', 'truck', 'bus', 'emergency_vehicle', 'other_vehicle', 'motorcycle',\n    'bicycle', 'pedestrian', 'animal'\n]\ndataset_type = 'CustomLyftDataset'\ndata_root = 'data/lyft/'\n# Input modality for Lyft dataset, this is consistent with the submission\n# format which requires the information in input_modality.\ninput_modality = dict(\n    use_lidar=True,",
        "detail": "projects.configs.datasets.custom_lyft-3d",
        "documentation": {}
    },
    {
        "label": "dataset_type",
        "kind": 5,
        "importPath": "projects.configs.datasets.custom_lyft-3d",
        "description": "projects.configs.datasets.custom_lyft-3d",
        "peekOfCode": "dataset_type = 'CustomLyftDataset'\ndata_root = 'data/lyft/'\n# Input modality for Lyft dataset, this is consistent with the submission\n# format which requires the information in input_modality.\ninput_modality = dict(\n    use_lidar=True,\n    use_camera=False,\n    use_radar=False,\n    use_map=False,\n    use_external=True)",
        "detail": "projects.configs.datasets.custom_lyft-3d",
        "documentation": {}
    },
    {
        "label": "data_root",
        "kind": 5,
        "importPath": "projects.configs.datasets.custom_lyft-3d",
        "description": "projects.configs.datasets.custom_lyft-3d",
        "peekOfCode": "data_root = 'data/lyft/'\n# Input modality for Lyft dataset, this is consistent with the submission\n# format which requires the information in input_modality.\ninput_modality = dict(\n    use_lidar=True,\n    use_camera=False,\n    use_radar=False,\n    use_map=False,\n    use_external=True)\nfile_client_args = dict(backend='disk')",
        "detail": "projects.configs.datasets.custom_lyft-3d",
        "documentation": {}
    },
    {
        "label": "input_modality",
        "kind": 5,
        "importPath": "projects.configs.datasets.custom_lyft-3d",
        "description": "projects.configs.datasets.custom_lyft-3d",
        "peekOfCode": "input_modality = dict(\n    use_lidar=True,\n    use_camera=False,\n    use_radar=False,\n    use_map=False,\n    use_external=True)\nfile_client_args = dict(backend='disk')\n# Uncomment the following if use ceph or other file clients.\n# See https://mmcv.readthedocs.io/en/latest/api.html#mmcv.fileio.FileClient\n# for more details.",
        "detail": "projects.configs.datasets.custom_lyft-3d",
        "documentation": {}
    },
    {
        "label": "file_client_args",
        "kind": 5,
        "importPath": "projects.configs.datasets.custom_lyft-3d",
        "description": "projects.configs.datasets.custom_lyft-3d",
        "peekOfCode": "file_client_args = dict(backend='disk')\n# Uncomment the following if use ceph or other file clients.\n# See https://mmcv.readthedocs.io/en/latest/api.html#mmcv.fileio.FileClient\n# for more details.\n# file_client_args = dict(\n#     backend='petrel',\n#     path_mapping=dict({\n#         './data/lyft/': 's3://lyft/lyft/',\n#         'data/lyft/': 's3://lyft/lyft/'\n#    }))",
        "detail": "projects.configs.datasets.custom_lyft-3d",
        "documentation": {}
    },
    {
        "label": "train_pipeline",
        "kind": 5,
        "importPath": "projects.configs.datasets.custom_lyft-3d",
        "description": "projects.configs.datasets.custom_lyft-3d",
        "peekOfCode": "train_pipeline = [\n    dict(\n        type='LoadPointsFromFile',\n        coord_type='LIDAR',\n        load_dim=5,\n        use_dim=5,\n        file_client_args=file_client_args),\n    dict(\n        type='LoadPointsFromMultiSweeps',\n        sweeps_num=10,",
        "detail": "projects.configs.datasets.custom_lyft-3d",
        "documentation": {}
    },
    {
        "label": "test_pipeline",
        "kind": 5,
        "importPath": "projects.configs.datasets.custom_lyft-3d",
        "description": "projects.configs.datasets.custom_lyft-3d",
        "peekOfCode": "test_pipeline = [\n    dict(\n        type='LoadPointsFromFile',\n        coord_type='LIDAR',\n        load_dim=5,\n        use_dim=5,\n        file_client_args=file_client_args),\n    dict(\n        type='LoadPointsFromMultiSweeps',\n        sweeps_num=10,",
        "detail": "projects.configs.datasets.custom_lyft-3d",
        "documentation": {}
    },
    {
        "label": "eval_pipeline",
        "kind": 5,
        "importPath": "projects.configs.datasets.custom_lyft-3d",
        "description": "projects.configs.datasets.custom_lyft-3d",
        "peekOfCode": "eval_pipeline = [\n    dict(\n        type='LoadPointsFromFile',\n        coord_type='LIDAR',\n        load_dim=5,\n        use_dim=5,\n        file_client_args=file_client_args),\n    dict(\n        type='LoadPointsFromMultiSweeps',\n        sweeps_num=10,",
        "detail": "projects.configs.datasets.custom_lyft-3d",
        "documentation": {}
    },
    {
        "label": "data",
        "kind": 5,
        "importPath": "projects.configs.datasets.custom_lyft-3d",
        "description": "projects.configs.datasets.custom_lyft-3d",
        "peekOfCode": "data = dict(\n    samples_per_gpu=2,\n    workers_per_gpu=2,\n    train=dict(\n        type=dataset_type,\n        data_root=data_root,\n        ann_file=data_root + 'lyft_infos_train.pkl',\n        pipeline=train_pipeline,\n        classes=class_names,\n        modality=input_modality,",
        "detail": "projects.configs.datasets.custom_lyft-3d",
        "documentation": {}
    },
    {
        "label": "evaluation",
        "kind": 5,
        "importPath": "projects.configs.datasets.custom_lyft-3d",
        "description": "projects.configs.datasets.custom_lyft-3d",
        "peekOfCode": "evaluation = dict(interval=24, pipeline=eval_pipeline)",
        "detail": "projects.configs.datasets.custom_lyft-3d",
        "documentation": {}
    },
    {
        "label": "point_cloud_range",
        "kind": 5,
        "importPath": "projects.configs.datasets.custom_nus-3d",
        "description": "projects.configs.datasets.custom_nus-3d",
        "peekOfCode": "point_cloud_range = [-50, -50, -5, 50, 50, 3]\n# For nuScenes we usually do 10-class detection\nclass_names = [\n    'car', 'truck', 'trailer', 'bus', 'construction_vehicle', 'bicycle',\n    'motorcycle', 'pedestrian', 'traffic_cone', 'barrier'\n]\ndataset_type = 'NuScenesDataset_eval_modified'\ndata_root = 'data/nuscenes/'\n# Input modality for nuScenes dataset, this is consistent with the submission\n# format which requires the information in input_modality.",
        "detail": "projects.configs.datasets.custom_nus-3d",
        "documentation": {}
    },
    {
        "label": "class_names",
        "kind": 5,
        "importPath": "projects.configs.datasets.custom_nus-3d",
        "description": "projects.configs.datasets.custom_nus-3d",
        "peekOfCode": "class_names = [\n    'car', 'truck', 'trailer', 'bus', 'construction_vehicle', 'bicycle',\n    'motorcycle', 'pedestrian', 'traffic_cone', 'barrier'\n]\ndataset_type = 'NuScenesDataset_eval_modified'\ndata_root = 'data/nuscenes/'\n# Input modality for nuScenes dataset, this is consistent with the submission\n# format which requires the information in input_modality.\ninput_modality = dict(\n    use_lidar=True,",
        "detail": "projects.configs.datasets.custom_nus-3d",
        "documentation": {}
    },
    {
        "label": "dataset_type",
        "kind": 5,
        "importPath": "projects.configs.datasets.custom_nus-3d",
        "description": "projects.configs.datasets.custom_nus-3d",
        "peekOfCode": "dataset_type = 'NuScenesDataset_eval_modified'\ndata_root = 'data/nuscenes/'\n# Input modality for nuScenes dataset, this is consistent with the submission\n# format which requires the information in input_modality.\ninput_modality = dict(\n    use_lidar=True,\n    use_camera=False,\n    use_radar=False,\n    use_map=False,\n    use_external=False)",
        "detail": "projects.configs.datasets.custom_nus-3d",
        "documentation": {}
    },
    {
        "label": "data_root",
        "kind": 5,
        "importPath": "projects.configs.datasets.custom_nus-3d",
        "description": "projects.configs.datasets.custom_nus-3d",
        "peekOfCode": "data_root = 'data/nuscenes/'\n# Input modality for nuScenes dataset, this is consistent with the submission\n# format which requires the information in input_modality.\ninput_modality = dict(\n    use_lidar=True,\n    use_camera=False,\n    use_radar=False,\n    use_map=False,\n    use_external=False)\nfile_client_args = dict(backend='disk')",
        "detail": "projects.configs.datasets.custom_nus-3d",
        "documentation": {}
    },
    {
        "label": "input_modality",
        "kind": 5,
        "importPath": "projects.configs.datasets.custom_nus-3d",
        "description": "projects.configs.datasets.custom_nus-3d",
        "peekOfCode": "input_modality = dict(\n    use_lidar=True,\n    use_camera=False,\n    use_radar=False,\n    use_map=False,\n    use_external=False)\nfile_client_args = dict(backend='disk')\n# Uncomment the following if use ceph or other file clients.\n# See https://mmcv.readthedocs.io/en/latest/api.html#mmcv.fileio.FileClient\n# for more details.",
        "detail": "projects.configs.datasets.custom_nus-3d",
        "documentation": {}
    },
    {
        "label": "file_client_args",
        "kind": 5,
        "importPath": "projects.configs.datasets.custom_nus-3d",
        "description": "projects.configs.datasets.custom_nus-3d",
        "peekOfCode": "file_client_args = dict(backend='disk')\n# Uncomment the following if use ceph or other file clients.\n# See https://mmcv.readthedocs.io/en/latest/api.html#mmcv.fileio.FileClient\n# for more details.\n# file_client_args = dict(\n#     backend='petrel',\n#     path_mapping=dict({\n#         './data/nuscenes/': 's3://nuscenes/nuscenes/',\n#         'data/nuscenes/': 's3://nuscenes/nuscenes/'\n#     }))",
        "detail": "projects.configs.datasets.custom_nus-3d",
        "documentation": {}
    },
    {
        "label": "train_pipeline",
        "kind": 5,
        "importPath": "projects.configs.datasets.custom_nus-3d",
        "description": "projects.configs.datasets.custom_nus-3d",
        "peekOfCode": "train_pipeline = [\n    dict(\n        type='LoadPointsFromFile',\n        coord_type='LIDAR',\n        load_dim=5,\n        use_dim=5,\n        file_client_args=file_client_args),\n    dict(\n        type='LoadPointsFromMultiSweeps',\n        sweeps_num=10,",
        "detail": "projects.configs.datasets.custom_nus-3d",
        "documentation": {}
    },
    {
        "label": "test_pipeline",
        "kind": 5,
        "importPath": "projects.configs.datasets.custom_nus-3d",
        "description": "projects.configs.datasets.custom_nus-3d",
        "peekOfCode": "test_pipeline = [\n    dict(\n        type='LoadPointsFromFile',\n        coord_type='LIDAR',\n        load_dim=5,\n        use_dim=5,\n        file_client_args=file_client_args),\n    dict(\n        type='LoadPointsFromMultiSweeps',\n        sweeps_num=10,",
        "detail": "projects.configs.datasets.custom_nus-3d",
        "documentation": {}
    },
    {
        "label": "eval_pipeline",
        "kind": 5,
        "importPath": "projects.configs.datasets.custom_nus-3d",
        "description": "projects.configs.datasets.custom_nus-3d",
        "peekOfCode": "eval_pipeline = [\n    dict(\n        type='LoadPointsFromFile',\n        coord_type='LIDAR',\n        load_dim=5,\n        use_dim=5,\n        file_client_args=file_client_args),\n    dict(\n        type='LoadPointsFromMultiSweeps',\n        sweeps_num=10,",
        "detail": "projects.configs.datasets.custom_nus-3d",
        "documentation": {}
    },
    {
        "label": "data",
        "kind": 5,
        "importPath": "projects.configs.datasets.custom_nus-3d",
        "description": "projects.configs.datasets.custom_nus-3d",
        "peekOfCode": "data = dict(\n    samples_per_gpu=4,\n    workers_per_gpu=4,\n    train=dict(\n        type=dataset_type,\n        data_root=data_root,\n        ann_file=data_root + 'nuscenes_infos_train.pkl',\n        pipeline=train_pipeline,\n        classes=class_names,\n        modality=input_modality,",
        "detail": "projects.configs.datasets.custom_nus-3d",
        "documentation": {}
    },
    {
        "label": "evaluation",
        "kind": 5,
        "importPath": "projects.configs.datasets.custom_nus-3d",
        "description": "projects.configs.datasets.custom_nus-3d",
        "peekOfCode": "evaluation = dict(interval=24, pipeline=eval_pipeline)",
        "detail": "projects.configs.datasets.custom_nus-3d",
        "documentation": {}
    },
    {
        "label": "dataset_type",
        "kind": 5,
        "importPath": "projects.configs.datasets.custom_waymo-3d",
        "description": "projects.configs.datasets.custom_waymo-3d",
        "peekOfCode": "dataset_type = 'CustomWaymoDataset'\ndata_root = 'data/waymo/kitti_format/'\nfile_client_args = dict(backend='disk')\n# Uncomment the following if use ceph or other file clients.\n# See https://mmcv.readthedocs.io/en/latest/api.html#mmcv.fileio.FileClient\n# for more details.\n# file_client_args = dict(\n#     backend='petrel', path_mapping=dict(data='s3://waymo_data/'))\nimg_norm_cfg = dict(\n    mean=[103.530, 116.280, 123.675], std=[1.0, 1.0, 1.0], to_rgb=False)",
        "detail": "projects.configs.datasets.custom_waymo-3d",
        "documentation": {}
    },
    {
        "label": "data_root",
        "kind": 5,
        "importPath": "projects.configs.datasets.custom_waymo-3d",
        "description": "projects.configs.datasets.custom_waymo-3d",
        "peekOfCode": "data_root = 'data/waymo/kitti_format/'\nfile_client_args = dict(backend='disk')\n# Uncomment the following if use ceph or other file clients.\n# See https://mmcv.readthedocs.io/en/latest/api.html#mmcv.fileio.FileClient\n# for more details.\n# file_client_args = dict(\n#     backend='petrel', path_mapping=dict(data='s3://waymo_data/'))\nimg_norm_cfg = dict(\n    mean=[103.530, 116.280, 123.675], std=[1.0, 1.0, 1.0], to_rgb=False)\nclass_names = ['Car', 'Pedestrian', 'Cyclist']",
        "detail": "projects.configs.datasets.custom_waymo-3d",
        "documentation": {}
    },
    {
        "label": "file_client_args",
        "kind": 5,
        "importPath": "projects.configs.datasets.custom_waymo-3d",
        "description": "projects.configs.datasets.custom_waymo-3d",
        "peekOfCode": "file_client_args = dict(backend='disk')\n# Uncomment the following if use ceph or other file clients.\n# See https://mmcv.readthedocs.io/en/latest/api.html#mmcv.fileio.FileClient\n# for more details.\n# file_client_args = dict(\n#     backend='petrel', path_mapping=dict(data='s3://waymo_data/'))\nimg_norm_cfg = dict(\n    mean=[103.530, 116.280, 123.675], std=[1.0, 1.0, 1.0], to_rgb=False)\nclass_names = ['Car', 'Pedestrian', 'Cyclist']\npoint_cloud_range = [-74.88, -74.88, -2, 74.88, 74.88, 4]",
        "detail": "projects.configs.datasets.custom_waymo-3d",
        "documentation": {}
    },
    {
        "label": "img_norm_cfg",
        "kind": 5,
        "importPath": "projects.configs.datasets.custom_waymo-3d",
        "description": "projects.configs.datasets.custom_waymo-3d",
        "peekOfCode": "img_norm_cfg = dict(\n    mean=[103.530, 116.280, 123.675], std=[1.0, 1.0, 1.0], to_rgb=False)\nclass_names = ['Car', 'Pedestrian', 'Cyclist']\npoint_cloud_range = [-74.88, -74.88, -2, 74.88, 74.88, 4]\ninput_modality = dict(use_lidar=False, use_camera=True)\ndb_sampler = dict(\n    data_root=data_root,\n    info_path=data_root + 'waymo_dbinfos_train.pkl',\n    rate=1.0,\n    prepare=dict(",
        "detail": "projects.configs.datasets.custom_waymo-3d",
        "documentation": {}
    },
    {
        "label": "class_names",
        "kind": 5,
        "importPath": "projects.configs.datasets.custom_waymo-3d",
        "description": "projects.configs.datasets.custom_waymo-3d",
        "peekOfCode": "class_names = ['Car', 'Pedestrian', 'Cyclist']\npoint_cloud_range = [-74.88, -74.88, -2, 74.88, 74.88, 4]\ninput_modality = dict(use_lidar=False, use_camera=True)\ndb_sampler = dict(\n    data_root=data_root,\n    info_path=data_root + 'waymo_dbinfos_train.pkl',\n    rate=1.0,\n    prepare=dict(\n        filter_by_difficulty=[-1],\n        filter_by_min_points=dict(Car=5, Pedestrian=10, Cyclist=10)),",
        "detail": "projects.configs.datasets.custom_waymo-3d",
        "documentation": {}
    },
    {
        "label": "point_cloud_range",
        "kind": 5,
        "importPath": "projects.configs.datasets.custom_waymo-3d",
        "description": "projects.configs.datasets.custom_waymo-3d",
        "peekOfCode": "point_cloud_range = [-74.88, -74.88, -2, 74.88, 74.88, 4]\ninput_modality = dict(use_lidar=False, use_camera=True)\ndb_sampler = dict(\n    data_root=data_root,\n    info_path=data_root + 'waymo_dbinfos_train.pkl',\n    rate=1.0,\n    prepare=dict(\n        filter_by_difficulty=[-1],\n        filter_by_min_points=dict(Car=5, Pedestrian=10, Cyclist=10)),\n    classes=class_names,",
        "detail": "projects.configs.datasets.custom_waymo-3d",
        "documentation": {}
    },
    {
        "label": "input_modality",
        "kind": 5,
        "importPath": "projects.configs.datasets.custom_waymo-3d",
        "description": "projects.configs.datasets.custom_waymo-3d",
        "peekOfCode": "input_modality = dict(use_lidar=False, use_camera=True)\ndb_sampler = dict(\n    data_root=data_root,\n    info_path=data_root + 'waymo_dbinfos_train.pkl',\n    rate=1.0,\n    prepare=dict(\n        filter_by_difficulty=[-1],\n        filter_by_min_points=dict(Car=5, Pedestrian=10, Cyclist=10)),\n    classes=class_names,\n    sample_groups=dict(Car=15, Pedestrian=10, Cyclist=10),",
        "detail": "projects.configs.datasets.custom_waymo-3d",
        "documentation": {}
    },
    {
        "label": "db_sampler",
        "kind": 5,
        "importPath": "projects.configs.datasets.custom_waymo-3d",
        "description": "projects.configs.datasets.custom_waymo-3d",
        "peekOfCode": "db_sampler = dict(\n    data_root=data_root,\n    info_path=data_root + 'waymo_dbinfos_train.pkl',\n    rate=1.0,\n    prepare=dict(\n        filter_by_difficulty=[-1],\n        filter_by_min_points=dict(Car=5, Pedestrian=10, Cyclist=10)),\n    classes=class_names,\n    sample_groups=dict(Car=15, Pedestrian=10, Cyclist=10),\n    points_loader=dict(",
        "detail": "projects.configs.datasets.custom_waymo-3d",
        "documentation": {}
    },
    {
        "label": "train_pipeline",
        "kind": 5,
        "importPath": "projects.configs.datasets.custom_waymo-3d",
        "description": "projects.configs.datasets.custom_waymo-3d",
        "peekOfCode": "train_pipeline = [\n    dict(type='LoadMultiViewImageFromFiles', to_float32=True),\n    dict(type='PhotoMetricDistortionMultiViewImage'),\n    dict(type='LoadAnnotations3D', with_bbox_3d=True, with_label_3d=True, with_attr_label=False),\n    dict(type='ObjectRangeFilter', point_cloud_range=point_cloud_range),\n    dict(type='ObjectNameFilter', classes=class_names),\n    dict(type='NormalizeMultiviewImage', **img_norm_cfg),\n    dict(type='PadMultiViewImage', size_divisor=32),\n    dict(type='DefaultFormatBundle3D', class_names=class_names),\n    dict(type='CustomCollect3D', keys=['gt_bboxes_3d', 'gt_labels_3d', 'img'])",
        "detail": "projects.configs.datasets.custom_waymo-3d",
        "documentation": {}
    },
    {
        "label": "test_pipeline",
        "kind": 5,
        "importPath": "projects.configs.datasets.custom_waymo-3d",
        "description": "projects.configs.datasets.custom_waymo-3d",
        "peekOfCode": "test_pipeline = [\n    dict(type='LoadMultiViewImageFromFiles', to_float32=True),\n    dict(type='NormalizeMultiviewImage', **img_norm_cfg),\n    dict(type='PadMultiViewImage', size_divisor=32),\n    dict(\n        type='MultiScaleFlipAug3D',\n        img_scale=(1920, 1280),\n        pts_scale_ratio=1,\n        flip=False,\n        transforms=[",
        "detail": "projects.configs.datasets.custom_waymo-3d",
        "documentation": {}
    },
    {
        "label": "data",
        "kind": 5,
        "importPath": "projects.configs.datasets.custom_waymo-3d",
        "description": "projects.configs.datasets.custom_waymo-3d",
        "peekOfCode": "data = dict(\n    samples_per_gpu=2,\n    workers_per_gpu=4,\n    train=dict(\n        type='RepeatDataset',\n        times=2,\n        dataset=dict(\n            type=dataset_type,\n            data_root=data_root,\n            ann_file=data_root + 'waymo_infos_train.pkl',",
        "detail": "projects.configs.datasets.custom_waymo-3d",
        "documentation": {}
    },
    {
        "label": "evaluation",
        "kind": 5,
        "importPath": "projects.configs.datasets.custom_waymo-3d",
        "description": "projects.configs.datasets.custom_waymo-3d",
        "peekOfCode": "evaluation = dict(interval=24, pipeline=test_pipeline)",
        "detail": "projects.configs.datasets.custom_waymo-3d",
        "documentation": {}
    },
    {
        "label": "custom_train_detector",
        "kind": 2,
        "importPath": "projects.mmdet3d_plugin.bevformer.apis.mmdet_train",
        "description": "projects.mmdet3d_plugin.bevformer.apis.mmdet_train",
        "peekOfCode": "def custom_train_detector(model,\n                   dataset,\n                   cfg,\n                   distributed=False,\n                   validate=False,\n                   timestamp=None,\n                   eval_model=None,\n                   meta=None):\n    logger = get_root_logger(cfg.log_level)\n    # prepare data loaders",
        "detail": "projects.mmdet3d_plugin.bevformer.apis.mmdet_train",
        "documentation": {}
    },
    {
        "label": "custom_encode_mask_results",
        "kind": 2,
        "importPath": "projects.mmdet3d_plugin.bevformer.apis.test",
        "description": "projects.mmdet3d_plugin.bevformer.apis.test",
        "peekOfCode": "def custom_encode_mask_results(mask_results):\n    \"\"\"Encode bitmap mask to RLE code. Semantic Masks only\n    Args:\n        mask_results (list | tuple[list]): bitmap mask results.\n            In mask scoring rcnn, mask_results is a tuple of (segm_results,\n            segm_cls_score).\n    Returns:\n        list | tuple: RLE encoded mask.\n    \"\"\"\n    cls_segms = mask_results",
        "detail": "projects.mmdet3d_plugin.bevformer.apis.test",
        "documentation": {}
    },
    {
        "label": "custom_multi_gpu_test",
        "kind": 2,
        "importPath": "projects.mmdet3d_plugin.bevformer.apis.test",
        "description": "projects.mmdet3d_plugin.bevformer.apis.test",
        "peekOfCode": "def custom_multi_gpu_test(model, data_loader, tmpdir=None, gpu_collect=False):\n    \"\"\"Test model with multiple gpus.\n    This method tests model with multiple gpus and collects the results\n    under two different modes: gpu and cpu modes. By setting 'gpu_collect=True'\n    it encodes results to gpu tensors and use gpu communication for results\n    collection. On cpu mode it saves the results on different gpus to 'tmpdir'\n    and collects them by the rank 0 worker.\n    Args:\n        model (nn.Module): Model to be tested.\n        data_loader (nn.Dataloader): Pytorch data loader.",
        "detail": "projects.mmdet3d_plugin.bevformer.apis.test",
        "documentation": {}
    },
    {
        "label": "collect_results_cpu",
        "kind": 2,
        "importPath": "projects.mmdet3d_plugin.bevformer.apis.test",
        "description": "projects.mmdet3d_plugin.bevformer.apis.test",
        "peekOfCode": "def collect_results_cpu(result_part, size, tmpdir=None):\n    rank, world_size = get_dist_info()\n    # create a tmp dir if it is not specified\n    if tmpdir is None:\n        MAX_LEN = 512\n        # 32 is whitespace\n        dir_tensor = torch.full((MAX_LEN, ),\n                                32,\n                                dtype=torch.uint8,\n                                device='cuda')",
        "detail": "projects.mmdet3d_plugin.bevformer.apis.test",
        "documentation": {}
    },
    {
        "label": "collect_results_gpu",
        "kind": 2,
        "importPath": "projects.mmdet3d_plugin.bevformer.apis.test",
        "description": "projects.mmdet3d_plugin.bevformer.apis.test",
        "peekOfCode": "def collect_results_gpu(result_part, size):\n    collect_results_cpu(result_part, size)",
        "detail": "projects.mmdet3d_plugin.bevformer.apis.test",
        "documentation": {}
    },
    {
        "label": "custom_train_model",
        "kind": 2,
        "importPath": "projects.mmdet3d_plugin.bevformer.apis.train",
        "description": "projects.mmdet3d_plugin.bevformer.apis.train",
        "peekOfCode": "def custom_train_model(model,\n                dataset,\n                cfg,\n                distributed=False,\n                validate=False,\n                timestamp=None,\n                eval_model=None,\n                meta=None):\n    \"\"\"A function wrapper for launching model training according to cfg.\n    Because we need different eval_hook in runner. Should be deprecated in the",
        "detail": "projects.mmdet3d_plugin.bevformer.apis.train",
        "documentation": {}
    },
    {
        "label": "train_model",
        "kind": 2,
        "importPath": "projects.mmdet3d_plugin.bevformer.apis.train",
        "description": "projects.mmdet3d_plugin.bevformer.apis.train",
        "peekOfCode": "def train_model(model,\n                dataset,\n                cfg,\n                distributed=False,\n                validate=False,\n                timestamp=None,\n                meta=None):\n    \"\"\"A function wrapper for launching model training according to cfg.\n    Because we need different eval_hook in runner. Should be deprecated in the\n    future.",
        "detail": "projects.mmdet3d_plugin.bevformer.apis.train",
        "documentation": {}
    },
    {
        "label": "BEVHead",
        "kind": 6,
        "importPath": "projects.mmdet3d_plugin.bevformer.dense_heads.bev_head",
        "description": "projects.mmdet3d_plugin.bevformer.dense_heads.bev_head",
        "peekOfCode": "class BEVHead(BaseModule):\n    def __init__(self, \n                 bev_h,\n                 bev_w,\n                 pc_range,\n                 embed_dims,\n                 transformer, \n                 positional_encoding: dict,\n                 pts_bbox_head_3d: dict, \n                 init_cfg=None,",
        "detail": "projects.mmdet3d_plugin.bevformer.dense_heads.bev_head",
        "documentation": {}
    },
    {
        "label": "FreeAnchor3DHeadV2",
        "kind": 6,
        "importPath": "projects.mmdet3d_plugin.bevformer.dense_heads.bev_head",
        "description": "projects.mmdet3d_plugin.bevformer.dense_heads.bev_head",
        "peekOfCode": "class FreeAnchor3DHeadV2(FreeAnchor3DHead):\n    @force_fp32(apply_to=('pred'))\n    def loss(self,\n             gt_bboxes_list,\n             gt_labels_list,\n             pred,\n             gt_bboxes_ignore=None,\n             img_metas=None):\n            cls_scores, bbox_preds, dir_cls_preds = pred\n            return super().loss(cls_scores, bbox_preds, dir_cls_preds, gt_bboxes_list, gt_labels_list, img_metas, gt_bboxes_ignore)",
        "detail": "projects.mmdet3d_plugin.bevformer.dense_heads.bev_head",
        "documentation": {}
    },
    {
        "label": "BEVFormerHead",
        "kind": 6,
        "importPath": "projects.mmdet3d_plugin.bevformer.dense_heads.bevformer_head",
        "description": "projects.mmdet3d_plugin.bevformer.dense_heads.bevformer_head",
        "peekOfCode": "class BEVFormerHead(DETRHead):\n    \"\"\"Head of Detr3D.\n    Args:\n        with_box_refine (bool): Whether to refine the reference points\n            in the decoder. Defaults to False.\n        as_two_stage (bool) : Whether to generate the proposal from\n            the outputs of encoder.\n        transformer (obj:`ConfigDict`): ConfigDict is used for building\n            the Encoder and Decoder.\n        bev_h, bev_w (int): spatial shape of BEV queries.",
        "detail": "projects.mmdet3d_plugin.bevformer.dense_heads.bevformer_head",
        "documentation": {}
    },
    {
        "label": "BEVFormerHead_GroupDETR",
        "kind": 6,
        "importPath": "projects.mmdet3d_plugin.bevformer.dense_heads.bevformer_head",
        "description": "projects.mmdet3d_plugin.bevformer.dense_heads.bevformer_head",
        "peekOfCode": "class BEVFormerHead_GroupDETR(BEVFormerHead):\n    def __init__(self,\n                 *args,\n                 group_detr=1,\n                 **kwargs):\n        self.group_detr = group_detr\n        assert 'num_query' in kwargs\n        kwargs['num_query'] = group_detr * kwargs['num_query']\n        super().__init__(*args, **kwargs)\n    def forward(self, mlvl_feats, img_metas, prev_bev=None,  only_bev=False):",
        "detail": "projects.mmdet3d_plugin.bevformer.dense_heads.bevformer_head",
        "documentation": {}
    },
    {
        "label": "BEVFormer",
        "kind": 6,
        "importPath": "projects.mmdet3d_plugin.bevformer.detectors.bevformer",
        "description": "projects.mmdet3d_plugin.bevformer.detectors.bevformer",
        "peekOfCode": "class BEVFormer(MVXTwoStageDetector):\n    \"\"\"BEVFormer.\n    Args:\n        video_test_mode (bool): Decide whether to use temporal information during inference.\n    \"\"\"\n    def __init__(self,\n                 use_grid_mask=False,\n                 pts_voxel_layer=None,\n                 pts_voxel_encoder=None,\n                 pts_middle_encoder=None,",
        "detail": "projects.mmdet3d_plugin.bevformer.detectors.bevformer",
        "documentation": {}
    },
    {
        "label": "BEVFormerV2",
        "kind": 6,
        "importPath": "projects.mmdet3d_plugin.bevformer.detectors.bevformerV2",
        "description": "projects.mmdet3d_plugin.bevformer.detectors.bevformerV2",
        "peekOfCode": "class BEVFormerV2(MVXTwoStageDetector):\n    \"\"\"BEVFormer.\n    Args:\n        video_test_mode (bool): Decide whether to use temporal information during inference.\n    \"\"\"\n    def __init__(self,\n                 use_grid_mask=False,\n                 pts_voxel_layer=None,\n                 pts_voxel_encoder=None,\n                 pts_middle_encoder=None,",
        "detail": "projects.mmdet3d_plugin.bevformer.detectors.bevformerV2",
        "documentation": {}
    },
    {
        "label": "BEVFormer_fp16",
        "kind": 6,
        "importPath": "projects.mmdet3d_plugin.bevformer.detectors.bevformer_fp16",
        "description": "projects.mmdet3d_plugin.bevformer.detectors.bevformer_fp16",
        "peekOfCode": "class BEVFormer_fp16(BEVFormer):\n    \"\"\"\n    The default version BEVFormer currently can not support FP16. \n    We provide this version to resolve this issue.\n    \"\"\"\n    @auto_fp16(apply_to=('img', 'prev_bev', 'points'))\n    def forward_train(self,\n                      points=None,\n                      img_metas=None,\n                      gt_bboxes_3d=None,",
        "detail": "projects.mmdet3d_plugin.bevformer.detectors.bevformer_fp16",
        "documentation": {}
    },
    {
        "label": "TransferWeight",
        "kind": 6,
        "importPath": "projects.mmdet3d_plugin.bevformer.hooks.custom_hooks",
        "description": "projects.mmdet3d_plugin.bevformer.hooks.custom_hooks",
        "peekOfCode": "class TransferWeight(Hook):\n    def __init__(self, every_n_inters=1):\n        self.every_n_inters=every_n_inters\n    def after_train_iter(self, runner):\n        if self.every_n_inner_iters(runner, self.every_n_inters):\n            runner.eval_model.load_state_dict(runner.model.state_dict())",
        "detail": "projects.mmdet3d_plugin.bevformer.hooks.custom_hooks",
        "documentation": {}
    },
    {
        "label": "MyCustomBaseTransformerLayer",
        "kind": 6,
        "importPath": "projects.mmdet3d_plugin.bevformer.modules.custom_base_transformer_layer",
        "description": "projects.mmdet3d_plugin.bevformer.modules.custom_base_transformer_layer",
        "peekOfCode": "class MyCustomBaseTransformerLayer(BaseModule):\n    \"\"\"Base `TransformerLayer` for vision transformer.\n    It can be built from `mmcv.ConfigDict` and support more flexible\n    customization, for example, using any number of `FFN or LN ` and\n    use different kinds of `attention` by specifying a list of `ConfigDict`\n    named `attn_cfgs`. It is worth mentioning that it supports `prenorm`\n    when you specifying `norm` as the first element of `operation_order`.\n    More details about the `prenorm`: `On Layer Normalization in the\n    Transformer Architecture <https://arxiv.org/abs/2002.04745>`_ .\n    Args:",
        "detail": "projects.mmdet3d_plugin.bevformer.modules.custom_base_transformer_layer",
        "documentation": {}
    },
    {
        "label": "DetectionTransformerDecoder",
        "kind": 6,
        "importPath": "projects.mmdet3d_plugin.bevformer.modules.decoder",
        "description": "projects.mmdet3d_plugin.bevformer.modules.decoder",
        "peekOfCode": "class DetectionTransformerDecoder(TransformerLayerSequence):\n    \"\"\"Implements the decoder in DETR3D transformer.\n    Args:\n        return_intermediate (bool): Whether to return intermediate outputs.\n        coder_norm_cfg (dict): Config of last normalization layer. Default：\n            `LN`.\n    \"\"\"\n    def __init__(self, *args, return_intermediate=False, **kwargs):\n        super(DetectionTransformerDecoder, self).__init__(*args, **kwargs)\n        self.return_intermediate = return_intermediate",
        "detail": "projects.mmdet3d_plugin.bevformer.modules.decoder",
        "documentation": {}
    },
    {
        "label": "CustomMSDeformableAttention",
        "kind": 6,
        "importPath": "projects.mmdet3d_plugin.bevformer.modules.decoder",
        "description": "projects.mmdet3d_plugin.bevformer.modules.decoder",
        "peekOfCode": "class CustomMSDeformableAttention(BaseModule):\n    \"\"\"An attention module used in Deformable-Detr.\n    `Deformable DETR: Deformable Transformers for End-to-End Object Detection.\n    <https://arxiv.org/pdf/2010.04159.pdf>`_.\n    Args:\n        embed_dims (int): The embedding dimension of Attention.\n            Default: 256.\n        num_heads (int): Parallel attention heads. Default: 64.\n        num_levels (int): The number of feature map used in\n            Attention. Default: 4.",
        "detail": "projects.mmdet3d_plugin.bevformer.modules.decoder",
        "documentation": {}
    },
    {
        "label": "inverse_sigmoid",
        "kind": 2,
        "importPath": "projects.mmdet3d_plugin.bevformer.modules.decoder",
        "description": "projects.mmdet3d_plugin.bevformer.modules.decoder",
        "peekOfCode": "def inverse_sigmoid(x, eps=1e-5):\n    \"\"\"Inverse function of sigmoid.\n    Args:\n        x (Tensor): The tensor to do the\n            inverse.\n        eps (float): EPS avoid numerical\n            overflow. Defaults 1e-5.\n    Returns:\n        Tensor: The x has passed the inverse\n            function of sigmoid, has same",
        "detail": "projects.mmdet3d_plugin.bevformer.modules.decoder",
        "documentation": {}
    },
    {
        "label": "ext_module",
        "kind": 5,
        "importPath": "projects.mmdet3d_plugin.bevformer.modules.decoder",
        "description": "projects.mmdet3d_plugin.bevformer.modules.decoder",
        "peekOfCode": "ext_module = ext_loader.load_ext(\n    '_ext', ['ms_deform_attn_backward', 'ms_deform_attn_forward'])\ndef inverse_sigmoid(x, eps=1e-5):\n    \"\"\"Inverse function of sigmoid.\n    Args:\n        x (Tensor): The tensor to do the\n            inverse.\n        eps (float): EPS avoid numerical\n            overflow. Defaults 1e-5.\n    Returns:",
        "detail": "projects.mmdet3d_plugin.bevformer.modules.decoder",
        "documentation": {}
    },
    {
        "label": "BEVFormerEncoder",
        "kind": 6,
        "importPath": "projects.mmdet3d_plugin.bevformer.modules.encoder",
        "description": "projects.mmdet3d_plugin.bevformer.modules.encoder",
        "peekOfCode": "class BEVFormerEncoder(TransformerLayerSequence):\n    \"\"\"\n    Attention with both self and cross\n    Implements the decoder in DETR transformer.\n    Args:\n        return_intermediate (bool): Whether to return intermediate outputs.\n        coder_norm_cfg (dict): Config of last normalization layer. Default：\n            `LN`.\n    \"\"\"\n    def __init__(self, *args, pc_range=None, num_points_in_pillar=4, return_intermediate=False, dataset_type='nuscenes',",
        "detail": "projects.mmdet3d_plugin.bevformer.modules.encoder",
        "documentation": {}
    },
    {
        "label": "BEVFormerLayer",
        "kind": 6,
        "importPath": "projects.mmdet3d_plugin.bevformer.modules.encoder",
        "description": "projects.mmdet3d_plugin.bevformer.modules.encoder",
        "peekOfCode": "class BEVFormerLayer(MyCustomBaseTransformerLayer):\n    \"\"\"Implements decoder layer in DETR transformer.\n    Args:\n        attn_cfgs (list[`mmcv.ConfigDict`] | list[dict] | dict )):\n            Configs for self_attention or cross_attention, the order\n            should be consistent with it in `operation_order`. If it is\n            a dict, it would be expand to the number of attention in\n            `operation_order`.\n        feedforward_channels (int): The hidden dimension for FFNs.\n        ffn_dropout (float): Probability of an element to be zeroed",
        "detail": "projects.mmdet3d_plugin.bevformer.modules.encoder",
        "documentation": {}
    },
    {
        "label": "MM_BEVFormerLayer",
        "kind": 6,
        "importPath": "projects.mmdet3d_plugin.bevformer.modules.encoder",
        "description": "projects.mmdet3d_plugin.bevformer.modules.encoder",
        "peekOfCode": "class MM_BEVFormerLayer(MyCustomBaseTransformerLayer):\n    \"\"\"multi-modality fusion layer.\n    \"\"\"\n    def __init__(self,\n                 attn_cfgs,\n                 feedforward_channels,\n                 ffn_dropout=0.0,\n                 operation_order=None,\n                 act_cfg=dict(type='ReLU', inplace=True),\n                 norm_cfg=dict(type='LN'),",
        "detail": "projects.mmdet3d_plugin.bevformer.modules.encoder",
        "documentation": {}
    },
    {
        "label": "ext_module",
        "kind": 5,
        "importPath": "projects.mmdet3d_plugin.bevformer.modules.encoder",
        "description": "projects.mmdet3d_plugin.bevformer.modules.encoder",
        "peekOfCode": "ext_module = ext_loader.load_ext(\n    '_ext', ['ms_deform_attn_backward', 'ms_deform_attn_forward'])\n@TRANSFORMER_LAYER_SEQUENCE.register_module()\nclass BEVFormerEncoder(TransformerLayerSequence):\n    \"\"\"\n    Attention with both self and cross\n    Implements the decoder in DETR transformer.\n    Args:\n        return_intermediate (bool): Whether to return intermediate outputs.\n        coder_norm_cfg (dict): Config of last normalization layer. Default：",
        "detail": "projects.mmdet3d_plugin.bevformer.modules.encoder",
        "documentation": {}
    },
    {
        "label": "GroupMultiheadAttention",
        "kind": 6,
        "importPath": "projects.mmdet3d_plugin.bevformer.modules.group_attention",
        "description": "projects.mmdet3d_plugin.bevformer.modules.group_attention",
        "peekOfCode": "class GroupMultiheadAttention(BaseModule):\n    \"\"\"A wrapper for ``torch.nn.MultiheadAttention``.\n    This module implements MultiheadAttention with identity connection,\n    and positional encoding  is also passed as input.\n    Args:\n        embed_dims (int): The embedding dimension.\n        num_heads (int): Parallel attention heads.\n        attn_drop (float): A Dropout layer on attn_output_weights.\n            Default: 0.0.\n        proj_drop (float): A Dropout layer after `nn.MultiheadAttention`.",
        "detail": "projects.mmdet3d_plugin.bevformer.modules.group_attention",
        "documentation": {}
    },
    {
        "label": "MultiScaleDeformableAttnFunction_fp16",
        "kind": 6,
        "importPath": "projects.mmdet3d_plugin.bevformer.modules.multi_scale_deformable_attn_function",
        "description": "projects.mmdet3d_plugin.bevformer.modules.multi_scale_deformable_attn_function",
        "peekOfCode": "class MultiScaleDeformableAttnFunction_fp16(Function):\n    @staticmethod\n    @custom_fwd(cast_inputs=torch.float16)\n    def forward(ctx, value, value_spatial_shapes, value_level_start_index,\n                sampling_locations, attention_weights, im2col_step):\n        \"\"\"GPU version of multi-scale deformable attention.\n        Args:\n            value (Tensor): The value has shape\n                (bs, num_keys, mum_heads, embed_dims//num_heads)\n            value_spatial_shapes (Tensor): Spatial shape of",
        "detail": "projects.mmdet3d_plugin.bevformer.modules.multi_scale_deformable_attn_function",
        "documentation": {}
    },
    {
        "label": "MultiScaleDeformableAttnFunction_fp32",
        "kind": 6,
        "importPath": "projects.mmdet3d_plugin.bevformer.modules.multi_scale_deformable_attn_function",
        "description": "projects.mmdet3d_plugin.bevformer.modules.multi_scale_deformable_attn_function",
        "peekOfCode": "class MultiScaleDeformableAttnFunction_fp32(Function):\n    @staticmethod\n    @custom_fwd(cast_inputs=torch.float32)\n    def forward(ctx, value, value_spatial_shapes, value_level_start_index,\n                sampling_locations, attention_weights, im2col_step):\n        \"\"\"GPU version of multi-scale deformable attention.\n        Args:\n            value (Tensor): The value has shape\n                (bs, num_keys, mum_heads, embed_dims//num_heads)\n            value_spatial_shapes (Tensor): Spatial shape of",
        "detail": "projects.mmdet3d_plugin.bevformer.modules.multi_scale_deformable_attn_function",
        "documentation": {}
    },
    {
        "label": "ext_module",
        "kind": 5,
        "importPath": "projects.mmdet3d_plugin.bevformer.modules.multi_scale_deformable_attn_function",
        "description": "projects.mmdet3d_plugin.bevformer.modules.multi_scale_deformable_attn_function",
        "peekOfCode": "ext_module = ext_loader.load_ext(\n    '_ext', ['ms_deform_attn_backward', 'ms_deform_attn_forward'])\nclass MultiScaleDeformableAttnFunction_fp16(Function):\n    @staticmethod\n    @custom_fwd(cast_inputs=torch.float16)\n    def forward(ctx, value, value_spatial_shapes, value_level_start_index,\n                sampling_locations, attention_weights, im2col_step):\n        \"\"\"GPU version of multi-scale deformable attention.\n        Args:\n            value (Tensor): The value has shape",
        "detail": "projects.mmdet3d_plugin.bevformer.modules.multi_scale_deformable_attn_function",
        "documentation": {}
    },
    {
        "label": "SpatialCrossAttention",
        "kind": 6,
        "importPath": "projects.mmdet3d_plugin.bevformer.modules.spatial_cross_attention",
        "description": "projects.mmdet3d_plugin.bevformer.modules.spatial_cross_attention",
        "peekOfCode": "class SpatialCrossAttention(BaseModule):\n    \"\"\"An attention module used in BEVFormer.\n    Args:\n        embed_dims (int): The embedding dimension of Attention.\n            Default: 256.\n        num_cams (int): The number of cameras\n        dropout (float): A Dropout layer on `inp_residual`.\n            Default: 0..\n        init_cfg (obj:`mmcv.ConfigDict`): The Config for initialization.\n            Default: None.",
        "detail": "projects.mmdet3d_plugin.bevformer.modules.spatial_cross_attention",
        "documentation": {}
    },
    {
        "label": "MSDeformableAttention3D",
        "kind": 6,
        "importPath": "projects.mmdet3d_plugin.bevformer.modules.spatial_cross_attention",
        "description": "projects.mmdet3d_plugin.bevformer.modules.spatial_cross_attention",
        "peekOfCode": "class MSDeformableAttention3D(BaseModule):\n    \"\"\"An attention module used in BEVFormer based on Deformable-Detr.\n    `Deformable DETR: Deformable Transformers for End-to-End Object Detection.\n    <https://arxiv.org/pdf/2010.04159.pdf>`_.\n    Args:\n        embed_dims (int): The embedding dimension of Attention.\n            Default: 256.\n        num_heads (int): Parallel attention heads. Default: 64.\n        num_levels (int): The number of feature map used in\n            Attention. Default: 4.",
        "detail": "projects.mmdet3d_plugin.bevformer.modules.spatial_cross_attention",
        "documentation": {}
    },
    {
        "label": "ext_module",
        "kind": 5,
        "importPath": "projects.mmdet3d_plugin.bevformer.modules.spatial_cross_attention",
        "description": "projects.mmdet3d_plugin.bevformer.modules.spatial_cross_attention",
        "peekOfCode": "ext_module = ext_loader.load_ext(\n    '_ext', ['ms_deform_attn_backward', 'ms_deform_attn_forward'])\n@ATTENTION.register_module()\nclass SpatialCrossAttention(BaseModule):\n    \"\"\"An attention module used in BEVFormer.\n    Args:\n        embed_dims (int): The embedding dimension of Attention.\n            Default: 256.\n        num_cams (int): The number of cameras\n        dropout (float): A Dropout layer on `inp_residual`.",
        "detail": "projects.mmdet3d_plugin.bevformer.modules.spatial_cross_attention",
        "documentation": {}
    },
    {
        "label": "TemporalSelfAttention",
        "kind": 6,
        "importPath": "projects.mmdet3d_plugin.bevformer.modules.temporal_self_attention",
        "description": "projects.mmdet3d_plugin.bevformer.modules.temporal_self_attention",
        "peekOfCode": "class TemporalSelfAttention(BaseModule):\n    \"\"\"An attention module used in BEVFormer based on Deformable-Detr.\n    `Deformable DETR: Deformable Transformers for End-to-End Object Detection.\n    <https://arxiv.org/pdf/2010.04159.pdf>`_.\n    Args:\n        embed_dims (int): The embedding dimension of Attention.\n            Default: 256.\n        num_heads (int): Parallel attention heads. Default: 64.\n        num_levels (int): The number of feature map used in\n            Attention. Default: 4.",
        "detail": "projects.mmdet3d_plugin.bevformer.modules.temporal_self_attention",
        "documentation": {}
    },
    {
        "label": "ext_module",
        "kind": 5,
        "importPath": "projects.mmdet3d_plugin.bevformer.modules.temporal_self_attention",
        "description": "projects.mmdet3d_plugin.bevformer.modules.temporal_self_attention",
        "peekOfCode": "ext_module = ext_loader.load_ext(\n    '_ext', ['ms_deform_attn_backward', 'ms_deform_attn_forward'])\n@ATTENTION.register_module()\nclass TemporalSelfAttention(BaseModule):\n    \"\"\"An attention module used in BEVFormer based on Deformable-Detr.\n    `Deformable DETR: Deformable Transformers for End-to-End Object Detection.\n    <https://arxiv.org/pdf/2010.04159.pdf>`_.\n    Args:\n        embed_dims (int): The embedding dimension of Attention.\n            Default: 256.",
        "detail": "projects.mmdet3d_plugin.bevformer.modules.temporal_self_attention",
        "documentation": {}
    },
    {
        "label": "PerceptionTransformer",
        "kind": 6,
        "importPath": "projects.mmdet3d_plugin.bevformer.modules.transformer",
        "description": "projects.mmdet3d_plugin.bevformer.modules.transformer",
        "peekOfCode": "class PerceptionTransformer(BaseModule):\n    \"\"\"Implements the Detr3D transformer.\n    Args:\n        as_two_stage (bool): Generate query from encoder features.\n            Default: False.\n        num_feature_levels (int): Number of feature maps from FPN:\n            Default: 4.\n        two_stage_num_proposals (int): Number of proposals when set\n            `as_two_stage` as True. Default: 300.\n    \"\"\"",
        "detail": "projects.mmdet3d_plugin.bevformer.modules.transformer",
        "documentation": {}
    },
    {
        "label": "ResNetFusion",
        "kind": 6,
        "importPath": "projects.mmdet3d_plugin.bevformer.modules.transformerV2",
        "description": "projects.mmdet3d_plugin.bevformer.modules.transformerV2",
        "peekOfCode": "class ResNetFusion(BaseModule):\n    def __init__(self, in_channels, out_channels, inter_channels, num_layer, norm_cfg=dict(type='SyncBN'),\n                 with_cp=False):\n        super(ResNetFusion, self).__init__()\n        layers = []\n        self.inter_channels = inter_channels\n        for i in range(num_layer):\n            if i == 0:\n                if inter_channels == in_channels:\n                    layers.append(BasicBlock(in_channels, inter_channels, stride=1, norm_cfg=norm_cfg))",
        "detail": "projects.mmdet3d_plugin.bevformer.modules.transformerV2",
        "documentation": {}
    },
    {
        "label": "PerceptionTransformerBEVEncoder",
        "kind": 6,
        "importPath": "projects.mmdet3d_plugin.bevformer.modules.transformerV2",
        "description": "projects.mmdet3d_plugin.bevformer.modules.transformerV2",
        "peekOfCode": "class PerceptionTransformerBEVEncoder(BaseModule):\n    def __init__(self,\n                 num_feature_levels=4,\n                 num_cams=6,\n                 two_stage_num_proposals=300,\n                 encoder=None,\n                 embed_dims=256,\n                 use_cams_embeds=True,\n                 rotate_center=[100, 100],\n                 **kwargs):",
        "detail": "projects.mmdet3d_plugin.bevformer.modules.transformerV2",
        "documentation": {}
    },
    {
        "label": "PerceptionTransformerV2",
        "kind": 6,
        "importPath": "projects.mmdet3d_plugin.bevformer.modules.transformerV2",
        "description": "projects.mmdet3d_plugin.bevformer.modules.transformerV2",
        "peekOfCode": "class PerceptionTransformerV2(PerceptionTransformerBEVEncoder):\n    \"\"\"Implements the Detr3D transformer.\n    Args:\n        as_two_stage (bool): Generate query from encoder features.\n            Default: False.\n        num_feature_levels (int): Number of feature maps from FPN:\n            Default: 4.\n        two_stage_num_proposals (int): Number of proposals when set\n            `as_two_stage` as True. Default: 300.\n    \"\"\"",
        "detail": "projects.mmdet3d_plugin.bevformer.modules.transformerV2",
        "documentation": {}
    },
    {
        "label": "EpochBasedRunner_video",
        "kind": 6,
        "importPath": "projects.mmdet3d_plugin.bevformer.runner.epoch_based_runner",
        "description": "projects.mmdet3d_plugin.bevformer.runner.epoch_based_runner",
        "peekOfCode": "class EpochBasedRunner_video(EpochBasedRunner):\n    ''' \n    # basic logic\n    input_sequence = [a, b, c] # given a sequence of samples\n    prev_bev = None\n    for each in input_sequcene[:-1]\n        prev_bev = eval_model(each, prev_bev)) # inference only.\n    model(input_sequcene[-1], prev_bev) # train the last sample.\n    '''\n    def __init__(self,",
        "detail": "projects.mmdet3d_plugin.bevformer.runner.epoch_based_runner",
        "documentation": {}
    },
    {
        "label": "HungarianAssigner3D",
        "kind": 6,
        "importPath": "projects.mmdet3d_plugin.core.bbox.assigners.hungarian_assigner_3d",
        "description": "projects.mmdet3d_plugin.core.bbox.assigners.hungarian_assigner_3d",
        "peekOfCode": "class HungarianAssigner3D(BaseAssigner):\n    \"\"\"Computes one-to-one matching between predictions and ground truth.\n    This class computes an assignment between the targets and the predictions\n    based on the costs. The costs are weighted sum of three components:\n    classification cost, regression L1 cost and regression iou cost. The\n    targets don't include the no_object, so generally there are more\n    predictions than targets. After the one-to-one matching, the un-matched\n    are treated as backgrounds. Thus each query prediction will be assigned\n    with `0` or a positive integer indicating the ground truth index:\n    - 0: negative sample, no assigned gt",
        "detail": "projects.mmdet3d_plugin.core.bbox.assigners.hungarian_assigner_3d",
        "documentation": {}
    },
    {
        "label": "NMSFreeCoder",
        "kind": 6,
        "importPath": "projects.mmdet3d_plugin.core.bbox.coders.nms_free_coder",
        "description": "projects.mmdet3d_plugin.core.bbox.coders.nms_free_coder",
        "peekOfCode": "class NMSFreeCoder(BaseBBoxCoder):\n    \"\"\"Bbox coder for NMS-free detector.\n    Args:\n        pc_range (list[float]): Range of point cloud.\n        post_center_range (list[float]): Limit of the center.\n            Default: None.\n        max_num (int): Max number to be kept. Default: 100.\n        score_threshold (float): Threshold to filter boxes based on score.\n            Default: None.\n        code_size (int): Code size of bboxes. Default: 9",
        "detail": "projects.mmdet3d_plugin.core.bbox.coders.nms_free_coder",
        "documentation": {}
    },
    {
        "label": "BBox3DL1Cost",
        "kind": 6,
        "importPath": "projects.mmdet3d_plugin.core.bbox.match_costs.match_cost",
        "description": "projects.mmdet3d_plugin.core.bbox.match_costs.match_cost",
        "peekOfCode": "class BBox3DL1Cost(object):\n    \"\"\"BBox3DL1Cost.\n     Args:\n         weight (int | float, optional): loss_weight\n    \"\"\"\n    def __init__(self, weight=1.):\n        self.weight = weight\n    def __call__(self, bbox_pred, gt_bboxes):\n        \"\"\"\n        Args:",
        "detail": "projects.mmdet3d_plugin.core.bbox.match_costs.match_cost",
        "documentation": {}
    },
    {
        "label": "SmoothL1Cost",
        "kind": 6,
        "importPath": "projects.mmdet3d_plugin.core.bbox.match_costs.match_cost",
        "description": "projects.mmdet3d_plugin.core.bbox.match_costs.match_cost",
        "peekOfCode": "class SmoothL1Cost(object):\n    \"\"\"SmoothL1Cost.\n     Args:\n         weight (int | float, optional): loss weight\n     Examples:\n         >>> from mmdet.core.bbox.match_costs.match_cost import IoUCost\n         >>> import torch\n         >>> self = IoUCost()\n         >>> bboxes = torch.FloatTensor([[1,1, 2, 2], [2, 2, 3, 4]])\n         >>> gt_bboxes = torch.FloatTensor([[0, 0, 2, 4], [1, 2, 3, 4]])",
        "detail": "projects.mmdet3d_plugin.core.bbox.match_costs.match_cost",
        "documentation": {}
    },
    {
        "label": "smooth_l1_loss",
        "kind": 2,
        "importPath": "projects.mmdet3d_plugin.core.bbox.match_costs.match_cost",
        "description": "projects.mmdet3d_plugin.core.bbox.match_costs.match_cost",
        "peekOfCode": "def smooth_l1_loss(pred, target, beta=1.0):\n    \"\"\"Smooth L1 loss.\n    Args:\n        pred (torch.Tensor): The prediction.\n        target (torch.Tensor): The learning target of the prediction.\n        beta (float, optional): The threshold in the piecewise function.\n            Defaults to 1.0.\n    Returns:\n        torch.Tensor: Calculated loss\n    \"\"\"",
        "detail": "projects.mmdet3d_plugin.core.bbox.match_costs.match_cost",
        "documentation": {}
    },
    {
        "label": "normalize_bbox",
        "kind": 2,
        "importPath": "projects.mmdet3d_plugin.core.bbox.util",
        "description": "projects.mmdet3d_plugin.core.bbox.util",
        "peekOfCode": "def normalize_bbox(bboxes, pc_range):\n    cx = bboxes[..., 0:1]\n    cy = bboxes[..., 1:2]\n    cz = bboxes[..., 2:3]\n    w = bboxes[..., 3:4].log()\n    l = bboxes[..., 4:5].log()\n    h = bboxes[..., 5:6].log()\n    rot = bboxes[..., 6:7]\n    if bboxes.size(-1) > 7:\n        vx = bboxes[..., 7:8] ",
        "detail": "projects.mmdet3d_plugin.core.bbox.util",
        "documentation": {}
    },
    {
        "label": "denormalize_bbox",
        "kind": 2,
        "importPath": "projects.mmdet3d_plugin.core.bbox.util",
        "description": "projects.mmdet3d_plugin.core.bbox.util",
        "peekOfCode": "def denormalize_bbox(normalized_bboxes, pc_range):\n    # rotation \n    rot_sine = normalized_bboxes[..., 6:7]\n    rot_cosine = normalized_bboxes[..., 7:8]\n    rot = torch.atan2(rot_sine, rot_cosine)\n    # center in the bev\n    cx = normalized_bboxes[..., 0:1]\n    cy = normalized_bboxes[..., 1:2]\n    cz = normalized_bboxes[..., 4:5]\n    # size",
        "detail": "projects.mmdet3d_plugin.core.bbox.util",
        "documentation": {}
    },
    {
        "label": "CustomDistEvalHook",
        "kind": 6,
        "importPath": "projects.mmdet3d_plugin.core.evaluation.eval_hooks",
        "description": "projects.mmdet3d_plugin.core.evaluation.eval_hooks",
        "peekOfCode": "class CustomDistEvalHook(BaseDistEvalHook):\n    def __init__(self, *args, dynamic_intervals=None,  **kwargs):\n        super(CustomDistEvalHook, self).__init__(*args, **kwargs)\n        self.use_dynamic_intervals = dynamic_intervals is not None\n        if self.use_dynamic_intervals:\n            self.dynamic_milestones, self.dynamic_intervals = \\\n                _calc_dynamic_intervals(self.interval, dynamic_intervals)\n    def _decide_interval(self, runner):\n        if self.use_dynamic_intervals:\n            progress = runner.epoch if self.by_epoch else runner.iter",
        "detail": "projects.mmdet3d_plugin.core.evaluation.eval_hooks",
        "documentation": {}
    },
    {
        "label": "KITTI2Waymo",
        "kind": 6,
        "importPath": "projects.mmdet3d_plugin.core.evaluation.kitti2waymo",
        "description": "projects.mmdet3d_plugin.core.evaluation.kitti2waymo",
        "peekOfCode": "class KITTI2Waymo(object):\n    \"\"\"KITTI predictions to Waymo converter.\n    This class serves as the converter to change predictions from KITTI to\n    Waymo format.\n    Args:\n        kitti_result_files (list[dict]): Predictions in KITTI format.\n        waymo_tfrecords_dir (str): Directory to load waymo raw data.\n        waymo_results_save_dir (str): Directory to save converted predictions\n            in waymo format (.bin files).\n        waymo_results_final_path (str): Path to save combined",
        "detail": "projects.mmdet3d_plugin.core.evaluation.kitti2waymo",
        "documentation": {}
    },
    {
        "label": "CropResizeFlipImage",
        "kind": 6,
        "importPath": "projects.mmdet3d_plugin.datasets.pipelines.augmentation",
        "description": "projects.mmdet3d_plugin.datasets.pipelines.augmentation",
        "peekOfCode": "class CropResizeFlipImage(object):\n    \"\"\"Fixed Crop and then randim resize and flip the image. Note the flip requires to flip the feature in the network   \n    ida_aug_conf = {\n        \"reisze\": [576, 608, 640, 672, 704]  # stride of 32 based on 640 (0.9, 1.1)\n        \"reisze\": [512, 544, 576, 608, 640, 672, 704, 736, 768]  #  (0.8, 1.2)\n        \"reisze\": [448, 480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800, 832]  #  (0.7, 1.3)\n        \"crop\": (0, 260, 1600, 900), \n        \"H\": 900,\n        \"W\": 1600,\n        \"rand_flip\": True,",
        "detail": "projects.mmdet3d_plugin.datasets.pipelines.augmentation",
        "documentation": {}
    },
    {
        "label": "GlobalRotScaleTransImage",
        "kind": 6,
        "importPath": "projects.mmdet3d_plugin.datasets.pipelines.augmentation",
        "description": "projects.mmdet3d_plugin.datasets.pipelines.augmentation",
        "peekOfCode": "class GlobalRotScaleTransImage(object):\n    \"\"\"Random resize, Crop and flip the image\n    Args:\n        size (tuple, optional): Fixed padding size.\n    \"\"\"\n    def __init__(\n            self,\n            rot_range=[-0.3925, 0.3925],\n            scale_ratio_range=[0.95, 1.05],\n            translation_std=[0, 0, 0],",
        "detail": "projects.mmdet3d_plugin.datasets.pipelines.augmentation",
        "documentation": {}
    },
    {
        "label": "DD3DMapper",
        "kind": 6,
        "importPath": "projects.mmdet3d_plugin.datasets.pipelines.dd3d_mapper",
        "description": "projects.mmdet3d_plugin.datasets.pipelines.dd3d_mapper",
        "peekOfCode": "class DD3DMapper:\n    def __init__(self,\n                 is_train: bool = True,\n                 tasks=dict(box2d_on=True, box3d_on=True),\n                 ):\n        self.is_train = is_train\n        self.task_manager = TaskManager(**tasks)\n    def __call__(self, results):\n        if results['mono_input_dict'] is None:\n            return results",
        "detail": "projects.mmdet3d_plugin.datasets.pipelines.dd3d_mapper",
        "documentation": {}
    },
    {
        "label": "CustomDefaultFormatBundle3D",
        "kind": 6,
        "importPath": "projects.mmdet3d_plugin.datasets.pipelines.formating",
        "description": "projects.mmdet3d_plugin.datasets.pipelines.formating",
        "peekOfCode": "class CustomDefaultFormatBundle3D(DefaultFormatBundle3D):\n    \"\"\"Default formatting bundle.\n    It simplifies the pipeline of formatting common fields for voxels,\n    including \"proposals\", \"gt_bboxes\", \"gt_labels\", \"gt_masks\" and\n    \"gt_semantic_seg\".\n    These fields are formatted as follows.\n    - img: (1)transpose, (2)to tensor, (3)to DataContainer (stack=True)\n    - proposals: (1)to tensor, (2)to DataContainer\n    - gt_bboxes: (1)to tensor, (2)to DataContainer\n    - gt_bboxes_ignore: (1)to tensor, (2)to DataContainer",
        "detail": "projects.mmdet3d_plugin.datasets.pipelines.formating",
        "documentation": {}
    },
    {
        "label": "PadMultiViewImage",
        "kind": 6,
        "importPath": "projects.mmdet3d_plugin.datasets.pipelines.transform_3d",
        "description": "projects.mmdet3d_plugin.datasets.pipelines.transform_3d",
        "peekOfCode": "class PadMultiViewImage(object):\n    \"\"\"Pad the multi-view image.\n    There are two padding modes: (1) pad to a fixed size and (2) pad to the\n    minimum size that is divisible by some number.\n    Added keys are \"pad_shape\", \"pad_fixed_size\", \"pad_size_divisor\",\n    Args:\n        size (tuple, optional): Fixed padding size.\n        size_divisor (int, optional): The divisor of padded size.\n        pad_val (float, optional): Padding value, 0 by default.\n    \"\"\"",
        "detail": "projects.mmdet3d_plugin.datasets.pipelines.transform_3d",
        "documentation": {}
    },
    {
        "label": "NormalizeMultiviewImage",
        "kind": 6,
        "importPath": "projects.mmdet3d_plugin.datasets.pipelines.transform_3d",
        "description": "projects.mmdet3d_plugin.datasets.pipelines.transform_3d",
        "peekOfCode": "class NormalizeMultiviewImage(object):\n    \"\"\"Normalize the image.\n    Added key is \"img_norm_cfg\".\n    Args:\n        mean (sequence): Mean values of 3 channels.\n        std (sequence): Std values of 3 channels.\n        to_rgb (bool): Whether to convert the image from BGR to RGB,\n            default is true.\n    \"\"\"\n    def __init__(self, mean, std, to_rgb=True):",
        "detail": "projects.mmdet3d_plugin.datasets.pipelines.transform_3d",
        "documentation": {}
    },
    {
        "label": "PhotoMetricDistortionMultiViewImage",
        "kind": 6,
        "importPath": "projects.mmdet3d_plugin.datasets.pipelines.transform_3d",
        "description": "projects.mmdet3d_plugin.datasets.pipelines.transform_3d",
        "peekOfCode": "class PhotoMetricDistortionMultiViewImage:\n    \"\"\"Apply photometric distortion to image sequentially, every transformation\n    is applied with a probability of 0.5. The position of random contrast is in\n    second or second to last.\n    1. random brightness\n    2. random contrast (mode 0)\n    3. convert color from BGR to HSV\n    4. random saturation\n    5. random hue\n    6. convert color from HSV to BGR",
        "detail": "projects.mmdet3d_plugin.datasets.pipelines.transform_3d",
        "documentation": {}
    },
    {
        "label": "CustomCollect3D",
        "kind": 6,
        "importPath": "projects.mmdet3d_plugin.datasets.pipelines.transform_3d",
        "description": "projects.mmdet3d_plugin.datasets.pipelines.transform_3d",
        "peekOfCode": "class CustomCollect3D(object):\n    \"\"\"Collect data from the loader relevant to the specific task.\n    This is usually the last stage of the data loader pipeline. Typically keys\n    is set to some subset of \"img\", \"proposals\", \"gt_bboxes\",\n    \"gt_bboxes_ignore\", \"gt_labels\", and/or \"gt_masks\".\n    The \"img_meta\" item is always populated.  The contents of the \"img_meta\"\n    dictionary depends on \"meta_keys\". By default this includes:\n        - 'img_shape': shape of the image input to the network as a tuple \\\n            (h, w, c).  Note that images may be zero padded on the \\\n            bottom/right if the batch tensor is larger than this shape.",
        "detail": "projects.mmdet3d_plugin.datasets.pipelines.transform_3d",
        "documentation": {}
    },
    {
        "label": "RandomScaleImageMultiViewImage",
        "kind": 6,
        "importPath": "projects.mmdet3d_plugin.datasets.pipelines.transform_3d",
        "description": "projects.mmdet3d_plugin.datasets.pipelines.transform_3d",
        "peekOfCode": "class RandomScaleImageMultiViewImage(object):\n    \"\"\"Random scale the image\n    Args:\n        scales\n    \"\"\"\n    def __init__(self, scales=[]):\n        self.scales = scales\n        assert len(self.scales)==1\n    def __call__(self, results):\n        \"\"\"Call function to pad images, masks, semantic segmentation maps.",
        "detail": "projects.mmdet3d_plugin.datasets.pipelines.transform_3d",
        "documentation": {}
    },
    {
        "label": "DistributedSampler",
        "kind": 6,
        "importPath": "projects.mmdet3d_plugin.datasets.samplers.distributed_sampler",
        "description": "projects.mmdet3d_plugin.datasets.samplers.distributed_sampler",
        "peekOfCode": "class DistributedSampler(_DistributedSampler):\n    def __init__(self,\n                 dataset=None,\n                 num_replicas=None,\n                 rank=None,\n                 shuffle=True,\n                 seed=0):\n        super().__init__(\n            dataset, num_replicas=num_replicas, rank=rank, shuffle=shuffle)\n        # for the compatibility from PyTorch 1.3+",
        "detail": "projects.mmdet3d_plugin.datasets.samplers.distributed_sampler",
        "documentation": {}
    },
    {
        "label": "DistributedGroupSampler",
        "kind": 6,
        "importPath": "projects.mmdet3d_plugin.datasets.samplers.group_sampler",
        "description": "projects.mmdet3d_plugin.datasets.samplers.group_sampler",
        "peekOfCode": "class DistributedGroupSampler(Sampler):\n    \"\"\"Sampler that restricts data loading to a subset of the dataset.\n    It is especially useful in conjunction with\n    :class:`torch.nn.parallel.DistributedDataParallel`. In such case, each\n    process can pass a DistributedSampler instance as a DataLoader sampler,\n    and load a subset of the original dataset that is exclusive to it.\n    .. note::\n        Dataset is assumed to be of constant size.\n    Arguments:\n        dataset: Dataset used for sampling.",
        "detail": "projects.mmdet3d_plugin.datasets.samplers.group_sampler",
        "documentation": {}
    },
    {
        "label": "build_sampler",
        "kind": 2,
        "importPath": "projects.mmdet3d_plugin.datasets.samplers.sampler",
        "description": "projects.mmdet3d_plugin.datasets.samplers.sampler",
        "peekOfCode": "def build_sampler(cfg, default_args):\n    return build_from_cfg(cfg, SAMPLER, default_args)",
        "detail": "projects.mmdet3d_plugin.datasets.samplers.sampler",
        "documentation": {}
    },
    {
        "label": "SAMPLER",
        "kind": 5,
        "importPath": "projects.mmdet3d_plugin.datasets.samplers.sampler",
        "description": "projects.mmdet3d_plugin.datasets.samplers.sampler",
        "peekOfCode": "SAMPLER = Registry('sampler')\ndef build_sampler(cfg, default_args):\n    return build_from_cfg(cfg, SAMPLER, default_args)",
        "detail": "projects.mmdet3d_plugin.datasets.samplers.sampler",
        "documentation": {}
    },
    {
        "label": "build_dataloader",
        "kind": 2,
        "importPath": "projects.mmdet3d_plugin.datasets.builder",
        "description": "projects.mmdet3d_plugin.datasets.builder",
        "peekOfCode": "def build_dataloader(dataset,\n                     samples_per_gpu,\n                     workers_per_gpu,\n                     num_gpus=1,\n                     dist=True,\n                     shuffle=True,\n                     seed=None,\n                     shuffler_sampler=None,\n                     nonshuffler_sampler=None,\n                     **kwargs):",
        "detail": "projects.mmdet3d_plugin.datasets.builder",
        "documentation": {}
    },
    {
        "label": "worker_init_fn",
        "kind": 2,
        "importPath": "projects.mmdet3d_plugin.datasets.builder",
        "description": "projects.mmdet3d_plugin.datasets.builder",
        "peekOfCode": "def worker_init_fn(worker_id, num_workers, rank, seed):\n    # The seed of each worker equals to\n    # num_worker * rank + worker_id + user_seed\n    worker_seed = num_workers * rank + worker_id + seed\n    np.random.seed(worker_seed)\n    random.seed(worker_seed)\n# Copyright (c) OpenMMLab. All rights reserved.\nimport platform\nfrom mmcv.utils import Registry, build_from_cfg\nfrom mmdet.datasets import DATASETS",
        "detail": "projects.mmdet3d_plugin.datasets.builder",
        "documentation": {}
    },
    {
        "label": "custom_build_dataset",
        "kind": 2,
        "importPath": "projects.mmdet3d_plugin.datasets.builder",
        "description": "projects.mmdet3d_plugin.datasets.builder",
        "peekOfCode": "def custom_build_dataset(cfg, default_args=None):\n    from mmdet3d.datasets.dataset_wrappers import CBGSDataset\n    from mmdet.datasets.dataset_wrappers import (ClassBalancedDataset,\n                                                 ConcatDataset, RepeatDataset)\n    if isinstance(cfg, (list, tuple)):\n        dataset = ConcatDataset([custom_build_dataset(c, default_args) for c in cfg])\n    elif cfg['type'] == 'ConcatDataset':\n        dataset = ConcatDataset(\n            [custom_build_dataset(c, default_args) for c in cfg['datasets']],\n            cfg.get('separate_eval', True))",
        "detail": "projects.mmdet3d_plugin.datasets.builder",
        "documentation": {}
    },
    {
        "label": "OBJECTSAMPLERS",
        "kind": 5,
        "importPath": "projects.mmdet3d_plugin.datasets.builder",
        "description": "projects.mmdet3d_plugin.datasets.builder",
        "peekOfCode": "OBJECTSAMPLERS = Registry('Object sampler')\ndef custom_build_dataset(cfg, default_args=None):\n    from mmdet3d.datasets.dataset_wrappers import CBGSDataset\n    from mmdet.datasets.dataset_wrappers import (ClassBalancedDataset,\n                                                 ConcatDataset, RepeatDataset)\n    if isinstance(cfg, (list, tuple)):\n        dataset = ConcatDataset([custom_build_dataset(c, default_args) for c in cfg])\n    elif cfg['type'] == 'ConcatDataset':\n        dataset = ConcatDataset(\n            [custom_build_dataset(c, default_args) for c in cfg['datasets']],",
        "detail": "projects.mmdet3d_plugin.datasets.builder",
        "documentation": {}
    },
    {
        "label": "CustomNuScenesDataset",
        "kind": 6,
        "importPath": "projects.mmdet3d_plugin.datasets.nuscenes_dataset",
        "description": "projects.mmdet3d_plugin.datasets.nuscenes_dataset",
        "peekOfCode": "class CustomNuScenesDataset(NuScenesDataset):\n    r\"\"\"NuScenes Dataset.\n    This datset only add camera intrinsics and extrinsics to the results.\n    \"\"\"\n    def __init__(self, queue_length=4, bev_size=(200, 200), overlap_test=False, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.queue_length = queue_length\n        self.overlap_test = overlap_test\n        self.bev_size = bev_size\n    def prepare_train_data(self, index):",
        "detail": "projects.mmdet3d_plugin.datasets.nuscenes_dataset",
        "documentation": {}
    },
    {
        "label": "CustomNuScenesDatasetV2",
        "kind": 6,
        "importPath": "projects.mmdet3d_plugin.datasets.nuscenes_dataset_v2",
        "description": "projects.mmdet3d_plugin.datasets.nuscenes_dataset_v2",
        "peekOfCode": "class CustomNuScenesDatasetV2(NuScenesDataset):\n    def __init__(self, frames=(),mono_cfg=None, overlap_test=False,*args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.frames = frames\n        self.queue_length = len(frames)\n        self.overlap_test = overlap_test\n        self.mono_cfg = mono_cfg\n        if not self.test_mode and mono_cfg is not None:\n            self.mono_dataset = DD3DNuscenesDataset(**mono_cfg)\n    def prepare_test_data(self, index):",
        "detail": "projects.mmdet3d_plugin.datasets.nuscenes_dataset_v2",
        "documentation": {}
    },
    {
        "label": "CustomNuScenesMonoDataset",
        "kind": 6,
        "importPath": "projects.mmdet3d_plugin.datasets.nuscenes_mono_dataset",
        "description": "projects.mmdet3d_plugin.datasets.nuscenes_mono_dataset",
        "peekOfCode": "class CustomNuScenesMonoDataset(CocoDataset):\n    r\"\"\"Monocular 3D detection on NuScenes Dataset.\n    This class serves as the API for experiments on the NuScenes Dataset.\n    Please refer to `NuScenes Dataset <https://www.nuscenes.org/download>`_\n    for data downloading.\n    Args:\n        ann_file (str): Path of annotation file.\n        data_root (str): Path of dataset root.\n        load_interval (int, optional): Interval of loading the dataset. It is\n            used to uniformly sample the dataset. Defaults to 1.",
        "detail": "projects.mmdet3d_plugin.datasets.nuscenes_mono_dataset",
        "documentation": {}
    },
    {
        "label": "output_to_nusc_box",
        "kind": 2,
        "importPath": "projects.mmdet3d_plugin.datasets.nuscenes_mono_dataset",
        "description": "projects.mmdet3d_plugin.datasets.nuscenes_mono_dataset",
        "peekOfCode": "def output_to_nusc_box(detection):\n    \"\"\"Convert the output to the box class in the nuScenes.\n    Args:\n        detection (dict): Detection results.\n            - boxes_3d (:obj:`BaseInstance3DBoxes`): Detection bbox.\n            - scores_3d (torch.Tensor): Detection scores.\n            - labels_3d (torch.Tensor): Predicted box labels.\n            - attrs_3d (torch.Tensor, optional): Predicted attributes.\n    Returns:\n        list[:obj:`NuScenesBox`]: List of standard NuScenesBoxes.",
        "detail": "projects.mmdet3d_plugin.datasets.nuscenes_mono_dataset",
        "documentation": {}
    },
    {
        "label": "cam_nusc_box_to_global",
        "kind": 2,
        "importPath": "projects.mmdet3d_plugin.datasets.nuscenes_mono_dataset",
        "description": "projects.mmdet3d_plugin.datasets.nuscenes_mono_dataset",
        "peekOfCode": "def cam_nusc_box_to_global(info,\n                           boxes,\n                           attrs,\n                           classes,\n                           eval_configs,\n                           eval_version='detection_cvpr_2019'):\n    \"\"\"Convert the box from camera to global coordinate.\n    Args:\n        info (dict): Info for a specific sample data, including the\n            calibration information.",
        "detail": "projects.mmdet3d_plugin.datasets.nuscenes_mono_dataset",
        "documentation": {}
    },
    {
        "label": "global_nusc_box_to_cam",
        "kind": 2,
        "importPath": "projects.mmdet3d_plugin.datasets.nuscenes_mono_dataset",
        "description": "projects.mmdet3d_plugin.datasets.nuscenes_mono_dataset",
        "peekOfCode": "def global_nusc_box_to_cam(info,\n                           boxes,\n                           classes,\n                           eval_configs,\n                           eval_version='detection_cvpr_2019'):\n    \"\"\"Convert the box from global to camera coordinate.\n    Args:\n        info (dict): Info for a specific sample data, including the\n            calibration information.\n        boxes (list[:obj:`NuScenesBox`]): List of predicted NuScenesBoxes.",
        "detail": "projects.mmdet3d_plugin.datasets.nuscenes_mono_dataset",
        "documentation": {}
    },
    {
        "label": "nusc_box_to_cam_box3d",
        "kind": 2,
        "importPath": "projects.mmdet3d_plugin.datasets.nuscenes_mono_dataset",
        "description": "projects.mmdet3d_plugin.datasets.nuscenes_mono_dataset",
        "peekOfCode": "def nusc_box_to_cam_box3d(boxes):\n    \"\"\"Convert boxes from :obj:`NuScenesBox` to :obj:`CameraInstance3DBoxes`.\n    Args:\n        boxes (list[:obj:`NuScenesBox`]): List of predicted NuScenesBoxes.\n    Returns:\n        tuple (:obj:`CameraInstance3DBoxes` | torch.Tensor | torch.Tensor): \\\n            Converted 3D bounding boxes, scores and labels.\n    \"\"\"\n    locs = torch.Tensor([b.center for b in boxes]).view(-1, 3)\n    dims = torch.Tensor([b.wlh for b in boxes]).view(-1, 3)",
        "detail": "projects.mmdet3d_plugin.datasets.nuscenes_mono_dataset",
        "documentation": {}
    },
    {
        "label": "DetectionBox_modified",
        "kind": 6,
        "importPath": "projects.mmdet3d_plugin.datasets.nuscnes_eval",
        "description": "projects.mmdet3d_plugin.datasets.nuscnes_eval",
        "peekOfCode": "class DetectionBox_modified(DetectionBox):\n    def __init__(self, *args, token=None, visibility=None, index=None, **kwargs):\n        '''\n        add annotation token\n        '''\n        super().__init__(*args, **kwargs)\n        self.token = token\n        self.visibility = visibility\n        self.index = index\n    def serialize(self) -> dict:",
        "detail": "projects.mmdet3d_plugin.datasets.nuscnes_eval",
        "documentation": {}
    },
    {
        "label": "NuScenesEval_custom",
        "kind": 6,
        "importPath": "projects.mmdet3d_plugin.datasets.nuscnes_eval",
        "description": "projects.mmdet3d_plugin.datasets.nuscnes_eval",
        "peekOfCode": "class NuScenesEval_custom(NuScenesEval):\n    \"\"\"\n    Dummy class for backward-compatibility. Same as DetectionEval.\n    \"\"\"\n    def __init__(self,\n                 nusc: NuScenes,\n                 config: DetectionConfig,\n                 result_path: str,\n                 eval_set: str,\n                 output_dir: str = None,",
        "detail": "projects.mmdet3d_plugin.datasets.nuscnes_eval",
        "documentation": {}
    },
    {
        "label": "class_tp_curve",
        "kind": 2,
        "importPath": "projects.mmdet3d_plugin.datasets.nuscnes_eval",
        "description": "projects.mmdet3d_plugin.datasets.nuscnes_eval",
        "peekOfCode": "def class_tp_curve(md_list: DetectionMetricDataList,\n                   metrics: DetectionMetrics,\n                   detection_name: str,\n                   min_recall: float,\n                   dist_th_tp: float,\n                   savepath: str = None,\n                   ax: Axis = None) -> None:\n    \"\"\"\n    Plot the true positive curve for the specified class.\n    :param md_list: DetectionMetricDataList instance.",
        "detail": "projects.mmdet3d_plugin.datasets.nuscnes_eval",
        "documentation": {}
    },
    {
        "label": "center_in_image",
        "kind": 2,
        "importPath": "projects.mmdet3d_plugin.datasets.nuscnes_eval",
        "description": "projects.mmdet3d_plugin.datasets.nuscnes_eval",
        "peekOfCode": "def center_in_image(box, intrinsic: np.ndarray, imsize: Tuple[int, int], vis_level: int = BoxVisibility.ANY) -> bool:\n    \"\"\"\n    Check if a box is visible inside an image without accounting for occlusions.\n    :param box: The box to be checked.\n    :param intrinsic: <float: 3, 3>. Intrinsic camera matrix.\n    :param imsize: (width, height).\n    :param vis_level: One of the enumerations of <BoxVisibility>.\n    :return True if visibility condition is satisfied.\n    \"\"\"\n    center_3d = box.center.reshape(3, 1)",
        "detail": "projects.mmdet3d_plugin.datasets.nuscnes_eval",
        "documentation": {}
    },
    {
        "label": "exist_corners_in_image_but_not_all",
        "kind": 2,
        "importPath": "projects.mmdet3d_plugin.datasets.nuscnes_eval",
        "description": "projects.mmdet3d_plugin.datasets.nuscnes_eval",
        "peekOfCode": "def exist_corners_in_image_but_not_all(box, intrinsic: np.ndarray, imsize: Tuple[int, int],\n                                       vis_level: int = BoxVisibility.ANY) -> bool:\n    \"\"\"\n    Check if a box is visible in images but not all corners in image .\n    :param box: The box to be checked.\n    :param intrinsic: <float: 3, 3>. Intrinsic camera matrix.\n    :param imsize: (width, height).\n    :param vis_level: One of the enumerations of <BoxVisibility>.\n    :return True if visibility condition is satisfied.\n    \"\"\"",
        "detail": "projects.mmdet3d_plugin.datasets.nuscnes_eval",
        "documentation": {}
    },
    {
        "label": "load_gt",
        "kind": 2,
        "importPath": "projects.mmdet3d_plugin.datasets.nuscnes_eval",
        "description": "projects.mmdet3d_plugin.datasets.nuscnes_eval",
        "peekOfCode": "def load_gt(nusc: NuScenes, eval_split: str, box_cls, verbose: bool = False):\n    \"\"\"\n    Loads ground truth boxes from DB.\n    :param nusc: A NuScenes instance.\n    :param eval_split: The evaluation split for which we load GT boxes.\n    :param box_cls: Type of box to load, e.g. DetectionBox or TrackingBox.\n    :param verbose: Whether to print messages to stdout.\n    :return: The GT boxes.\n    \"\"\"\n    # Init.",
        "detail": "projects.mmdet3d_plugin.datasets.nuscnes_eval",
        "documentation": {}
    },
    {
        "label": "filter_eval_boxes_by_id",
        "kind": 2,
        "importPath": "projects.mmdet3d_plugin.datasets.nuscnes_eval",
        "description": "projects.mmdet3d_plugin.datasets.nuscnes_eval",
        "peekOfCode": "def filter_eval_boxes_by_id(nusc: NuScenes,\n                            eval_boxes: EvalBoxes,\n                            id=None,\n                            verbose: bool = False) -> EvalBoxes:\n    \"\"\"\n    Applies filtering to boxes. Distance, bike-racks and points per box.\n    :param nusc: An instance of the NuScenes class.\n    :param eval_boxes: An instance of the EvalBoxes class.\n    :param is: the anns token set that used to keep bboxes.\n    :param verbose: Whether to print to stdout.",
        "detail": "projects.mmdet3d_plugin.datasets.nuscnes_eval",
        "documentation": {}
    },
    {
        "label": "filter_eval_boxes_by_visibility",
        "kind": 2,
        "importPath": "projects.mmdet3d_plugin.datasets.nuscnes_eval",
        "description": "projects.mmdet3d_plugin.datasets.nuscnes_eval",
        "peekOfCode": "def filter_eval_boxes_by_visibility(\n        ori_eval_boxes: EvalBoxes,\n        visibility=None,\n        verbose: bool = False) -> EvalBoxes:\n    \"\"\"\n    Applies filtering to boxes. Distance, bike-racks and points per box.\n    :param nusc: An instance of the NuScenes class.\n    :param eval_boxes: An instance of the EvalBoxes class.\n    :param is: the anns token set that used to keep bboxes.\n    :param verbose: Whether to print to stdout.",
        "detail": "projects.mmdet3d_plugin.datasets.nuscnes_eval",
        "documentation": {}
    },
    {
        "label": "filter_by_sample_token",
        "kind": 2,
        "importPath": "projects.mmdet3d_plugin.datasets.nuscnes_eval",
        "description": "projects.mmdet3d_plugin.datasets.nuscnes_eval",
        "peekOfCode": "def filter_by_sample_token(ori_eval_boxes, valid_sample_tokens=[],  verbose=False):\n    eval_boxes = copy.deepcopy(ori_eval_boxes)\n    for sample_token in eval_boxes.sample_tokens:\n        if sample_token not in valid_sample_tokens:\n            eval_boxes.boxes.pop(sample_token)\n    return eval_boxes\ndef filter_eval_boxes_by_overlap(nusc: NuScenes,\n                                 eval_boxes: EvalBoxes,\n                                 verbose: bool = False) -> EvalBoxes:\n    \"\"\"",
        "detail": "projects.mmdet3d_plugin.datasets.nuscnes_eval",
        "documentation": {}
    },
    {
        "label": "filter_eval_boxes_by_overlap",
        "kind": 2,
        "importPath": "projects.mmdet3d_plugin.datasets.nuscnes_eval",
        "description": "projects.mmdet3d_plugin.datasets.nuscnes_eval",
        "peekOfCode": "def filter_eval_boxes_by_overlap(nusc: NuScenes,\n                                 eval_boxes: EvalBoxes,\n                                 verbose: bool = False) -> EvalBoxes:\n    \"\"\"\n    Applies filtering to boxes. basedon overlap .\n    :param nusc: An instance of the NuScenes class.\n    :param eval_boxes: An instance of the EvalBoxes class.\n    :param verbose: Whether to print to stdout.\n    \"\"\"\n    # Accumulators for number of filtered boxes.",
        "detail": "projects.mmdet3d_plugin.datasets.nuscnes_eval",
        "documentation": {}
    },
    {
        "label": "Axis",
        "kind": 5,
        "importPath": "projects.mmdet3d_plugin.datasets.nuscnes_eval",
        "description": "projects.mmdet3d_plugin.datasets.nuscnes_eval",
        "peekOfCode": "Axis = Any\ndef class_tp_curve(md_list: DetectionMetricDataList,\n                   metrics: DetectionMetrics,\n                   detection_name: str,\n                   min_recall: float,\n                   dist_th_tp: float,\n                   savepath: str = None,\n                   ax: Axis = None) -> None:\n    \"\"\"\n    Plot the true positive curve for the specified class.",
        "detail": "projects.mmdet3d_plugin.datasets.nuscnes_eval",
        "documentation": {}
    },
    {
        "label": "NuscenesDataset",
        "kind": 6,
        "importPath": "projects.mmdet3d_plugin.dd3d.datasets.nuscenes",
        "description": "projects.mmdet3d_plugin.dd3d.datasets.nuscenes",
        "peekOfCode": "class NuscenesDataset(Dataset):\n    def __init__(self, name, data_root, datum_names=CAMERA_NAMES, min_num_lidar_points=3, min_box_visibility=0.2, **unused):\n        self.data_root = data_root\n        assert name in DATASET_NAME_TO_VERSION\n        version = DATASET_NAME_TO_VERSION[name]\n        self.nusc = NuScenes(version=version, dataroot=data_root, verbose=True)\n        self.datum_names = datum_names\n        self.min_num_lidar_points = min_num_lidar_points\n        self.min_box_visibility = min_box_visibility\n        self.dataset_item_info = self._build_dataset_item_info(name)",
        "detail": "projects.mmdet3d_plugin.dd3d.datasets.nuscenes",
        "documentation": {}
    },
    {
        "label": "DATASET_NAME_TO_VERSION",
        "kind": 5,
        "importPath": "projects.mmdet3d_plugin.dd3d.datasets.nuscenes",
        "description": "projects.mmdet3d_plugin.dd3d.datasets.nuscenes",
        "peekOfCode": "DATASET_NAME_TO_VERSION = {\n    \"nusc_train\": \"v1.0-trainval\",\n    \"nusc_val\": \"v1.0-trainval\",\n    \"nusc_val-subsample-8\": \"v1.0-trainval\",\n    \"nusc_trainval\": \"v1.0-trainval\",\n    \"nusc_test\": \"v1.0-test\",\n    \"nusc_mini_train\": \"v1.0-mini\",\n    \"nusc_mini_val\": \"v1.0-mini\",\n}\nCAMERA_NAMES = ('CAM_FRONT_LEFT', 'CAM_FRONT', 'CAM_FRONT_RIGHT', 'CAM_BACK_LEFT', 'CAM_BACK', 'CAM_BACK_RIGHT')",
        "detail": "projects.mmdet3d_plugin.dd3d.datasets.nuscenes",
        "documentation": {}
    },
    {
        "label": "CAMERA_NAMES",
        "kind": 5,
        "importPath": "projects.mmdet3d_plugin.dd3d.datasets.nuscenes",
        "description": "projects.mmdet3d_plugin.dd3d.datasets.nuscenes",
        "peekOfCode": "CAMERA_NAMES = ('CAM_FRONT_LEFT', 'CAM_FRONT', 'CAM_FRONT_RIGHT', 'CAM_BACK_LEFT', 'CAM_BACK', 'CAM_BACK_RIGHT')\nATTRIBUTE_IDS = {\n    'vehicle.moving': 0,\n    'vehicle.parked': 1,\n    'vehicle.stopped': 2,\n    'pedestrian.moving': 0,\n    'pedestrian.standing': 1,\n    'pedestrian.sitting_lying_down': 2,\n    'cycle.with_rider': 0,\n    'cycle.without_rider': 1,",
        "detail": "projects.mmdet3d_plugin.dd3d.datasets.nuscenes",
        "documentation": {}
    },
    {
        "label": "ATTRIBUTE_IDS",
        "kind": 5,
        "importPath": "projects.mmdet3d_plugin.dd3d.datasets.nuscenes",
        "description": "projects.mmdet3d_plugin.dd3d.datasets.nuscenes",
        "peekOfCode": "ATTRIBUTE_IDS = {\n    'vehicle.moving': 0,\n    'vehicle.parked': 1,\n    'vehicle.stopped': 2,\n    'pedestrian.moving': 0,\n    'pedestrian.standing': 1,\n    'pedestrian.sitting_lying_down': 2,\n    'cycle.with_rider': 0,\n    'cycle.without_rider': 1,\n}",
        "detail": "projects.mmdet3d_plugin.dd3d.datasets.nuscenes",
        "documentation": {}
    },
    {
        "label": "CATEGORY_IDS",
        "kind": 5,
        "importPath": "projects.mmdet3d_plugin.dd3d.datasets.nuscenes",
        "description": "projects.mmdet3d_plugin.dd3d.datasets.nuscenes",
        "peekOfCode": "CATEGORY_IDS = OrderedDict({\n    'barrier': 0,\n    'bicycle': 1,\n    'bus': 2,\n    'car': 3,\n    'construction_vehicle': 4,\n    'motorcycle': 5,\n    'pedestrian': 6,\n    'traffic_cone': 7,\n    'trailer': 8,",
        "detail": "projects.mmdet3d_plugin.dd3d.datasets.nuscenes",
        "documentation": {}
    },
    {
        "label": "COLORS",
        "kind": 5,
        "importPath": "projects.mmdet3d_plugin.dd3d.datasets.nuscenes",
        "description": "projects.mmdet3d_plugin.dd3d.datasets.nuscenes",
        "peekOfCode": "COLORS = [float_to_uint8_color(clr) for clr in sns.color_palette(\"bright\", n_colors=10)]\nCOLORMAP = OrderedDict({\n    'barrier': COLORS[8],  # yellow\n    'bicycle': COLORS[0],  # blue\n    'bus': COLORS[6],  # pink\n    'car': COLORS[2],  # green\n    'construction_vehicle': COLORS[7],  # gray\n    'motorcycle': COLORS[4],  # purple\n    'pedestrian': COLORS[1],  # orange\n    'traffic_cone': COLORS[3],  # red",
        "detail": "projects.mmdet3d_plugin.dd3d.datasets.nuscenes",
        "documentation": {}
    },
    {
        "label": "COLORMAP",
        "kind": 5,
        "importPath": "projects.mmdet3d_plugin.dd3d.datasets.nuscenes",
        "description": "projects.mmdet3d_plugin.dd3d.datasets.nuscenes",
        "peekOfCode": "COLORMAP = OrderedDict({\n    'barrier': COLORS[8],  # yellow\n    'bicycle': COLORS[0],  # blue\n    'bus': COLORS[6],  # pink\n    'car': COLORS[2],  # green\n    'construction_vehicle': COLORS[7],  # gray\n    'motorcycle': COLORS[4],  # purple\n    'pedestrian': COLORS[1],  # orange\n    'traffic_cone': COLORS[3],  # red\n    'trailer': COLORS[9],  # skyblue",
        "detail": "projects.mmdet3d_plugin.dd3d.datasets.nuscenes",
        "documentation": {}
    },
    {
        "label": "MAX_NUM_ATTRIBUTES",
        "kind": 5,
        "importPath": "projects.mmdet3d_plugin.dd3d.datasets.nuscenes",
        "description": "projects.mmdet3d_plugin.dd3d.datasets.nuscenes",
        "peekOfCode": "MAX_NUM_ATTRIBUTES = 3\ndef _compute_iou(box1, box2):\n    \"\"\"\n    Parameters\n    ----------\n    box1, box2:\n        (x1, y1, x2, y2)\n    \"\"\"\n    xx1 = max(box1[0], box2[0])\n    yy1 = max(box1[1], box2[1])",
        "detail": "projects.mmdet3d_plugin.dd3d.datasets.nuscenes",
        "documentation": {}
    },
    {
        "label": "transform_instance_annotations",
        "kind": 2,
        "importPath": "projects.mmdet3d_plugin.dd3d.datasets.transform_utils",
        "description": "projects.mmdet3d_plugin.dd3d.datasets.transform_utils",
        "peekOfCode": "def transform_instance_annotations(\n    annotation,\n    transforms,\n    image_size,\n):\n    \"\"\"Adapted from:\n        https://github.com/facebookresearch/detectron2/blob/master/detectron2/data/detection_utils.py#L254\n    The changes from original:\n        - The presence of 2D bounding box (i.e. \"bbox\" field) is assumed by default in d2; here it's optional.\n        - Add optional 3D bounding box support.",
        "detail": "projects.mmdet3d_plugin.dd3d.datasets.transform_utils",
        "documentation": {}
    },
    {
        "label": "annotations_to_instances",
        "kind": 2,
        "importPath": "projects.mmdet3d_plugin.dd3d.datasets.transform_utils",
        "description": "projects.mmdet3d_plugin.dd3d.datasets.transform_utils",
        "peekOfCode": "def annotations_to_instances(\n    annos,\n    image_size,\n    intrinsics=None,\n):\n    \"\"\"\n    Create an :class:`Instances` object used by the models,\n    from instance annotations in the dataset dict.\n    Args:\n        annos (list[dict]): a list of instance annotations in one image, each",
        "detail": "projects.mmdet3d_plugin.dd3d.datasets.transform_utils",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "projects.mmdet3d_plugin.dd3d.datasets.transform_utils",
        "description": "projects.mmdet3d_plugin.dd3d.datasets.transform_utils",
        "peekOfCode": "__all__ = [\"transform_instance_annotations\", \"annotations_to_instances\"]\ndef transform_instance_annotations(\n    annotation,\n    transforms,\n    image_size,\n):\n    \"\"\"Adapted from:\n        https://github.com/facebookresearch/detectron2/blob/master/detectron2/data/detection_utils.py#L254\n    The changes from original:\n        - The presence of 2D bounding box (i.e. \"bbox\" field) is assumed by default in d2; here it's optional.",
        "detail": "projects.mmdet3d_plugin.dd3d.datasets.transform_utils",
        "documentation": {}
    },
    {
        "label": "IOULoss",
        "kind": 6,
        "importPath": "projects.mmdet3d_plugin.dd3d.layers.iou_loss",
        "description": "projects.mmdet3d_plugin.dd3d.layers.iou_loss",
        "peekOfCode": "class IOULoss(nn.Module):\n    \"\"\"\n    Intersetion Over Union (IoU) loss which supports three\n    different IoU computations:\n    * IoU\n    * Linear IoU\n    * gIoU\n    \"\"\"\n    def __init__(self, loc_loss_type='iou'):\n        super(IOULoss, self).__init__()",
        "detail": "projects.mmdet3d_plugin.dd3d.layers.iou_loss",
        "documentation": {}
    },
    {
        "label": "Scale",
        "kind": 6,
        "importPath": "projects.mmdet3d_plugin.dd3d.layers.normalization",
        "description": "projects.mmdet3d_plugin.dd3d.layers.normalization",
        "peekOfCode": "class Scale(nn.Module):\n    def __init__(self, init_value=1.0):\n        super(Scale, self).__init__()\n        self.scale = nn.Parameter(torch.FloatTensor([init_value]))\n    def forward(self, input):\n        return input * self.scale\nclass Offset(nn.Module):\n    def __init__(self, init_value=0.):\n        super(Offset, self).__init__()\n        self.bias = nn.Parameter(torch.FloatTensor([init_value]))",
        "detail": "projects.mmdet3d_plugin.dd3d.layers.normalization",
        "documentation": {}
    },
    {
        "label": "Offset",
        "kind": 6,
        "importPath": "projects.mmdet3d_plugin.dd3d.layers.normalization",
        "description": "projects.mmdet3d_plugin.dd3d.layers.normalization",
        "peekOfCode": "class Offset(nn.Module):\n    def __init__(self, init_value=0.):\n        super(Offset, self).__init__()\n        self.bias = nn.Parameter(torch.FloatTensor([init_value]))\n    def forward(self, input):\n        return input + self.bias\nclass ModuleListDial(nn.ModuleList):\n    def __init__(self, modules=None):\n        super(ModuleListDial, self).__init__(modules)\n        self.cur_position = 0",
        "detail": "projects.mmdet3d_plugin.dd3d.layers.normalization",
        "documentation": {}
    },
    {
        "label": "ModuleListDial",
        "kind": 6,
        "importPath": "projects.mmdet3d_plugin.dd3d.layers.normalization",
        "description": "projects.mmdet3d_plugin.dd3d.layers.normalization",
        "peekOfCode": "class ModuleListDial(nn.ModuleList):\n    def __init__(self, modules=None):\n        super(ModuleListDial, self).__init__(modules)\n        self.cur_position = 0\n    def forward(self, x):\n        result = self[self.cur_position](x)\n        self.cur_position += 1\n        if self.cur_position >= len(self):\n            self.cur_position = 0\n        return result",
        "detail": "projects.mmdet3d_plugin.dd3d.layers.normalization",
        "documentation": {}
    },
    {
        "label": "LOG",
        "kind": 5,
        "importPath": "projects.mmdet3d_plugin.dd3d.layers.normalization",
        "description": "projects.mmdet3d_plugin.dd3d.layers.normalization",
        "peekOfCode": "LOG = logging.getLogger(__name__)\nclass Scale(nn.Module):\n    def __init__(self, init_value=1.0):\n        super(Scale, self).__init__()\n        self.scale = nn.Parameter(torch.FloatTensor([init_value]))\n    def forward(self, input):\n        return input * self.scale\nclass Offset(nn.Module):\n    def __init__(self, init_value=0.):\n        super(Offset, self).__init__()",
        "detail": "projects.mmdet3d_plugin.dd3d.layers.normalization",
        "documentation": {}
    },
    {
        "label": "smooth_l1_loss",
        "kind": 2,
        "importPath": "projects.mmdet3d_plugin.dd3d.layers.smooth_l1_loss",
        "description": "projects.mmdet3d_plugin.dd3d.layers.smooth_l1_loss",
        "peekOfCode": "def smooth_l1_loss(input: torch.Tensor, target: torch.Tensor, beta: float, reduction: str = \"none\") -> torch.Tensor:\n    \"\"\"\n    Smooth L1 loss defined in the Fast R-CNN paper as:\n                  | 0.5 * x ** 2 / beta   if abs(x) < beta\n    smoothl1(x) = |\n                  | abs(x) - 0.5 * beta   otherwise,\n    where x = input - target.\n    Smooth L1 loss is related to Huber loss, which is defined as:\n                | 0.5 * x ** 2                  if abs(x) < beta\n     huber(x) = |",
        "detail": "projects.mmdet3d_plugin.dd3d.layers.smooth_l1_loss",
        "documentation": {}
    },
    {
        "label": "DD3D",
        "kind": 6,
        "importPath": "projects.mmdet3d_plugin.dd3d.modeling.core",
        "description": "projects.mmdet3d_plugin.dd3d.modeling.core",
        "peekOfCode": "class DD3D(nn.Module):\n    def __init__(self,\n                 num_classes,\n                 in_channels,\n                 strides,\n                 fcos2d_cfg=dict(),\n                 fcos2d_loss_cfg=dict(),\n                 fcos3d_cfg=dict(),\n                 fcos3d_loss_cfg=dict(),\n                 target_assign_cfg=dict(),",
        "detail": "projects.mmdet3d_plugin.dd3d.modeling.core",
        "documentation": {}
    },
    {
        "label": "DisentangledBox3DLoss",
        "kind": 6,
        "importPath": "projects.mmdet3d_plugin.dd3d.modeling.disentangled_box3d_loss",
        "description": "projects.mmdet3d_plugin.dd3d.modeling.disentangled_box3d_loss",
        "peekOfCode": "class DisentangledBox3DLoss(nn.Module):\n    def __init__(self, smooth_l1_loss_beta, max_loss_per_group):\n        super().__init__()\n        self.smooth_l1_loss_beta = smooth_l1_loss_beta\n        self.max_loss_per_group = max_loss_per_group\n    def forward(self, box3d_pred, box3d_targets, locations, weights=None):\n        box3d_pred = box3d_pred.to(torch.float32)\n        box3d_targets = box3d_targets.to(torch.float32)\n        target_corners = box3d_targets.corners\n        disentangled_losses = {}",
        "detail": "projects.mmdet3d_plugin.dd3d.modeling.disentangled_box3d_loss",
        "documentation": {}
    },
    {
        "label": "LOG",
        "kind": 5,
        "importPath": "projects.mmdet3d_plugin.dd3d.modeling.disentangled_box3d_loss",
        "description": "projects.mmdet3d_plugin.dd3d.modeling.disentangled_box3d_loss",
        "peekOfCode": "LOG = logging.getLogger(__name__)\nclass DisentangledBox3DLoss(nn.Module):\n    def __init__(self, smooth_l1_loss_beta, max_loss_per_group):\n        super().__init__()\n        self.smooth_l1_loss_beta = smooth_l1_loss_beta\n        self.max_loss_per_group = max_loss_per_group\n    def forward(self, box3d_pred, box3d_targets, locations, weights=None):\n        box3d_pred = box3d_pred.to(torch.float32)\n        box3d_targets = box3d_targets.to(torch.float32)\n        target_corners = box3d_targets.corners",
        "detail": "projects.mmdet3d_plugin.dd3d.modeling.disentangled_box3d_loss",
        "documentation": {}
    },
    {
        "label": "FCOS2DHead",
        "kind": 6,
        "importPath": "projects.mmdet3d_plugin.dd3d.modeling.fcos2d",
        "description": "projects.mmdet3d_plugin.dd3d.modeling.fcos2d",
        "peekOfCode": "class FCOS2DHead(nn.Module):\n    def __init__(self, \n                 num_classes, \n                 input_shape,\n                 num_cls_convs=4,\n                 num_box_convs=4,\n                 norm='BN',\n                 use_deformable=False,\n                 use_scale=True,\n                 box2d_scale_init_factor=1.0,",
        "detail": "projects.mmdet3d_plugin.dd3d.modeling.fcos2d",
        "documentation": {}
    },
    {
        "label": "FCOS2DLoss",
        "kind": 6,
        "importPath": "projects.mmdet3d_plugin.dd3d.modeling.fcos2d",
        "description": "projects.mmdet3d_plugin.dd3d.modeling.fcos2d",
        "peekOfCode": "class FCOS2DLoss(nn.Module):\n    def __init__(self,\n                 num_classes,\n                 focal_loss_alpha=0.25,\n                 focal_loss_gamma=2.0,\n                 loc_loss_type='giou',\n                 ):\n        super().__init__()\n        self.focal_loss_alpha = focal_loss_alpha\n        self.focal_loss_gamma = focal_loss_gamma",
        "detail": "projects.mmdet3d_plugin.dd3d.modeling.fcos2d",
        "documentation": {}
    },
    {
        "label": "FCOS2DInference",
        "kind": 6,
        "importPath": "projects.mmdet3d_plugin.dd3d.modeling.fcos2d",
        "description": "projects.mmdet3d_plugin.dd3d.modeling.fcos2d",
        "peekOfCode": "class FCOS2DInference():\n    def __init__(self, cfg):\n        self.thresh_with_ctr = cfg.DD3D.FCOS2D.INFERENCE.THRESH_WITH_CTR\n        self.pre_nms_thresh = cfg.DD3D.FCOS2D.INFERENCE.PRE_NMS_THRESH\n        self.pre_nms_topk = cfg.DD3D.FCOS2D.INFERENCE.PRE_NMS_TOPK\n        self.post_nms_topk = cfg.DD3D.FCOS2D.INFERENCE.POST_NMS_TOPK\n        self.nms_thresh = cfg.DD3D.FCOS2D.INFERENCE.NMS_THRESH\n        self.num_classes = cfg.DD3D.NUM_CLASSES\n    def __call__(self, logits, box2d_reg, centerness, locations, image_sizes):\n        pred_instances = []  # List[List[Instances]], shape = (L, B)",
        "detail": "projects.mmdet3d_plugin.dd3d.modeling.fcos2d",
        "documentation": {}
    },
    {
        "label": "compute_ctrness_targets",
        "kind": 2,
        "importPath": "projects.mmdet3d_plugin.dd3d.modeling.fcos2d",
        "description": "projects.mmdet3d_plugin.dd3d.modeling.fcos2d",
        "peekOfCode": "def compute_ctrness_targets(reg_targets):\n    if len(reg_targets) == 0:\n        return reg_targets.new_zeros(len(reg_targets))\n    left_right = reg_targets[:, [0, 2]]\n    top_bottom = reg_targets[:, [1, 3]]\n    ctrness = (left_right.min(dim=-1)[0] / left_right.max(dim=-1)[0]) * \\\n                 (top_bottom.min(dim=-1)[0] / top_bottom.max(dim=-1)[0])\n    return torch.sqrt(ctrness)\nclass FCOS2DHead(nn.Module):\n    def __init__(self, ",
        "detail": "projects.mmdet3d_plugin.dd3d.modeling.fcos2d",
        "documentation": {}
    },
    {
        "label": "INF",
        "kind": 5,
        "importPath": "projects.mmdet3d_plugin.dd3d.modeling.fcos2d",
        "description": "projects.mmdet3d_plugin.dd3d.modeling.fcos2d",
        "peekOfCode": "INF = 100000000\ndef compute_ctrness_targets(reg_targets):\n    if len(reg_targets) == 0:\n        return reg_targets.new_zeros(len(reg_targets))\n    left_right = reg_targets[:, [0, 2]]\n    top_bottom = reg_targets[:, [1, 3]]\n    ctrness = (left_right.min(dim=-1)[0] / left_right.max(dim=-1)[0]) * \\\n                 (top_bottom.min(dim=-1)[0] / top_bottom.max(dim=-1)[0])\n    return torch.sqrt(ctrness)\nclass FCOS2DHead(nn.Module):",
        "detail": "projects.mmdet3d_plugin.dd3d.modeling.fcos2d",
        "documentation": {}
    },
    {
        "label": "FCOS3DHead",
        "kind": 6,
        "importPath": "projects.mmdet3d_plugin.dd3d.modeling.fcos3d",
        "description": "projects.mmdet3d_plugin.dd3d.modeling.fcos3d",
        "peekOfCode": "class FCOS3DHead(nn.Module):\n    def __init__(self, \n                 num_classes,\n                 input_shape,\n                 num_convs=4,\n                 norm='BN',\n                 use_scale=True,\n                 depth_scale_init_factor=0.3,\n                 proj_ctr_scale_init_factor=1.0,\n                 use_per_level_predictors=False,",
        "detail": "projects.mmdet3d_plugin.dd3d.modeling.fcos3d",
        "documentation": {}
    },
    {
        "label": "FCOS3DLoss",
        "kind": 6,
        "importPath": "projects.mmdet3d_plugin.dd3d.modeling.fcos3d",
        "description": "projects.mmdet3d_plugin.dd3d.modeling.fcos3d",
        "peekOfCode": "class FCOS3DLoss(nn.Module):\n    def __init__(self, \n                 num_classes,\n                 min_depth=0.1,\n                 max_depth=80.0,\n                 box3d_loss_weight=2.0,\n                 conf3d_loss_weight=1.0,\n                 conf_3d_temperature=1.0,\n                 smooth_l1_loss_beta=0.05, \n                 max_loss_per_group=20,",
        "detail": "projects.mmdet3d_plugin.dd3d.modeling.fcos3d",
        "documentation": {}
    },
    {
        "label": "FCOS3DInference",
        "kind": 6,
        "importPath": "projects.mmdet3d_plugin.dd3d.modeling.fcos3d",
        "description": "projects.mmdet3d_plugin.dd3d.modeling.fcos3d",
        "peekOfCode": "class FCOS3DInference():\n    def __init__(self, cfg):\n        self.canon_box_sizes = cfg.DD3D.FCOS3D.CANONICAL_BOX3D_SIZES\n        self.min_depth = cfg.DD3D.FCOS3D.MIN_DEPTH\n        self.max_depth = cfg.DD3D.FCOS3D.MAX_DEPTH\n        self.predict_allocentric_rot = cfg.DD3D.FCOS3D.PREDICT_ALLOCENTRIC_ROT\n        self.scale_depth_by_focal_lengths = cfg.DD3D.FCOS3D.SCALE_DEPTH_BY_FOCAL_LENGTHS\n        self.scale_depth_by_focal_lengths_factor = cfg.DD3D.FCOS3D.SCALE_DEPTH_BY_FOCAL_LENGTHS_FACTOR\n        self.predict_distance = cfg.DD3D.FCOS3D.PREDICT_DISTANCE\n        self.num_classes = cfg.DD3D.NUM_CLASSES",
        "detail": "projects.mmdet3d_plugin.dd3d.modeling.fcos3d",
        "documentation": {}
    },
    {
        "label": "predictions_to_boxes3d",
        "kind": 2,
        "importPath": "projects.mmdet3d_plugin.dd3d.modeling.fcos3d",
        "description": "projects.mmdet3d_plugin.dd3d.modeling.fcos3d",
        "peekOfCode": "def predictions_to_boxes3d(\n    quat,\n    proj_ctr,\n    depth,\n    size,\n    locations,\n    inv_intrinsics,\n    canon_box_sizes,\n    min_depth,\n    max_depth,",
        "detail": "projects.mmdet3d_plugin.dd3d.modeling.fcos3d",
        "documentation": {}
    },
    {
        "label": "EPS",
        "kind": 5,
        "importPath": "projects.mmdet3d_plugin.dd3d.modeling.fcos3d",
        "description": "projects.mmdet3d_plugin.dd3d.modeling.fcos3d",
        "peekOfCode": "EPS = 1e-7\ndef predictions_to_boxes3d(\n    quat,\n    proj_ctr,\n    depth,\n    size,\n    locations,\n    inv_intrinsics,\n    canon_box_sizes,\n    min_depth,",
        "detail": "projects.mmdet3d_plugin.dd3d.modeling.fcos3d",
        "documentation": {}
    },
    {
        "label": "NuscenesDD3DTargetPreparer",
        "kind": 6,
        "importPath": "projects.mmdet3d_plugin.dd3d.modeling.nuscenes_dd3d",
        "description": "projects.mmdet3d_plugin.dd3d.modeling.nuscenes_dd3d",
        "peekOfCode": "class NuscenesDD3DTargetPreparer(DD3DTargetPreparer):\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        assert self.dd3d_enabled, f\"{type(self).__name__} requires dd3d_enabled = True\"\n    def __call__(self, locations, gt_instances, feature_shapes):\n        num_loc_list = [len(loc) for loc in locations]\n        # compute locations to size ranges\n        loc_to_size_range = []\n        for l, loc_per_level in enumerate(locations):\n            loc_to_size_range_per_level = loc_per_level.new_tensor(self.sizes_of_interest[l])",
        "detail": "projects.mmdet3d_plugin.dd3d.modeling.nuscenes_dd3d",
        "documentation": {}
    },
    {
        "label": "NuscenesLoss",
        "kind": 6,
        "importPath": "projects.mmdet3d_plugin.dd3d.modeling.nuscenes_dd3d",
        "description": "projects.mmdet3d_plugin.dd3d.modeling.nuscenes_dd3d",
        "peekOfCode": "class NuscenesLoss(nn.Module):\n    def __init__(self, attr_loss_weight=0.2, speed_loss_weight=0.2):\n        super().__init__()\n        self.attr_loss_weight = attr_loss_weight\n        self.speed_loss_weight = speed_loss_weight\n    @force_fp32(apply_to=('attr_logits', 'speeds'))\n    def forward(self, attr_logits, speeds, fcos2d_info, targets):\n        # Flatten predictions\n        attr_logits = cat([x.permute(0, 2, 3, 1).reshape(-1, MAX_NUM_ATTRIBUTES) for x in attr_logits])\n        speeds = cat([x.permute(0, 2, 3, 1).reshape(-1) for x in speeds])",
        "detail": "projects.mmdet3d_plugin.dd3d.modeling.nuscenes_dd3d",
        "documentation": {}
    },
    {
        "label": "NuscenesInference",
        "kind": 6,
        "importPath": "projects.mmdet3d_plugin.dd3d.modeling.nuscenes_dd3d",
        "description": "projects.mmdet3d_plugin.dd3d.modeling.nuscenes_dd3d",
        "peekOfCode": "class NuscenesInference():\n    def __init__(self, cfg):\n        pass\n    def __call__(self, attr_logits, speeds, pred_instances, fcos2d_info):\n        \"\"\"Add 'pred_attribute', 'pred_speed' to Instances in 'pred_instances'.\"\"\"\n        N = attr_logits[0].shape[0]\n        for lvl, (attr_logits_lvl, speed_lvl, info_lvl, instances_lvl) in \\\n            enumerate(zip(attr_logits, speeds, fcos2d_info, pred_instances)):\n            attr_logits_lvl = attr_logits_lvl.permute(0, 2, 3, 1).reshape(N, -1, MAX_NUM_ATTRIBUTES)\n            speed_lvl = speed_lvl.permute(0, 2, 3, 1).reshape(N, -1)",
        "detail": "projects.mmdet3d_plugin.dd3d.modeling.nuscenes_dd3d",
        "documentation": {}
    },
    {
        "label": "NuscenesDD3D",
        "kind": 6,
        "importPath": "projects.mmdet3d_plugin.dd3d.modeling.nuscenes_dd3d",
        "description": "projects.mmdet3d_plugin.dd3d.modeling.nuscenes_dd3d",
        "peekOfCode": "class NuscenesDD3D(DD3D):\n    def __init__(self, \n                 num_classes,\n                 in_channels,\n                 strides,\n                 fcos2d_cfg=dict(),\n                 fcos2d_loss_cfg=dict(),\n                 fcos3d_cfg=dict(),\n                 fcos3d_loss_cfg=dict(),\n                 target_assign_cfg=dict(),",
        "detail": "projects.mmdet3d_plugin.dd3d.modeling.nuscenes_dd3d",
        "documentation": {}
    },
    {
        "label": "INF",
        "kind": 5,
        "importPath": "projects.mmdet3d_plugin.dd3d.modeling.nuscenes_dd3d",
        "description": "projects.mmdet3d_plugin.dd3d.modeling.nuscenes_dd3d",
        "peekOfCode": "INF = 100000000.\nclass NuscenesDD3DTargetPreparer(DD3DTargetPreparer):\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        assert self.dd3d_enabled, f\"{type(self).__name__} requires dd3d_enabled = True\"\n    def __call__(self, locations, gt_instances, feature_shapes):\n        num_loc_list = [len(loc) for loc in locations]\n        # compute locations to size ranges\n        loc_to_size_range = []\n        for l, loc_per_level in enumerate(locations):",
        "detail": "projects.mmdet3d_plugin.dd3d.modeling.nuscenes_dd3d",
        "documentation": {}
    },
    {
        "label": "DD3DTargetPreparer",
        "kind": 6,
        "importPath": "projects.mmdet3d_plugin.dd3d.modeling.prepare_targets",
        "description": "projects.mmdet3d_plugin.dd3d.modeling.prepare_targets",
        "peekOfCode": "class DD3DTargetPreparer():\n    def __init__(self, \n                 num_classes, \n                 input_shape,\n                 box3d_on=True,\n                 center_sample=True,\n                 pos_radius=1.5,\n                 sizes_of_interest=None):\n        self.num_classes = num_classes\n        self.center_sample = center_sample",
        "detail": "projects.mmdet3d_plugin.dd3d.modeling.prepare_targets",
        "documentation": {}
    },
    {
        "label": "INF",
        "kind": 5,
        "importPath": "projects.mmdet3d_plugin.dd3d.modeling.prepare_targets",
        "description": "projects.mmdet3d_plugin.dd3d.modeling.prepare_targets",
        "peekOfCode": "INF = 100000000.\nclass DD3DTargetPreparer():\n    def __init__(self, \n                 num_classes, \n                 input_shape,\n                 box3d_on=True,\n                 center_sample=True,\n                 pos_radius=1.5,\n                 sizes_of_interest=None):\n        self.num_classes = num_classes",
        "detail": "projects.mmdet3d_plugin.dd3d.modeling.prepare_targets",
        "documentation": {}
    },
    {
        "label": "GenericBoxes3D",
        "kind": 6,
        "importPath": "projects.mmdet3d_plugin.dd3d.structures.boxes3d",
        "description": "projects.mmdet3d_plugin.dd3d.structures.boxes3d",
        "peekOfCode": "class GenericBoxes3D():\n    def __init__(self, quat, tvec, size):\n        self.quat = _to_tensor(quat, dim=4)\n        self._tvec = _to_tensor(tvec, dim=3)\n        self.size = _to_tensor(size, dim=3)\n    @property\n    def tvec(self):\n        return self._tvec\n    @property\n    @amp.autocast(enabled=False)",
        "detail": "projects.mmdet3d_plugin.dd3d.structures.boxes3d",
        "documentation": {}
    },
    {
        "label": "Boxes3D",
        "kind": 6,
        "importPath": "projects.mmdet3d_plugin.dd3d.structures.boxes3d",
        "description": "projects.mmdet3d_plugin.dd3d.structures.boxes3d",
        "peekOfCode": "class Boxes3D(GenericBoxes3D):\n    \"\"\"Vision-based 3D box container.\n    The tvec is computed from projected center, depth, and intrinsics.\n    \"\"\"\n    def __init__(self, quat, proj_ctr, depth, size, inv_intrinsics):\n        self.quat = quat\n        self.proj_ctr = proj_ctr\n        self.depth = depth\n        self.size = size\n        self.inv_intrinsics = inv_intrinsics",
        "detail": "projects.mmdet3d_plugin.dd3d.structures.boxes3d",
        "documentation": {}
    },
    {
        "label": "quaternion_to_matrix",
        "kind": 2,
        "importPath": "projects.mmdet3d_plugin.dd3d.structures.boxes3d",
        "description": "projects.mmdet3d_plugin.dd3d.structures.boxes3d",
        "peekOfCode": "def quaternion_to_matrix(quaternions: torch.Tensor) -> torch.Tensor:\n    \"\"\"\n    Convert rotations given as quaternions to rotation matrices.\n    Args:\n        quaternions: quaternions with real part first,\n            as tensor of shape (..., 4).\n    Returns:\n        Rotation matrices as tensor of shape (..., 3, 3).\n    \"\"\"\n    r, i, j, k = torch.unbind(quaternions, -1)",
        "detail": "projects.mmdet3d_plugin.dd3d.structures.boxes3d",
        "documentation": {}
    },
    {
        "label": "BOX3D_CORNER_MAPPING",
        "kind": 5,
        "importPath": "projects.mmdet3d_plugin.dd3d.structures.boxes3d",
        "description": "projects.mmdet3d_plugin.dd3d.structures.boxes3d",
        "peekOfCode": "BOX3D_CORNER_MAPPING = [\n    [1, 1, 1, 1, -1, -1, -1, -1],\n    [1, -1, -1, 1, 1, -1, -1, 1],\n    [1, 1, -1, -1, 1, 1, -1, -1]\n]\n# yapf: enable\ndef quaternion_to_matrix(quaternions: torch.Tensor) -> torch.Tensor:\n    \"\"\"\n    Convert rotations given as quaternions to rotation matrices.\n    Args:",
        "detail": "projects.mmdet3d_plugin.dd3d.structures.boxes3d",
        "documentation": {}
    },
    {
        "label": "ImageList",
        "kind": 6,
        "importPath": "projects.mmdet3d_plugin.dd3d.structures.image_list",
        "description": "projects.mmdet3d_plugin.dd3d.structures.image_list",
        "peekOfCode": "class ImageList(object):\n    \"\"\"\n    Adapted from detectron2:\n        https://github.com/facebookresearch/detectron2/blob/master/detectron2/structures/image_list.py)\n    Key differences:\n        - add optional intrinsics\n        - add optional image path (useful for debugging)\n    ==================================================================================================================\n    Structure that holds a list of images (of possibly\n    varying sizes) as a single tensor.",
        "detail": "projects.mmdet3d_plugin.dd3d.structures.image_list",
        "documentation": {}
    },
    {
        "label": "Pose",
        "kind": 6,
        "importPath": "projects.mmdet3d_plugin.dd3d.structures.pose",
        "description": "projects.mmdet3d_plugin.dd3d.structures.pose",
        "peekOfCode": "class Pose:\n    \"\"\"SE(3) rigid transform class that allows compounding of 6-DOF poses\n    and provides common transformations that are commonly seen in geometric problems.\n    \"\"\"\n    def __init__(self, wxyz=np.float32([1., 0., 0., 0.]), tvec=np.float32([0., 0., 0.])):\n        \"\"\"Initialize a Pose with Quaternion and 3D Position\n        Parameters\n        ----------\n        wxyz: np.float32 or Quaternion (default: np.float32([1,0,0,0]))\n            Quaternion/Rotation (wxyz)",
        "detail": "projects.mmdet3d_plugin.dd3d.structures.pose",
        "documentation": {}
    },
    {
        "label": "Transform3d",
        "kind": 6,
        "importPath": "projects.mmdet3d_plugin.dd3d.structures.transform3d",
        "description": "projects.mmdet3d_plugin.dd3d.structures.transform3d",
        "peekOfCode": "class Transform3d:\n    \"\"\"\n    A Transform3d object encapsulates a batch of N 3D transformations, and knows\n    how to transform points and normal vectors. Suppose that t is a Transform3d;\n    then we can do the following:\n    .. code-block:: python\n        N = len(t)\n        points = torch.randn(N, P, 3)\n        normals = torch.randn(N, P, 3)\n        points_transformed = t.transform_points(points)    # => (N, P, 3)",
        "detail": "projects.mmdet3d_plugin.dd3d.structures.transform3d",
        "documentation": {}
    },
    {
        "label": "Translate",
        "kind": 6,
        "importPath": "projects.mmdet3d_plugin.dd3d.structures.transform3d",
        "description": "projects.mmdet3d_plugin.dd3d.structures.transform3d",
        "peekOfCode": "class Translate(Transform3d):\n    def __init__(\n        self,\n        x,\n        y=None,\n        z=None,\n        dtype: torch.dtype = torch.float32,\n        device: Optional[Device] = None,\n    ) -> None:\n        \"\"\"",
        "detail": "projects.mmdet3d_plugin.dd3d.structures.transform3d",
        "documentation": {}
    },
    {
        "label": "Scale",
        "kind": 6,
        "importPath": "projects.mmdet3d_plugin.dd3d.structures.transform3d",
        "description": "projects.mmdet3d_plugin.dd3d.structures.transform3d",
        "peekOfCode": "class Scale(Transform3d):\n    def __init__(\n        self,\n        x,\n        y=None,\n        z=None,\n        dtype: torch.dtype = torch.float32,\n        device: Optional[Device] = None,\n    ) -> None:\n        \"\"\"",
        "detail": "projects.mmdet3d_plugin.dd3d.structures.transform3d",
        "documentation": {}
    },
    {
        "label": "Rotate",
        "kind": 6,
        "importPath": "projects.mmdet3d_plugin.dd3d.structures.transform3d",
        "description": "projects.mmdet3d_plugin.dd3d.structures.transform3d",
        "peekOfCode": "class Rotate(Transform3d):\n    def __init__(\n        self,\n        R: torch.Tensor,\n        dtype: torch.dtype = torch.float32,\n        device: Optional[Device] = None,\n        orthogonal_tol: float = 1e-5,\n    ) -> None:\n        \"\"\"\n        Create a new Transform3d representing 3D rotation using a rotation",
        "detail": "projects.mmdet3d_plugin.dd3d.structures.transform3d",
        "documentation": {}
    },
    {
        "label": "RotateAxisAngle",
        "kind": 6,
        "importPath": "projects.mmdet3d_plugin.dd3d.structures.transform3d",
        "description": "projects.mmdet3d_plugin.dd3d.structures.transform3d",
        "peekOfCode": "class RotateAxisAngle(Rotate):\n    def __init__(\n        self,\n        angle,\n        axis: str = \"X\",\n        degrees: bool = True,\n        dtype: torch.dtype = torch.float32,\n        device: Optional[Device] = None,\n    ) -> None:\n        \"\"\"",
        "detail": "projects.mmdet3d_plugin.dd3d.structures.transform3d",
        "documentation": {}
    },
    {
        "label": "make_device",
        "kind": 2,
        "importPath": "projects.mmdet3d_plugin.dd3d.structures.transform3d",
        "description": "projects.mmdet3d_plugin.dd3d.structures.transform3d",
        "peekOfCode": "def make_device(device: Device) -> torch.device:\n    \"\"\"\n    Makes an actual torch.device object from the device specified as\n    either a string or torch.device object. If the device is `cuda` without\n    a specific index, the index of the current device is assigned.\n    Args:\n        device: Device (as str or torch.device)\n    Returns:\n        A matching torch.device object\n    \"\"\"",
        "detail": "projects.mmdet3d_plugin.dd3d.structures.transform3d",
        "documentation": {}
    },
    {
        "label": "get_device",
        "kind": 2,
        "importPath": "projects.mmdet3d_plugin.dd3d.structures.transform3d",
        "description": "projects.mmdet3d_plugin.dd3d.structures.transform3d",
        "peekOfCode": "def get_device(x, device: Optional[Device] = None) -> torch.device:\n    \"\"\"\n    Gets the device of the specified variable x if it is a tensor, or\n    falls back to a default CPU device otherwise. Allows overriding by\n    providing an explicit device.\n    Args:\n        x: a torch.Tensor to get the device from or another type\n        device: Device (as str or torch.device) to fall back to\n    Returns:\n        A matching torch.device object",
        "detail": "projects.mmdet3d_plugin.dd3d.structures.transform3d",
        "documentation": {}
    },
    {
        "label": "Device",
        "kind": 5,
        "importPath": "projects.mmdet3d_plugin.dd3d.structures.transform3d",
        "description": "projects.mmdet3d_plugin.dd3d.structures.transform3d",
        "peekOfCode": "Device = Union[str, torch.device]\ndef make_device(device: Device) -> torch.device:\n    \"\"\"\n    Makes an actual torch.device object from the device specified as\n    either a string or torch.device object. If the device is `cuda` without\n    a specific index, the index of the current device is assigned.\n    Args:\n        device: Device (as str or torch.device)\n    Returns:\n        A matching torch.device object",
        "detail": "projects.mmdet3d_plugin.dd3d.structures.transform3d",
        "documentation": {}
    },
    {
        "label": "is_distributed",
        "kind": 2,
        "importPath": "projects.mmdet3d_plugin.dd3d.utils.comm",
        "description": "projects.mmdet3d_plugin.dd3d.utils.comm",
        "peekOfCode": "def is_distributed():\n    return d2_comm.get_world_size() > 1\ndef broadcast_from_master(fn):\n    \"\"\"If distributed, only the master executes the function and broadcast the results to other workers.\n    Usage:\n    @broadcast_from_master\n    def foo(a, b): ...\n    \"\"\"\n    @wraps(fn)\n    def wrapper(*args, **kwargs):  # pylint: disable=unused-argument",
        "detail": "projects.mmdet3d_plugin.dd3d.utils.comm",
        "documentation": {}
    },
    {
        "label": "broadcast_from_master",
        "kind": 2,
        "importPath": "projects.mmdet3d_plugin.dd3d.utils.comm",
        "description": "projects.mmdet3d_plugin.dd3d.utils.comm",
        "peekOfCode": "def broadcast_from_master(fn):\n    \"\"\"If distributed, only the master executes the function and broadcast the results to other workers.\n    Usage:\n    @broadcast_from_master\n    def foo(a, b): ...\n    \"\"\"\n    @wraps(fn)\n    def wrapper(*args, **kwargs):  # pylint: disable=unused-argument\n        global _NESTED_BROADCAST_FROM_MASTER\n        if not is_distributed():",
        "detail": "projects.mmdet3d_plugin.dd3d.utils.comm",
        "documentation": {}
    },
    {
        "label": "master_only",
        "kind": 2,
        "importPath": "projects.mmdet3d_plugin.dd3d.utils.comm",
        "description": "projects.mmdet3d_plugin.dd3d.utils.comm",
        "peekOfCode": "def master_only(fn):\n    \"\"\"If distributed, only the master executes the function.\n    Usage:\n    @master_only\n    def foo(a, b): ...\n    \"\"\"\n    @wraps(fn)\n    def wrapped_fn(*args, **kwargs):\n        if d2_comm.is_main_process():\n            ret = fn(*args, **kwargs)",
        "detail": "projects.mmdet3d_plugin.dd3d.utils.comm",
        "documentation": {}
    },
    {
        "label": "gather_dict",
        "kind": 2,
        "importPath": "projects.mmdet3d_plugin.dd3d.utils.comm",
        "description": "projects.mmdet3d_plugin.dd3d.utils.comm",
        "peekOfCode": "def gather_dict(dikt):\n    \"\"\"Gather python dictionaries from all workers to the rank=0 worker.\n    Assumption: the keys of `dikt` are disjoint across all workers.\n    If rank = 0, then returned aggregated dict.\n    If rank > 0, then return `None`.\n    \"\"\"\n    dict_lst = d2_comm.gather(dikt, dst=0)\n    if d2_comm.is_main_process():\n        gathered_dict = {}\n        for dic in dict_lst:",
        "detail": "projects.mmdet3d_plugin.dd3d.utils.comm",
        "documentation": {}
    },
    {
        "label": "reduce_sum",
        "kind": 2,
        "importPath": "projects.mmdet3d_plugin.dd3d.utils.comm",
        "description": "projects.mmdet3d_plugin.dd3d.utils.comm",
        "peekOfCode": "def reduce_sum(tensor):\n    \"\"\"\n    Adapted from AdelaiDet:\n        https://github.com/aim-uofa/AdelaiDet/blob/master/adet/utils/comm.py\n    \"\"\"\n    if not is_distributed():\n        return tensor\n    tensor = tensor.clone()\n    dist.all_reduce(tensor, op=dist.ReduceOp.SUM)\n    return tensor",
        "detail": "projects.mmdet3d_plugin.dd3d.utils.comm",
        "documentation": {}
    },
    {
        "label": "LOG",
        "kind": 5,
        "importPath": "projects.mmdet3d_plugin.dd3d.utils.comm",
        "description": "projects.mmdet3d_plugin.dd3d.utils.comm",
        "peekOfCode": "LOG = logging.getLogger(__name__)\n_NESTED_BROADCAST_FROM_MASTER = False\ndef is_distributed():\n    return d2_comm.get_world_size() > 1\ndef broadcast_from_master(fn):\n    \"\"\"If distributed, only the master executes the function and broadcast the results to other workers.\n    Usage:\n    @broadcast_from_master\n    def foo(a, b): ...\n    \"\"\"",
        "detail": "projects.mmdet3d_plugin.dd3d.utils.comm",
        "documentation": {}
    },
    {
        "label": "_NESTED_BROADCAST_FROM_MASTER",
        "kind": 5,
        "importPath": "projects.mmdet3d_plugin.dd3d.utils.comm",
        "description": "projects.mmdet3d_plugin.dd3d.utils.comm",
        "peekOfCode": "_NESTED_BROADCAST_FROM_MASTER = False\ndef is_distributed():\n    return d2_comm.get_world_size() > 1\ndef broadcast_from_master(fn):\n    \"\"\"If distributed, only the master executes the function and broadcast the results to other workers.\n    Usage:\n    @broadcast_from_master\n    def foo(a, b): ...\n    \"\"\"\n    @wraps(fn)",
        "detail": "projects.mmdet3d_plugin.dd3d.utils.comm",
        "documentation": {}
    },
    {
        "label": "matrix_to_quaternion",
        "kind": 2,
        "importPath": "projects.mmdet3d_plugin.dd3d.utils.geometry",
        "description": "projects.mmdet3d_plugin.dd3d.utils.geometry",
        "peekOfCode": "def matrix_to_quaternion(matrix: torch.Tensor) -> torch.Tensor:\n    \"\"\"\n    Convert rotations given as rotation matrices to quaternions.\n    Args:\n        matrix: Rotation matrices as tensor of shape (..., 3, 3).\n    Returns:\n        quaternions with real part first, as tensor of shape (..., 4).\n    \"\"\"\n    if matrix.size(-1) != 3 or matrix.size(-2) != 3:\n        raise ValueError(f\"Invalid rotation matrix shape {matrix.shape}.\")",
        "detail": "projects.mmdet3d_plugin.dd3d.utils.geometry",
        "documentation": {}
    },
    {
        "label": "quaternion_to_matrix",
        "kind": 2,
        "importPath": "projects.mmdet3d_plugin.dd3d.utils.geometry",
        "description": "projects.mmdet3d_plugin.dd3d.utils.geometry",
        "peekOfCode": "def quaternion_to_matrix(quaternions: torch.Tensor) -> torch.Tensor:\n    \"\"\"\n    Convert rotations given as quaternions to rotation matrices.\n    Args:\n        quaternions: quaternions with real part first,\n            as tensor of shape (..., 4).\n    Returns:\n        Rotation matrices as tensor of shape (..., 3, 3).\n    \"\"\"\n    r, i, j, k = torch.unbind(quaternions, -1)",
        "detail": "projects.mmdet3d_plugin.dd3d.utils.geometry",
        "documentation": {}
    },
    {
        "label": "allocentric_to_egocentric",
        "kind": 2,
        "importPath": "projects.mmdet3d_plugin.dd3d.utils.geometry",
        "description": "projects.mmdet3d_plugin.dd3d.utils.geometry",
        "peekOfCode": "def allocentric_to_egocentric(quat, proj_ctr, inv_intrinsics):\n    \"\"\"\n    Parameters\n    ----------\n    quat: Tensor\n        (N, 4). Batch of (allocentric) quaternions.\n    proj_ctr: Tensor\n        (N, 2). Projected centers. xy coordninates.\n    inv_intrinsics: [type]\n        (N, 3, 3). Inverted intrinsics.",
        "detail": "projects.mmdet3d_plugin.dd3d.utils.geometry",
        "documentation": {}
    },
    {
        "label": "homogenize_points",
        "kind": 2,
        "importPath": "projects.mmdet3d_plugin.dd3d.utils.geometry",
        "description": "projects.mmdet3d_plugin.dd3d.utils.geometry",
        "peekOfCode": "def homogenize_points(xy):\n    \"\"\"\n    Parameters\n    ----------\n    xy: Tensor\n        xy coordinates. shape=(N, ..., 2)\n        E.g., (N, 2) or (N, K, 2) or (N, H, W, 2)\n    Returns\n    -------\n    Tensor:",
        "detail": "projects.mmdet3d_plugin.dd3d.utils.geometry",
        "documentation": {}
    },
    {
        "label": "project_points3d",
        "kind": 2,
        "importPath": "projects.mmdet3d_plugin.dd3d.utils.geometry",
        "description": "projects.mmdet3d_plugin.dd3d.utils.geometry",
        "peekOfCode": "def project_points3d(Xw, K):\n    _, C = Xw.shape\n    assert C == 3\n    uv, _ = cv2.projectPoints(\n        Xw, np.zeros((3, 1), dtype=np.float32), np.zeros(3, dtype=np.float32), K, np.zeros(5, dtype=np.float32)\n    )\n    return uv.reshape(-1, 2)\ndef unproject_points2d(points2d, inv_K, scale=1.0):\n    \"\"\"\n    Parameters",
        "detail": "projects.mmdet3d_plugin.dd3d.utils.geometry",
        "documentation": {}
    },
    {
        "label": "unproject_points2d",
        "kind": 2,
        "importPath": "projects.mmdet3d_plugin.dd3d.utils.geometry",
        "description": "projects.mmdet3d_plugin.dd3d.utils.geometry",
        "peekOfCode": "def unproject_points2d(points2d, inv_K, scale=1.0):\n    \"\"\"\n    Parameters\n    ----------\n    points2d: Tensor\n        xy coordinates. shape=(N, ..., 2)\n        E.g., (N, 2) or (N, K, 2) or (N, H, W, 2)\n    inv_K: Tensor\n        Inverted intrinsics; shape=(N, 3, 3)\n    scale: float, default: 1.0",
        "detail": "projects.mmdet3d_plugin.dd3d.utils.geometry",
        "documentation": {}
    },
    {
        "label": "LOG",
        "kind": 5,
        "importPath": "projects.mmdet3d_plugin.dd3d.utils.geometry",
        "description": "projects.mmdet3d_plugin.dd3d.utils.geometry",
        "peekOfCode": "LOG = logging.getLogger(__name__)\nPI = 3.14159265358979323846\nEPS = 1e-7\ndef _sqrt_positive_part(x: torch.Tensor) -> torch.Tensor:\n    \"\"\"\n    Returns torch.sqrt(torch.max(0, x))\n    but with a zero subgradient where x is 0.\n    \"\"\"\n    ret = torch.zeros_like(x)\n    positive_mask = x > 0",
        "detail": "projects.mmdet3d_plugin.dd3d.utils.geometry",
        "documentation": {}
    },
    {
        "label": "PI",
        "kind": 5,
        "importPath": "projects.mmdet3d_plugin.dd3d.utils.geometry",
        "description": "projects.mmdet3d_plugin.dd3d.utils.geometry",
        "peekOfCode": "PI = 3.14159265358979323846\nEPS = 1e-7\ndef _sqrt_positive_part(x: torch.Tensor) -> torch.Tensor:\n    \"\"\"\n    Returns torch.sqrt(torch.max(0, x))\n    but with a zero subgradient where x is 0.\n    \"\"\"\n    ret = torch.zeros_like(x)\n    positive_mask = x > 0\n    ret[positive_mask] = torch.sqrt(x[positive_mask])",
        "detail": "projects.mmdet3d_plugin.dd3d.utils.geometry",
        "documentation": {}
    },
    {
        "label": "EPS",
        "kind": 5,
        "importPath": "projects.mmdet3d_plugin.dd3d.utils.geometry",
        "description": "projects.mmdet3d_plugin.dd3d.utils.geometry",
        "peekOfCode": "EPS = 1e-7\ndef _sqrt_positive_part(x: torch.Tensor) -> torch.Tensor:\n    \"\"\"\n    Returns torch.sqrt(torch.max(0, x))\n    but with a zero subgradient where x is 0.\n    \"\"\"\n    ret = torch.zeros_like(x)\n    positive_mask = x > 0\n    ret[positive_mask] = torch.sqrt(x[positive_mask])\n    return ret",
        "detail": "projects.mmdet3d_plugin.dd3d.utils.geometry",
        "documentation": {}
    },
    {
        "label": "Task",
        "kind": 6,
        "importPath": "projects.mmdet3d_plugin.dd3d.utils.tasks",
        "description": "projects.mmdet3d_plugin.dd3d.utils.tasks",
        "peekOfCode": "class Task():\n    def __init__(self, name, is_detection_task, is_dense_prediction_task):\n        self.name = name\n        self.is_detection_task = is_detection_task\n        self.is_dense_prediction_task = is_dense_prediction_task\n# yapf: disable\nTASKS = [\n    Task(\n        name=\"box2d\",\n        is_detection_task=True,",
        "detail": "projects.mmdet3d_plugin.dd3d.utils.tasks",
        "documentation": {}
    },
    {
        "label": "TaskManager",
        "kind": 6,
        "importPath": "projects.mmdet3d_plugin.dd3d.utils.tasks",
        "description": "projects.mmdet3d_plugin.dd3d.utils.tasks",
        "peekOfCode": "class TaskManager():\n    #@configurable\n    def __init__(self, box2d_on=False, box3d_on=False, depth_on=False):\n        \"\"\"\n        configurable is experimental.\n        \"\"\"\n        self._box2d_on = self._mask2d_on = self._box3d_on = self._semseg2d_on = self._depth_on = False\n        tasks = []\n        if box2d_on:\n            tasks.append(NAME_TO_TASK['box2d'])",
        "detail": "projects.mmdet3d_plugin.dd3d.utils.tasks",
        "documentation": {}
    },
    {
        "label": "TASKS",
        "kind": 5,
        "importPath": "projects.mmdet3d_plugin.dd3d.utils.tasks",
        "description": "projects.mmdet3d_plugin.dd3d.utils.tasks",
        "peekOfCode": "TASKS = [\n    Task(\n        name=\"box2d\",\n        is_detection_task=True,\n        is_dense_prediction_task=False,\n    ),\n    Task(\n        name=\"box3d\",\n        is_detection_task=True,\n        is_dense_prediction_task=False,",
        "detail": "projects.mmdet3d_plugin.dd3d.utils.tasks",
        "documentation": {}
    },
    {
        "label": "NAME_TO_TASK",
        "kind": 5,
        "importPath": "projects.mmdet3d_plugin.dd3d.utils.tasks",
        "description": "projects.mmdet3d_plugin.dd3d.utils.tasks",
        "peekOfCode": "NAME_TO_TASK = OrderedDict([(task.name, task) for task in TASKS])\nclass TaskManager():\n    #@configurable\n    def __init__(self, box2d_on=False, box3d_on=False, depth_on=False):\n        \"\"\"\n        configurable is experimental.\n        \"\"\"\n        self._box2d_on = self._mask2d_on = self._box3d_on = self._semseg2d_on = self._depth_on = False\n        tasks = []\n        if box2d_on:",
        "detail": "projects.mmdet3d_plugin.dd3d.utils.tasks",
        "documentation": {}
    },
    {
        "label": "compute_features_locations",
        "kind": 2,
        "importPath": "projects.mmdet3d_plugin.dd3d.utils.tensor2d",
        "description": "projects.mmdet3d_plugin.dd3d.utils.tensor2d",
        "peekOfCode": "def compute_features_locations(h, w, stride, dtype=torch.float32, device='cpu', offset=\"none\"):\n    \"\"\"Adapted from AdelaiDet:\n        https://github.com/aim-uofa/AdelaiDet/blob/master/adet/utils/comm.py\n    Key differnece: offset is configurable.\n    \"\"\"\n    shifts_x = torch.arange(0, w * stride, step=stride, dtype=dtype, device=device)\n    shifts_y = torch.arange(0, h * stride, step=stride, dtype=dtype, device=device)\n    shift_y, shift_x = torch.meshgrid(shifts_y, shifts_x)\n    shift_x = shift_x.reshape(-1)\n    shift_y = shift_y.reshape(-1)",
        "detail": "projects.mmdet3d_plugin.dd3d.utils.tensor2d",
        "documentation": {}
    },
    {
        "label": "aligned_bilinear",
        "kind": 2,
        "importPath": "projects.mmdet3d_plugin.dd3d.utils.tensor2d",
        "description": "projects.mmdet3d_plugin.dd3d.utils.tensor2d",
        "peekOfCode": "def aligned_bilinear(tensor, factor, offset=\"none\"):\n    \"\"\"Adapted from AdelaiDet:\n        https://github.com/aim-uofa/AdelaiDet/blob/master/adet/utils/comm.py\n    \"\"\"\n    assert tensor.dim() == 4\n    assert factor >= 1\n    assert int(factor) == factor\n    if factor == 1:\n        return tensor\n    h, w = tensor.size()[2:]",
        "detail": "projects.mmdet3d_plugin.dd3d.utils.tensor2d",
        "documentation": {}
    },
    {
        "label": "fill_color_polygon",
        "kind": 2,
        "importPath": "projects.mmdet3d_plugin.dd3d.utils.visualization",
        "description": "projects.mmdet3d_plugin.dd3d.utils.visualization",
        "peekOfCode": "def fill_color_polygon(image, polygon, color, alpha=0.5):\n    \"\"\"Color interior of polygon with alpha-blending. This function modified input in place.\n    \"\"\"\n    _mask = Image.new('L', (image.shape[1], image.shape[0]), 0)\n    ImageDraw.Draw(_mask).polygon(polygon, outline=1, fill=1)\n    mask = np.array(_mask, np.bool)\n    for c in range(3):\n        channel = image[:, :, c]\n        channel[mask] = channel[mask] * (1. - alpha) + color[c] * alpha\ndef change_color_brightness(color, brightness_factor):",
        "detail": "projects.mmdet3d_plugin.dd3d.utils.visualization",
        "documentation": {}
    },
    {
        "label": "change_color_brightness",
        "kind": 2,
        "importPath": "projects.mmdet3d_plugin.dd3d.utils.visualization",
        "description": "projects.mmdet3d_plugin.dd3d.utils.visualization",
        "peekOfCode": "def change_color_brightness(color, brightness_factor):\n    \"\"\"\n    Copied from detectron2.utils.visualizer.py\n    -------------------------------------------\n    Depending on the brightness_factor, gives a lighter or darker color i.e. a color with\n    less or more saturation than the original color.\n    Args:\n        color: color of the polygon. Refer to `matplotlib.colors` for a full list of\n            formats that are accepted.\n        brightness_factor (float): a value in [-1.0, 1.0] range. A lightness factor of",
        "detail": "projects.mmdet3d_plugin.dd3d.utils.visualization",
        "documentation": {}
    },
    {
        "label": "draw_text",
        "kind": 2,
        "importPath": "projects.mmdet3d_plugin.dd3d.utils.visualization",
        "description": "projects.mmdet3d_plugin.dd3d.utils.visualization",
        "peekOfCode": "def draw_text(ax, text, position, *, font_size, color=\"g\", horizontal_alignment=\"center\", rotation=0):\n    \"\"\"\n    Copied from Visualizer.draw_text()\n    -----------------------------------\n    Args:\n        text (str): class label\n        position (tuple): a tuple of the x and y coordinates to place text on image.\n        font_size (int, optional): font of the text. If not provided, a font size\n            proportional to the image width is calculated and used.\n        color: color of the text. Refer to `matplotlib.colors` for full list",
        "detail": "projects.mmdet3d_plugin.dd3d.utils.visualization",
        "documentation": {}
    },
    {
        "label": "float_to_uint8_color",
        "kind": 2,
        "importPath": "projects.mmdet3d_plugin.dd3d.utils.visualization",
        "description": "projects.mmdet3d_plugin.dd3d.utils.visualization",
        "peekOfCode": "def float_to_uint8_color(float_clr):\n    assert all([c >= 0. for c in float_clr])\n    assert all([c <= 1. for c in float_clr])\n    return [int(c * 255.) for c in float_clr]\ndef mosaic(items, scale=1.0, pad=3, grid_width=None):\n    \"\"\"Creates a mosaic from list of images.\n    Parameters\n    ----------\n    items: list of np.ndarray\n        List of images to mosaic.",
        "detail": "projects.mmdet3d_plugin.dd3d.utils.visualization",
        "documentation": {}
    },
    {
        "label": "mosaic",
        "kind": 2,
        "importPath": "projects.mmdet3d_plugin.dd3d.utils.visualization",
        "description": "projects.mmdet3d_plugin.dd3d.utils.visualization",
        "peekOfCode": "def mosaic(items, scale=1.0, pad=3, grid_width=None):\n    \"\"\"Creates a mosaic from list of images.\n    Parameters\n    ----------\n    items: list of np.ndarray\n        List of images to mosaic.\n    scale: float, default=1.0\n        Scale factor applied to images. scale > 1.0 enlarges images.\n    pad: int, default=3\n        Padding size of the images before mosaic",
        "detail": "projects.mmdet3d_plugin.dd3d.utils.visualization",
        "documentation": {}
    },
    {
        "label": "Hsigmoid",
        "kind": 6,
        "importPath": "projects.mmdet3d_plugin.models.backbones.vovnet",
        "description": "projects.mmdet3d_plugin.models.backbones.vovnet",
        "peekOfCode": "class Hsigmoid(nn.Module):\n    def __init__(self, inplace=True):\n        super(Hsigmoid, self).__init__()\n        self.inplace = inplace\n    def forward(self, x):\n        return F.relu6(x + 3.0, inplace=self.inplace) / 6.0\nclass eSEModule(nn.Module):\n    def __init__(self, channel, reduction=4):\n        super(eSEModule, self).__init__()\n        self.avg_pool = nn.AdaptiveAvgPool2d(1)",
        "detail": "projects.mmdet3d_plugin.models.backbones.vovnet",
        "documentation": {}
    },
    {
        "label": "eSEModule",
        "kind": 6,
        "importPath": "projects.mmdet3d_plugin.models.backbones.vovnet",
        "description": "projects.mmdet3d_plugin.models.backbones.vovnet",
        "peekOfCode": "class eSEModule(nn.Module):\n    def __init__(self, channel, reduction=4):\n        super(eSEModule, self).__init__()\n        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n        self.fc = nn.Conv2d(channel, channel, kernel_size=1, padding=0)\n        self.hsigmoid = Hsigmoid()\n    def forward(self, x):\n        input = x\n        x = self.avg_pool(x)\n        x = self.fc(x)",
        "detail": "projects.mmdet3d_plugin.models.backbones.vovnet",
        "documentation": {}
    },
    {
        "label": "_OSA_module",
        "kind": 6,
        "importPath": "projects.mmdet3d_plugin.models.backbones.vovnet",
        "description": "projects.mmdet3d_plugin.models.backbones.vovnet",
        "peekOfCode": "class _OSA_module(nn.Module):\n    def __init__(\n        self, in_ch, stage_ch, concat_ch, layer_per_block, module_name, SE=False, identity=False, depthwise=False\n    ):\n        super(_OSA_module, self).__init__()\n        self.identity = identity\n        self.depthwise = depthwise\n        self.isReduced = False\n        self.layers = nn.ModuleList()\n        in_channel = in_ch",
        "detail": "projects.mmdet3d_plugin.models.backbones.vovnet",
        "documentation": {}
    },
    {
        "label": "_OSA_stage",
        "kind": 6,
        "importPath": "projects.mmdet3d_plugin.models.backbones.vovnet",
        "description": "projects.mmdet3d_plugin.models.backbones.vovnet",
        "peekOfCode": "class _OSA_stage(nn.Sequential):\n    def __init__(\n        self, in_ch, stage_ch, concat_ch, block_per_stage, layer_per_block, stage_num, SE=False, depthwise=False\n    ):\n        super(_OSA_stage, self).__init__()\n        if not stage_num == 2:\n            self.add_module(\"Pooling\", nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True))\n        if block_per_stage != 1:\n            SE = False\n        module_name = f\"OSA{stage_num}_1\"",
        "detail": "projects.mmdet3d_plugin.models.backbones.vovnet",
        "documentation": {}
    },
    {
        "label": "VoVNet",
        "kind": 6,
        "importPath": "projects.mmdet3d_plugin.models.backbones.vovnet",
        "description": "projects.mmdet3d_plugin.models.backbones.vovnet",
        "peekOfCode": "class VoVNet(BaseModule):\n    def __init__(self, spec_name, input_ch=3, out_features=None, \n                 frozen_stages=-1, norm_eval=True, pretrained=None, init_cfg=None):\n        \"\"\"\n        Args:\n            input_ch(int) : the number of input channel\n            out_features (list[str]): name of the layers whose outputs should\n                be returned in forward. Can be anything in \"stem\", \"stage2\" ...\n        \"\"\"\n        super(VoVNet, self).__init__(init_cfg)",
        "detail": "projects.mmdet3d_plugin.models.backbones.vovnet",
        "documentation": {}
    },
    {
        "label": "dw_conv3x3",
        "kind": 2,
        "importPath": "projects.mmdet3d_plugin.models.backbones.vovnet",
        "description": "projects.mmdet3d_plugin.models.backbones.vovnet",
        "peekOfCode": "def dw_conv3x3(in_channels, out_channels, module_name, postfix, stride=1, kernel_size=3, padding=1):\n    \"\"\"3x3 convolution with padding\"\"\"\n    return [\n        (\n            '{}_{}/dw_conv3x3'.format(module_name, postfix),\n            nn.Conv2d(\n                in_channels,\n                out_channels,\n                kernel_size=kernel_size,\n                stride=stride,",
        "detail": "projects.mmdet3d_plugin.models.backbones.vovnet",
        "documentation": {}
    },
    {
        "label": "conv3x3",
        "kind": 2,
        "importPath": "projects.mmdet3d_plugin.models.backbones.vovnet",
        "description": "projects.mmdet3d_plugin.models.backbones.vovnet",
        "peekOfCode": "def conv3x3(in_channels, out_channels, module_name, postfix, stride=1, groups=1, kernel_size=3, padding=1):\n    \"\"\"3x3 convolution with padding\"\"\"\n    return [\n        (\n            f\"{module_name}_{postfix}/conv\",\n            nn.Conv2d(\n                in_channels,\n                out_channels,\n                kernel_size=kernel_size,\n                stride=stride,",
        "detail": "projects.mmdet3d_plugin.models.backbones.vovnet",
        "documentation": {}
    },
    {
        "label": "conv1x1",
        "kind": 2,
        "importPath": "projects.mmdet3d_plugin.models.backbones.vovnet",
        "description": "projects.mmdet3d_plugin.models.backbones.vovnet",
        "peekOfCode": "def conv1x1(in_channels, out_channels, module_name, postfix, stride=1, groups=1, kernel_size=1, padding=0):\n    \"\"\"1x1 convolution with padding\"\"\"\n    return [\n        (\n            f\"{module_name}_{postfix}/conv\",\n            nn.Conv2d(\n                in_channels,\n                out_channels,\n                kernel_size=kernel_size,\n                stride=stride,",
        "detail": "projects.mmdet3d_plugin.models.backbones.vovnet",
        "documentation": {}
    },
    {
        "label": "VoVNet19_slim_dw_eSE",
        "kind": 5,
        "importPath": "projects.mmdet3d_plugin.models.backbones.vovnet",
        "description": "projects.mmdet3d_plugin.models.backbones.vovnet",
        "peekOfCode": "VoVNet19_slim_dw_eSE = {\n    'stem': [64, 64, 64],\n    'stage_conv_ch': [64, 80, 96, 112],\n    'stage_out_ch': [112, 256, 384, 512],\n    \"layer_per_block\": 3,\n    \"block_per_stage\": [1, 1, 1, 1],\n    \"eSE\": True,\n    \"dw\": True\n}\nVoVNet19_dw_eSE = {",
        "detail": "projects.mmdet3d_plugin.models.backbones.vovnet",
        "documentation": {}
    },
    {
        "label": "VoVNet19_dw_eSE",
        "kind": 5,
        "importPath": "projects.mmdet3d_plugin.models.backbones.vovnet",
        "description": "projects.mmdet3d_plugin.models.backbones.vovnet",
        "peekOfCode": "VoVNet19_dw_eSE = {\n    'stem': [64, 64, 64],\n    \"stage_conv_ch\": [128, 160, 192, 224],\n    \"stage_out_ch\": [256, 512, 768, 1024],\n    \"layer_per_block\": 3,\n    \"block_per_stage\": [1, 1, 1, 1],\n    \"eSE\": True,\n    \"dw\": True\n}\nVoVNet19_slim_eSE = {",
        "detail": "projects.mmdet3d_plugin.models.backbones.vovnet",
        "documentation": {}
    },
    {
        "label": "VoVNet19_slim_eSE",
        "kind": 5,
        "importPath": "projects.mmdet3d_plugin.models.backbones.vovnet",
        "description": "projects.mmdet3d_plugin.models.backbones.vovnet",
        "peekOfCode": "VoVNet19_slim_eSE = {\n    'stem': [64, 64, 128],\n    'stage_conv_ch': [64, 80, 96, 112],\n    'stage_out_ch': [112, 256, 384, 512],\n    'layer_per_block': 3,\n    'block_per_stage': [1, 1, 1, 1],\n    'eSE': True,\n    \"dw\": False\n}\nVoVNet19_eSE = {",
        "detail": "projects.mmdet3d_plugin.models.backbones.vovnet",
        "documentation": {}
    },
    {
        "label": "VoVNet19_eSE",
        "kind": 5,
        "importPath": "projects.mmdet3d_plugin.models.backbones.vovnet",
        "description": "projects.mmdet3d_plugin.models.backbones.vovnet",
        "peekOfCode": "VoVNet19_eSE = {\n    'stem': [64, 64, 128],\n    \"stage_conv_ch\": [128, 160, 192, 224],\n    \"stage_out_ch\": [256, 512, 768, 1024],\n    \"layer_per_block\": 3,\n    \"block_per_stage\": [1, 1, 1, 1],\n    \"eSE\": True,\n    \"dw\": False\n}\nVoVNet39_eSE = {",
        "detail": "projects.mmdet3d_plugin.models.backbones.vovnet",
        "documentation": {}
    },
    {
        "label": "VoVNet39_eSE",
        "kind": 5,
        "importPath": "projects.mmdet3d_plugin.models.backbones.vovnet",
        "description": "projects.mmdet3d_plugin.models.backbones.vovnet",
        "peekOfCode": "VoVNet39_eSE = {\n    'stem': [64, 64, 128],\n    \"stage_conv_ch\": [128, 160, 192, 224],\n    \"stage_out_ch\": [256, 512, 768, 1024],\n    \"layer_per_block\": 5,\n    \"block_per_stage\": [1, 1, 2, 2],\n    \"eSE\": True,\n    \"dw\": False\n}\nVoVNet57_eSE = {",
        "detail": "projects.mmdet3d_plugin.models.backbones.vovnet",
        "documentation": {}
    },
    {
        "label": "VoVNet57_eSE",
        "kind": 5,
        "importPath": "projects.mmdet3d_plugin.models.backbones.vovnet",
        "description": "projects.mmdet3d_plugin.models.backbones.vovnet",
        "peekOfCode": "VoVNet57_eSE = {\n    'stem': [64, 64, 128],\n    \"stage_conv_ch\": [128, 160, 192, 224],\n    \"stage_out_ch\": [256, 512, 768, 1024],\n    \"layer_per_block\": 5,\n    \"block_per_stage\": [1, 1, 4, 3],\n    \"eSE\": True,\n    \"dw\": False\n}\nVoVNet99_eSE = {",
        "detail": "projects.mmdet3d_plugin.models.backbones.vovnet",
        "documentation": {}
    },
    {
        "label": "VoVNet99_eSE",
        "kind": 5,
        "importPath": "projects.mmdet3d_plugin.models.backbones.vovnet",
        "description": "projects.mmdet3d_plugin.models.backbones.vovnet",
        "peekOfCode": "VoVNet99_eSE = {\n    'stem': [64, 64, 128],\n    \"stage_conv_ch\": [128, 160, 192, 224],\n    \"stage_out_ch\": [256, 512, 768, 1024],\n    \"layer_per_block\": 5,\n    \"block_per_stage\": [1, 3, 9, 3],\n    \"eSE\": True,\n    \"dw\": False\n}\n_STAGE_SPECS = {",
        "detail": "projects.mmdet3d_plugin.models.backbones.vovnet",
        "documentation": {}
    },
    {
        "label": "_STAGE_SPECS",
        "kind": 5,
        "importPath": "projects.mmdet3d_plugin.models.backbones.vovnet",
        "description": "projects.mmdet3d_plugin.models.backbones.vovnet",
        "peekOfCode": "_STAGE_SPECS = {\n    \"V-19-slim-dw-eSE\": VoVNet19_slim_dw_eSE,\n    \"V-19-dw-eSE\": VoVNet19_dw_eSE,\n    \"V-19-slim-eSE\": VoVNet19_slim_eSE,\n    \"V-19-eSE\": VoVNet19_eSE,\n    \"V-39-eSE\": VoVNet39_eSE,\n    \"V-57-eSE\": VoVNet57_eSE,\n    \"V-99-eSE\": VoVNet99_eSE,\n}\ndef dw_conv3x3(in_channels, out_channels, module_name, postfix, stride=1, kernel_size=3, padding=1):",
        "detail": "projects.mmdet3d_plugin.models.backbones.vovnet",
        "documentation": {}
    },
    {
        "label": "GradChecker",
        "kind": 6,
        "importPath": "projects.mmdet3d_plugin.models.hooks.hooks",
        "description": "projects.mmdet3d_plugin.models.hooks.hooks",
        "peekOfCode": "class GradChecker(Hook):\n    def after_train_iter(self, runner):\n        for key, val in runner.model.named_parameters():\n            if val.grad == None and val.requires_grad:\n                print('WARNNING: {key}\\'s parameters are not be used!!!!'.format(key=key))",
        "detail": "projects.mmdet3d_plugin.models.hooks.hooks",
        "documentation": {}
    },
    {
        "label": "AdamW2",
        "kind": 6,
        "importPath": "projects.mmdet3d_plugin.models.opt.adamw",
        "description": "projects.mmdet3d_plugin.models.opt.adamw",
        "peekOfCode": "class AdamW2(Optimizer):\n    r\"\"\"Implements AdamW algorithm. Solve the bug of torch 1.8\n    The original Adam algorithm was proposed in `Adam: A Method for Stochastic Optimization`_.\n    The AdamW variant was proposed in `Decoupled Weight Decay Regularization`_.\n    Args:\n        params (iterable): iterable of parameters to optimize or dicts defining\n            parameter groups\n        lr (float, optional): learning rate (default: 1e-3)\n        betas (Tuple[float, float], optional): coefficients used for computing\n            running averages of gradient and its square (default: (0.9, 0.999))",
        "detail": "projects.mmdet3d_plugin.models.opt.adamw",
        "documentation": {}
    },
    {
        "label": "run_time",
        "kind": 2,
        "importPath": "projects.mmdet3d_plugin.models.utils.bricks",
        "description": "projects.mmdet3d_plugin.models.utils.bricks",
        "peekOfCode": "def run_time(name):\n    def middle(fn):\n        def wrapper(*args, **kwargs):\n            torch.cuda.synchronize()\n            start = time.time()\n            res = fn(*args, **kwargs)\n            torch.cuda.synchronize()\n            time_maps['%s : %s'%(name, fn.__name__) ] += time.time()-start\n            count_maps['%s : %s'%(name, fn.__name__) ] +=1\n            print(\"%s : %s takes up %f \"% (name, fn.__name__,time_maps['%s : %s'%(name, fn.__name__) ] /count_maps['%s : %s'%(name, fn.__name__) ] ))",
        "detail": "projects.mmdet3d_plugin.models.utils.bricks",
        "documentation": {}
    },
    {
        "label": "time_maps",
        "kind": 5,
        "importPath": "projects.mmdet3d_plugin.models.utils.bricks",
        "description": "projects.mmdet3d_plugin.models.utils.bricks",
        "peekOfCode": "time_maps = defaultdict(lambda :0.)\ncount_maps = defaultdict(lambda :0.)\ndef run_time(name):\n    def middle(fn):\n        def wrapper(*args, **kwargs):\n            torch.cuda.synchronize()\n            start = time.time()\n            res = fn(*args, **kwargs)\n            torch.cuda.synchronize()\n            time_maps['%s : %s'%(name, fn.__name__) ] += time.time()-start",
        "detail": "projects.mmdet3d_plugin.models.utils.bricks",
        "documentation": {}
    },
    {
        "label": "count_maps",
        "kind": 5,
        "importPath": "projects.mmdet3d_plugin.models.utils.bricks",
        "description": "projects.mmdet3d_plugin.models.utils.bricks",
        "peekOfCode": "count_maps = defaultdict(lambda :0.)\ndef run_time(name):\n    def middle(fn):\n        def wrapper(*args, **kwargs):\n            torch.cuda.synchronize()\n            start = time.time()\n            res = fn(*args, **kwargs)\n            torch.cuda.synchronize()\n            time_maps['%s : %s'%(name, fn.__name__) ] += time.time()-start\n            count_maps['%s : %s'%(name, fn.__name__) ] +=1",
        "detail": "projects.mmdet3d_plugin.models.utils.bricks",
        "documentation": {}
    },
    {
        "label": "Grid",
        "kind": 6,
        "importPath": "projects.mmdet3d_plugin.models.utils.grid_mask",
        "description": "projects.mmdet3d_plugin.models.utils.grid_mask",
        "peekOfCode": "class Grid(object):\n    def __init__(self, use_h, use_w, rotate = 1, offset=False, ratio = 0.5, mode=0, prob = 1.):\n        self.use_h = use_h\n        self.use_w = use_w\n        self.rotate = rotate\n        self.offset = offset\n        self.ratio = ratio\n        self.mode=mode\n        self.st_prob = prob\n        self.prob = prob",
        "detail": "projects.mmdet3d_plugin.models.utils.grid_mask",
        "documentation": {}
    },
    {
        "label": "GridMask",
        "kind": 6,
        "importPath": "projects.mmdet3d_plugin.models.utils.grid_mask",
        "description": "projects.mmdet3d_plugin.models.utils.grid_mask",
        "peekOfCode": "class GridMask(nn.Module):\n    def __init__(self, use_h, use_w, rotate = 1, offset=False, ratio = 0.5, mode=0, prob = 1.):\n        super(GridMask, self).__init__()\n        self.use_h = use_h\n        self.use_w = use_w\n        self.rotate = rotate\n        self.offset = offset\n        self.ratio = ratio\n        self.mode = mode\n        self.st_prob = prob",
        "detail": "projects.mmdet3d_plugin.models.utils.grid_mask",
        "documentation": {}
    },
    {
        "label": "RelPositionEmbedding",
        "kind": 6,
        "importPath": "projects.mmdet3d_plugin.models.utils.position_embedding",
        "description": "projects.mmdet3d_plugin.models.utils.position_embedding",
        "peekOfCode": "class RelPositionEmbedding(nn.Module):\n    def __init__(self, num_pos_feats=64, pos_norm=True):\n        super().__init__()\n        self.num_pos_feats = num_pos_feats\n        self.fc = nn.Linear(4, self.num_pos_feats,bias=False)\n        #nn.init.orthogonal_(self.fc.weight)\n        #self.fc.weight.requires_grad = False\n        self.pos_norm = pos_norm\n        if self.pos_norm:\n            self.norm = nn.LayerNorm(self.num_pos_feats)",
        "detail": "projects.mmdet3d_plugin.models.utils.position_embedding",
        "documentation": {}
    },
    {
        "label": "convert_color",
        "kind": 2,
        "importPath": "projects.mmdet3d_plugin.models.utils.visual",
        "description": "projects.mmdet3d_plugin.models.utils.visual",
        "peekOfCode": "def convert_color(img_path):\n    plt.figure()\n    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n    plt.imsave(img_path, img, cmap=plt.get_cmap('viridis'))\n    plt.close()\ndef save_tensor(tensor, path, pad_value=254.0,):\n    print('save_tensor', path)\n    tensor = tensor.to(torch.float).detach().cpu()\n    if tensor.type() == 'torch.BoolTensor':\n        tensor = tensor*255",
        "detail": "projects.mmdet3d_plugin.models.utils.visual",
        "documentation": {}
    },
    {
        "label": "save_tensor",
        "kind": 2,
        "importPath": "projects.mmdet3d_plugin.models.utils.visual",
        "description": "projects.mmdet3d_plugin.models.utils.visual",
        "peekOfCode": "def save_tensor(tensor, path, pad_value=254.0,):\n    print('save_tensor', path)\n    tensor = tensor.to(torch.float).detach().cpu()\n    if tensor.type() == 'torch.BoolTensor':\n        tensor = tensor*255\n    if len(tensor.shape) == 3:\n        tensor = tensor.unsqueeze(1)\n    tensor = make_grid(tensor, pad_value=pad_value, normalize=False).permute(1, 2, 0).numpy().copy()\n    torchvision.utils.save_image(torch.tensor(tensor).permute(2, 0, 1), path)\n    convert_color(path)",
        "detail": "projects.mmdet3d_plugin.models.utils.visual",
        "documentation": {}
    },
    {
        "label": "cal_train_time",
        "kind": 2,
        "importPath": "tools.analysis_tools.analyze_logs",
        "description": "tools.analysis_tools.analyze_logs",
        "peekOfCode": "def cal_train_time(log_dicts, args):\n    for i, log_dict in enumerate(log_dicts):\n        print(f'{\"-\" * 5}Analyze train time of {args.json_logs[i]}{\"-\" * 5}')\n        all_times = []\n        for epoch in log_dict.keys():\n            if args.include_outliers:\n                all_times.append(log_dict[epoch]['time'])\n            else:\n                all_times.append(log_dict[epoch]['time'][1:])\n        all_times = np.array(all_times)",
        "detail": "tools.analysis_tools.analyze_logs",
        "documentation": {}
    },
    {
        "label": "plot_curve",
        "kind": 2,
        "importPath": "tools.analysis_tools.analyze_logs",
        "description": "tools.analysis_tools.analyze_logs",
        "peekOfCode": "def plot_curve(log_dicts, args):\n    if args.backend is not None:\n        plt.switch_backend(args.backend)\n    sns.set_style(args.style)\n    # if legend is None, use {filename}_{key} as legend\n    legend = args.legend\n    if legend is None:\n        legend = []\n        for json_log in args.json_logs:\n            for metric in args.keys:",
        "detail": "tools.analysis_tools.analyze_logs",
        "documentation": {}
    },
    {
        "label": "add_plot_parser",
        "kind": 2,
        "importPath": "tools.analysis_tools.analyze_logs",
        "description": "tools.analysis_tools.analyze_logs",
        "peekOfCode": "def add_plot_parser(subparsers):\n    parser_plt = subparsers.add_parser(\n        'plot_curve', help='parser for plotting curves')\n    parser_plt.add_argument(\n        'json_logs',\n        type=str,\n        nargs='+',\n        help='path of train log in json format')\n    parser_plt.add_argument(\n        '--keys',",
        "detail": "tools.analysis_tools.analyze_logs",
        "documentation": {}
    },
    {
        "label": "add_time_parser",
        "kind": 2,
        "importPath": "tools.analysis_tools.analyze_logs",
        "description": "tools.analysis_tools.analyze_logs",
        "peekOfCode": "def add_time_parser(subparsers):\n    parser_time = subparsers.add_parser(\n        'cal_train_time',\n        help='parser for computing the average time per training iteration')\n    parser_time.add_argument(\n        'json_logs',\n        type=str,\n        nargs='+',\n        help='path of train log in json format')\n    parser_time.add_argument(",
        "detail": "tools.analysis_tools.analyze_logs",
        "documentation": {}
    },
    {
        "label": "parse_args",
        "kind": 2,
        "importPath": "tools.analysis_tools.analyze_logs",
        "description": "tools.analysis_tools.analyze_logs",
        "peekOfCode": "def parse_args():\n    parser = argparse.ArgumentParser(description='Analyze Json Log')\n    # currently only support plot curve and calculate average train time\n    subparsers = parser.add_subparsers(dest='task', help='task parser')\n    add_plot_parser(subparsers)\n    add_time_parser(subparsers)\n    args = parser.parse_args()\n    return args\ndef load_json_logs(json_logs):\n    # load and convert json_logs to log_dict, key is epoch, value is a sub dict",
        "detail": "tools.analysis_tools.analyze_logs",
        "documentation": {}
    },
    {
        "label": "load_json_logs",
        "kind": 2,
        "importPath": "tools.analysis_tools.analyze_logs",
        "description": "tools.analysis_tools.analyze_logs",
        "peekOfCode": "def load_json_logs(json_logs):\n    # load and convert json_logs to log_dict, key is epoch, value is a sub dict\n    # keys of sub dict is different metrics, e.g. memory, bbox_mAP\n    # value of sub dict is a list of corresponding values of all iterations\n    log_dicts = [dict() for _ in json_logs]\n    for json_log, log_dict in zip(json_logs, log_dicts):\n        with open(json_log, 'r') as log_file:\n            for line in log_file:\n                log = json.loads(line.strip())\n                # skip lines without `epoch` field",
        "detail": "tools.analysis_tools.analyze_logs",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "tools.analysis_tools.analyze_logs",
        "description": "tools.analysis_tools.analyze_logs",
        "peekOfCode": "def main():\n    args = parse_args()\n    json_logs = args.json_logs\n    for json_log in json_logs:\n        assert json_log.endswith('.json')\n    log_dicts = load_json_logs(json_logs)\n    eval(args.task)(log_dicts, args)\nif __name__ == '__main__':\n    main()",
        "detail": "tools.analysis_tools.analyze_logs",
        "documentation": {}
    },
    {
        "label": "parse_args",
        "kind": 2,
        "importPath": "tools.analysis_tools.benchmark",
        "description": "tools.analysis_tools.benchmark",
        "peekOfCode": "def parse_args():\n    parser = argparse.ArgumentParser(description='MMDet benchmark a model')\n    parser.add_argument('config', help='test config file path')\n    parser.add_argument('--checkpoint', default=None, help='checkpoint file')\n    parser.add_argument('--samples', default=2000, help='samples to benchmark')\n    parser.add_argument(\n        '--log-interval', default=50, help='interval of logging')\n    parser.add_argument(\n        '--fuse-conv-bn',\n        action='store_true',",
        "detail": "tools.analysis_tools.benchmark",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "tools.analysis_tools.benchmark",
        "description": "tools.analysis_tools.benchmark",
        "peekOfCode": "def main():\n    args = parse_args()\n    cfg = Config.fromfile(args.config)\n    # set cudnn_benchmark\n    if cfg.get('cudnn_benchmark', False):\n        torch.backends.cudnn.benchmark = True\n    cfg.model.pretrained = None\n    cfg.data.test.test_mode = True\n    # build the dataloader\n    # TODO: support multiple images per gpu (only minor changes are needed)",
        "detail": "tools.analysis_tools.benchmark",
        "documentation": {}
    },
    {
        "label": "file_path",
        "kind": 5,
        "importPath": "tools.analysis_tools.get_params",
        "description": "tools.analysis_tools.get_params",
        "peekOfCode": "file_path = './ckpts/bevformer_v4.pth'\nmodel = torch.load(file_path, map_location='cpu')\nall = 0\nfor key in list(model['state_dict'].keys()):\n    all += model['state_dict'][key].nelement()\nprint(all)\n# smaller 63374123\n# v4 69140395",
        "detail": "tools.analysis_tools.get_params",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "tools.analysis_tools.get_params",
        "description": "tools.analysis_tools.get_params",
        "peekOfCode": "model = torch.load(file_path, map_location='cpu')\nall = 0\nfor key in list(model['state_dict'].keys()):\n    all += model['state_dict'][key].nelement()\nprint(all)\n# smaller 63374123\n# v4 69140395",
        "detail": "tools.analysis_tools.get_params",
        "documentation": {}
    },
    {
        "label": "all",
        "kind": 5,
        "importPath": "tools.analysis_tools.get_params",
        "description": "tools.analysis_tools.get_params",
        "peekOfCode": "all = 0\nfor key in list(model['state_dict'].keys()):\n    all += model['state_dict'][key].nelement()\nprint(all)\n# smaller 63374123\n# v4 69140395",
        "detail": "tools.analysis_tools.get_params",
        "documentation": {}
    },
    {
        "label": "render_annotation",
        "kind": 2,
        "importPath": "tools.analysis_tools.visual",
        "description": "tools.analysis_tools.visual",
        "peekOfCode": "def render_annotation(\n        anntoken: str,\n        margin: float = 10,\n        view: np.ndarray = np.eye(4),\n        box_vis_level: BoxVisibility = BoxVisibility.ANY,\n        out_path: str = 'render.png',\n        extra_info: bool = False) -> None:\n    \"\"\"\n    Render selected annotation.\n    :param anntoken: Sample_annotation token.",
        "detail": "tools.analysis_tools.visual",
        "documentation": {}
    },
    {
        "label": "get_sample_data",
        "kind": 2,
        "importPath": "tools.analysis_tools.visual",
        "description": "tools.analysis_tools.visual",
        "peekOfCode": "def get_sample_data(sample_data_token: str,\n                    box_vis_level: BoxVisibility = BoxVisibility.ANY,\n                    selected_anntokens=None,\n                    use_flat_vehicle_coordinates: bool = False):\n    \"\"\"\n    Returns the data path as well as all annotations related to that sample_data.\n    Note that the boxes are transformed into the current sensor's coordinate frame.\n    :param sample_data_token: Sample_data token.\n    :param box_vis_level: If sample_data is an image, this sets required visibility for boxes.\n    :param selected_anntokens: If provided only return the selected annotation.",
        "detail": "tools.analysis_tools.visual",
        "documentation": {}
    },
    {
        "label": "get_predicted_data",
        "kind": 2,
        "importPath": "tools.analysis_tools.visual",
        "description": "tools.analysis_tools.visual",
        "peekOfCode": "def get_predicted_data(sample_data_token: str,\n                       box_vis_level: BoxVisibility = BoxVisibility.ANY,\n                       selected_anntokens=None,\n                       use_flat_vehicle_coordinates: bool = False,\n                       pred_anns=None\n                       ):\n    \"\"\"\n    Returns the data path as well as all annotations related to that sample_data.\n    Note that the boxes are transformed into the current sensor's coordinate frame.\n    :param sample_data_token: Sample_data token.",
        "detail": "tools.analysis_tools.visual",
        "documentation": {}
    },
    {
        "label": "lidiar_render",
        "kind": 2,
        "importPath": "tools.analysis_tools.visual",
        "description": "tools.analysis_tools.visual",
        "peekOfCode": "def lidiar_render(sample_token, data,out_path=None):\n    bbox_gt_list = []\n    bbox_pred_list = []\n    anns = nusc.get('sample', sample_token)['anns']\n    for ann in anns:\n        content = nusc.get('sample_annotation', ann)\n        try:\n            bbox_gt_list.append(DetectionBox(\n                sample_token=content['sample_token'],\n                translation=tuple(content['translation']),",
        "detail": "tools.analysis_tools.visual",
        "documentation": {}
    },
    {
        "label": "get_color",
        "kind": 2,
        "importPath": "tools.analysis_tools.visual",
        "description": "tools.analysis_tools.visual",
        "peekOfCode": "def get_color(category_name: str):\n    \"\"\"\n    Provides the default colors based on the category names.\n    This method works for the general nuScenes categories, as well as the nuScenes detection categories.\n    \"\"\"\n    a = ['noise', 'animal', 'human.pedestrian.adult', 'human.pedestrian.child', 'human.pedestrian.construction_worker',\n     'human.pedestrian.personal_mobility', 'human.pedestrian.police_officer', 'human.pedestrian.stroller',\n     'human.pedestrian.wheelchair', 'movable_object.barrier', 'movable_object.debris',\n     'movable_object.pushable_pullable', 'movable_object.trafficcone', 'static_object.bicycle_rack', 'vehicle.bicycle',\n     'vehicle.bus.bendy', 'vehicle.bus.rigid', 'vehicle.car', 'vehicle.construction', 'vehicle.emergency.ambulance',",
        "detail": "tools.analysis_tools.visual",
        "documentation": {}
    },
    {
        "label": "render_sample_data",
        "kind": 2,
        "importPath": "tools.analysis_tools.visual",
        "description": "tools.analysis_tools.visual",
        "peekOfCode": "def render_sample_data(\n        sample_toekn: str,\n        with_anns: bool = True,\n        box_vis_level: BoxVisibility = BoxVisibility.ANY,\n        axes_limit: float = 40,\n        ax=None,\n        nsweeps: int = 1,\n        out_path: str = None,\n        underlay_map: bool = True,\n        use_flat_vehicle_coordinates: bool = True,",
        "detail": "tools.analysis_tools.visual",
        "documentation": {}
    },
    {
        "label": "cams",
        "kind": 5,
        "importPath": "tools.analysis_tools.visual",
        "description": "tools.analysis_tools.visual",
        "peekOfCode": "cams = ['CAM_FRONT',\n 'CAM_FRONT_RIGHT',\n 'CAM_BACK_RIGHT',\n 'CAM_BACK',\n 'CAM_BACK_LEFT',\n 'CAM_FRONT_LEFT']\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom nuscenes.utils.data_classes import LidarPointCloud, RadarPointCloud, Box\nfrom PIL import Image",
        "detail": "tools.analysis_tools.visual",
        "documentation": {}
    },
    {
        "label": "crop_image_patch_v2",
        "kind": 2,
        "importPath": "tools.data_converter.create_gt_database",
        "description": "tools.data_converter.create_gt_database",
        "peekOfCode": "def crop_image_patch_v2(pos_proposals, pos_assigned_gt_inds, gt_masks):\n    import torch\n    from torch.nn.modules.utils import _pair\n    device = pos_proposals.device\n    num_pos = pos_proposals.size(0)\n    fake_inds = (\n        torch.arange(num_pos,\n                     device=device).to(dtype=pos_proposals.dtype)[:, None])\n    rois = torch.cat([fake_inds, pos_proposals], dim=1)  # Nx5\n    mask_size = _pair(28)",
        "detail": "tools.data_converter.create_gt_database",
        "documentation": {}
    },
    {
        "label": "crop_image_patch",
        "kind": 2,
        "importPath": "tools.data_converter.create_gt_database",
        "description": "tools.data_converter.create_gt_database",
        "peekOfCode": "def crop_image_patch(pos_proposals, gt_masks, pos_assigned_gt_inds, org_img):\n    num_pos = pos_proposals.shape[0]\n    masks = []\n    img_patches = []\n    for i in range(num_pos):\n        gt_mask = gt_masks[pos_assigned_gt_inds[i]]\n        bbox = pos_proposals[i, :].astype(np.int32)\n        x1, y1, x2, y2 = bbox\n        w = np.maximum(x2 - x1 + 1, 1)\n        h = np.maximum(y2 - y1 + 1, 1)",
        "detail": "tools.data_converter.create_gt_database",
        "documentation": {}
    },
    {
        "label": "create_groundtruth_database",
        "kind": 2,
        "importPath": "tools.data_converter.create_gt_database",
        "description": "tools.data_converter.create_gt_database",
        "peekOfCode": "def create_groundtruth_database(dataset_class_name,\n                                data_path,\n                                info_prefix,\n                                info_path=None,\n                                mask_anno_path=None,\n                                used_classes=None,\n                                database_save_path=None,\n                                db_info_save_path=None,\n                                relative_path=True,\n                                add_rgb=False,",
        "detail": "tools.data_converter.create_gt_database",
        "documentation": {}
    },
    {
        "label": "create_indoor_info_file",
        "kind": 2,
        "importPath": "tools.data_converter.indoor_converter",
        "description": "tools.data_converter.indoor_converter",
        "peekOfCode": "def create_indoor_info_file(data_path,\n                            pkl_prefix='sunrgbd',\n                            save_path=None,\n                            use_v1=False,\n                            workers=4):\n    \"\"\"Create indoor information file.\n    Get information of the raw data and save it to the pkl file.\n    Args:\n        data_path (str): Path of the data.\n        pkl_prefix (str): Prefix of the pkl to be saved. Default: 'sunrgbd'.",
        "detail": "tools.data_converter.indoor_converter",
        "documentation": {}
    },
    {
        "label": "convert_to_kitti_info_version2",
        "kind": 2,
        "importPath": "tools.data_converter.kitti_converter",
        "description": "tools.data_converter.kitti_converter",
        "peekOfCode": "def convert_to_kitti_info_version2(info):\n    \"\"\"convert kitti info v1 to v2 if possible.\n    Args:\n        info (dict): Info of the input kitti data.\n            - image (dict): image info\n            - calib (dict): calibration info\n            - point_cloud (dict): point cloud info\n    \"\"\"\n    if 'image' not in info or 'calib' not in info or 'point_cloud' not in info:\n        info['image'] = {",
        "detail": "tools.data_converter.kitti_converter",
        "documentation": {}
    },
    {
        "label": "create_kitti_info_file",
        "kind": 2,
        "importPath": "tools.data_converter.kitti_converter",
        "description": "tools.data_converter.kitti_converter",
        "peekOfCode": "def create_kitti_info_file(data_path,\n                           pkl_prefix='kitti',\n                           save_path=None,\n                           relative_path=True):\n    \"\"\"Create info file of KITTI dataset.\n    Given the raw data, generate its related info file in pkl format.\n    Args:\n        data_path (str): Path of the data root.\n        pkl_prefix (str): Prefix of the info file to be generated.\n        save_path (str): Path to save the info file.",
        "detail": "tools.data_converter.kitti_converter",
        "documentation": {}
    },
    {
        "label": "create_waymo_info_file",
        "kind": 2,
        "importPath": "tools.data_converter.kitti_converter",
        "description": "tools.data_converter.kitti_converter",
        "peekOfCode": "def create_waymo_info_file(data_path,\n                           pkl_prefix='waymo',\n                           save_path=None,\n                           relative_path=True,\n                           max_sweeps=5):\n    \"\"\"Create info file of waymo dataset.\n    Given the raw data, generate its related info file in pkl format.\n    Args:\n        data_path (str): Path of the data root.\n        pkl_prefix (str): Prefix of the info file to be generated.",
        "detail": "tools.data_converter.kitti_converter",
        "documentation": {}
    },
    {
        "label": "create_reduced_point_cloud",
        "kind": 2,
        "importPath": "tools.data_converter.kitti_converter",
        "description": "tools.data_converter.kitti_converter",
        "peekOfCode": "def create_reduced_point_cloud(data_path,\n                               pkl_prefix,\n                               train_info_path=None,\n                               val_info_path=None,\n                               test_info_path=None,\n                               save_path=None,\n                               with_back=False):\n    \"\"\"Create reduced point clouds for training/validation/testing.\n    Args:\n        data_path (str): Path of original data.",
        "detail": "tools.data_converter.kitti_converter",
        "documentation": {}
    },
    {
        "label": "export_2d_annotation",
        "kind": 2,
        "importPath": "tools.data_converter.kitti_converter",
        "description": "tools.data_converter.kitti_converter",
        "peekOfCode": "def export_2d_annotation(root_path, info_path, mono3d=True):\n    \"\"\"Export 2d annotation from the info file and raw data.\n    Args:\n        root_path (str): Root path of the raw data.\n        info_path (str): Path of the info file.\n        mono3d (bool): Whether to export mono3d annotation. Default: True.\n    \"\"\"\n    # get bbox annotations for camera\n    kitti_infos = mmcv.load(info_path)\n    cat2Ids = [",
        "detail": "tools.data_converter.kitti_converter",
        "documentation": {}
    },
    {
        "label": "get_2d_boxes",
        "kind": 2,
        "importPath": "tools.data_converter.kitti_converter",
        "description": "tools.data_converter.kitti_converter",
        "peekOfCode": "def get_2d_boxes(info, occluded, mono3d=True):\n    \"\"\"Get the 2D annotation records for a given info.\n    Args:\n        info: Information of the given sample data.\n        occluded: Integer (0, 1, 2, 3) indicating occlusion state: \\\n            0 = fully visible, 1 = partly occluded, 2 = largely occluded, \\\n            3 = unknown, -1 = DontCare\n        mono3d (bool): Whether to get boxes with mono3d annotation.\n    Return:\n        list[dict]: List of 2D annotation record that belongs to the input",
        "detail": "tools.data_converter.kitti_converter",
        "documentation": {}
    },
    {
        "label": "generate_record",
        "kind": 2,
        "importPath": "tools.data_converter.kitti_converter",
        "description": "tools.data_converter.kitti_converter",
        "peekOfCode": "def generate_record(ann_rec, x1, y1, x2, y2, sample_data_token, filename):\n    \"\"\"Generate one 2D annotation record given various informations on top of\n    the 2D bounding box coordinates.\n    Args:\n        ann_rec (dict): Original 3d annotation record.\n        x1 (float): Minimum value of the x coordinate.\n        y1 (float): Minimum value of the y coordinate.\n        x2 (float): Maximum value of the x coordinate.\n        y2 (float): Maximum value of the y coordinate.\n        sample_data_token (str): Sample data token.",
        "detail": "tools.data_converter.kitti_converter",
        "documentation": {}
    },
    {
        "label": "kitti_categories",
        "kind": 5,
        "importPath": "tools.data_converter.kitti_converter",
        "description": "tools.data_converter.kitti_converter",
        "peekOfCode": "kitti_categories = ('Pedestrian', 'Cyclist', 'Car')\ndef convert_to_kitti_info_version2(info):\n    \"\"\"convert kitti info v1 to v2 if possible.\n    Args:\n        info (dict): Info of the input kitti data.\n            - image (dict): image info\n            - calib (dict): calibration info\n            - point_cloud (dict): point cloud info\n    \"\"\"\n    if 'image' not in info or 'calib' not in info or 'point_cloud' not in info:",
        "detail": "tools.data_converter.kitti_converter",
        "documentation": {}
    },
    {
        "label": "get_image_index_str",
        "kind": 2,
        "importPath": "tools.data_converter.kitti_data_utils",
        "description": "tools.data_converter.kitti_data_utils",
        "peekOfCode": "def get_image_index_str(img_idx, use_prefix_id=False):\n    if use_prefix_id:\n        return '{:07d}'.format(img_idx)\n    else:\n        return '{:06d}'.format(img_idx)\ndef get_kitti_info_path(idx,\n                        prefix,\n                        info_type='image_2',\n                        file_tail='.png',\n                        training=True,",
        "detail": "tools.data_converter.kitti_data_utils",
        "documentation": {}
    },
    {
        "label": "get_kitti_info_path",
        "kind": 2,
        "importPath": "tools.data_converter.kitti_data_utils",
        "description": "tools.data_converter.kitti_data_utils",
        "peekOfCode": "def get_kitti_info_path(idx,\n                        prefix,\n                        info_type='image_2',\n                        file_tail='.png',\n                        training=True,\n                        relative_path=True,\n                        exist_check=True,\n                        use_prefix_id=False):\n    img_idx_str = get_image_index_str(idx, use_prefix_id)\n    img_idx_str += file_tail",
        "detail": "tools.data_converter.kitti_data_utils",
        "documentation": {}
    },
    {
        "label": "get_image_path",
        "kind": 2,
        "importPath": "tools.data_converter.kitti_data_utils",
        "description": "tools.data_converter.kitti_data_utils",
        "peekOfCode": "def get_image_path(idx,\n                   prefix,\n                   training=True,\n                   relative_path=True,\n                   exist_check=True,\n                   info_type='image_2',\n                   use_prefix_id=False):\n    return get_kitti_info_path(idx, prefix, info_type, '.png', training,\n                               relative_path, exist_check, use_prefix_id)\ndef get_label_path(idx,",
        "detail": "tools.data_converter.kitti_data_utils",
        "documentation": {}
    },
    {
        "label": "get_label_path",
        "kind": 2,
        "importPath": "tools.data_converter.kitti_data_utils",
        "description": "tools.data_converter.kitti_data_utils",
        "peekOfCode": "def get_label_path(idx,\n                   prefix,\n                   training=True,\n                   relative_path=True,\n                   exist_check=True,\n                   info_type='label_2',\n                   use_prefix_id=False):\n    return get_kitti_info_path(idx, prefix, info_type, '.txt', training,\n                               relative_path, exist_check, use_prefix_id)\ndef get_velodyne_path(idx,",
        "detail": "tools.data_converter.kitti_data_utils",
        "documentation": {}
    },
    {
        "label": "get_velodyne_path",
        "kind": 2,
        "importPath": "tools.data_converter.kitti_data_utils",
        "description": "tools.data_converter.kitti_data_utils",
        "peekOfCode": "def get_velodyne_path(idx,\n                      prefix,\n                      training=True,\n                      relative_path=True,\n                      exist_check=True,\n                      use_prefix_id=False):\n    return get_kitti_info_path(idx, prefix, 'velodyne', '.bin', training,\n                               relative_path, exist_check, use_prefix_id)\ndef get_calib_path(idx,\n                   prefix,",
        "detail": "tools.data_converter.kitti_data_utils",
        "documentation": {}
    },
    {
        "label": "get_calib_path",
        "kind": 2,
        "importPath": "tools.data_converter.kitti_data_utils",
        "description": "tools.data_converter.kitti_data_utils",
        "peekOfCode": "def get_calib_path(idx,\n                   prefix,\n                   training=True,\n                   relative_path=True,\n                   exist_check=True,\n                   use_prefix_id=False):\n    return get_kitti_info_path(idx, prefix, 'calib', '.txt', training,\n                               relative_path, exist_check, use_prefix_id)\ndef get_pose_path(idx,\n                  prefix,",
        "detail": "tools.data_converter.kitti_data_utils",
        "documentation": {}
    },
    {
        "label": "get_pose_path",
        "kind": 2,
        "importPath": "tools.data_converter.kitti_data_utils",
        "description": "tools.data_converter.kitti_data_utils",
        "peekOfCode": "def get_pose_path(idx,\n                  prefix,\n                  training=True,\n                  relative_path=True,\n                  exist_check=True,\n                  use_prefix_id=False):\n    return get_kitti_info_path(idx, prefix, 'pose', '.txt', training,\n                               relative_path, exist_check, use_prefix_id)\ndef get_label_anno(label_path):\n    annotations = {}",
        "detail": "tools.data_converter.kitti_data_utils",
        "documentation": {}
    },
    {
        "label": "get_label_anno",
        "kind": 2,
        "importPath": "tools.data_converter.kitti_data_utils",
        "description": "tools.data_converter.kitti_data_utils",
        "peekOfCode": "def get_label_anno(label_path):\n    annotations = {}\n    annotations.update({\n        'name': [],\n        'truncated': [],\n        'occluded': [],\n        'alpha': [],\n        'bbox': [],\n        'dimensions': [],\n        'location': [],",
        "detail": "tools.data_converter.kitti_data_utils",
        "documentation": {}
    },
    {
        "label": "get_kitti_image_info",
        "kind": 2,
        "importPath": "tools.data_converter.kitti_data_utils",
        "description": "tools.data_converter.kitti_data_utils",
        "peekOfCode": "def get_kitti_image_info(path,\n                         training=True,\n                         label_info=True,\n                         velodyne=False,\n                         calib=False,\n                         image_ids=7481,\n                         extend_matrix=True,\n                         num_worker=8,\n                         relative_path=True,\n                         with_imageshape=True):",
        "detail": "tools.data_converter.kitti_data_utils",
        "documentation": {}
    },
    {
        "label": "get_waymo_image_info",
        "kind": 2,
        "importPath": "tools.data_converter.kitti_data_utils",
        "description": "tools.data_converter.kitti_data_utils",
        "peekOfCode": "def get_waymo_image_info(path,\n                         training=True,\n                         label_info=True,\n                         velodyne=False,\n                         calib=False,\n                         pose=False,\n                         image_ids=7481,\n                         extend_matrix=True,\n                         num_worker=8,\n                         relative_path=True,",
        "detail": "tools.data_converter.kitti_data_utils",
        "documentation": {}
    },
    {
        "label": "kitti_anno_to_label_file",
        "kind": 2,
        "importPath": "tools.data_converter.kitti_data_utils",
        "description": "tools.data_converter.kitti_data_utils",
        "peekOfCode": "def kitti_anno_to_label_file(annos, folder):\n    folder = Path(folder)\n    for anno in annos:\n        image_idx = anno['metadata']['image_idx']\n        label_lines = []\n        for j in range(anno['bbox'].shape[0]):\n            label_dict = {\n                'name': anno['name'][j],\n                'alpha': anno['alpha'][j],\n                'bbox': anno['bbox'][j],",
        "detail": "tools.data_converter.kitti_data_utils",
        "documentation": {}
    },
    {
        "label": "add_difficulty_to_annos",
        "kind": 2,
        "importPath": "tools.data_converter.kitti_data_utils",
        "description": "tools.data_converter.kitti_data_utils",
        "peekOfCode": "def add_difficulty_to_annos(info):\n    min_height = [40, 25,\n                  25]  # minimum height for evaluated groundtruth/detections\n    max_occlusion = [\n        0, 1, 2\n    ]  # maximum occlusion level of the groundtruth used for evaluation\n    max_trunc = [\n        0.15, 0.3, 0.5\n    ]  # maximum truncation level of the groundtruth used for evaluation\n    annos = info['annos']",
        "detail": "tools.data_converter.kitti_data_utils",
        "documentation": {}
    },
    {
        "label": "kitti_result_line",
        "kind": 2,
        "importPath": "tools.data_converter.kitti_data_utils",
        "description": "tools.data_converter.kitti_data_utils",
        "peekOfCode": "def kitti_result_line(result_dict, precision=4):\n    prec_float = '{' + ':.{}f'.format(precision) + '}'\n    res_line = []\n    all_field_default = OrderedDict([\n        ('name', None),\n        ('truncated', -1),\n        ('occluded', -1),\n        ('alpha', -10),\n        ('bbox', None),\n        ('dimensions', [-1, -1, -1]),",
        "detail": "tools.data_converter.kitti_data_utils",
        "documentation": {}
    },
    {
        "label": "create_lyft_infos",
        "kind": 2,
        "importPath": "tools.data_converter.lyft_converter",
        "description": "tools.data_converter.lyft_converter",
        "peekOfCode": "def create_lyft_infos(root_path,\n                      info_prefix,\n                      version='v1.01-train',\n                      max_sweeps=10):\n    \"\"\"Create info file of lyft dataset.\n    Given the raw data, generate its related info file in pkl format.\n    Args:\n        root_path (str): Path of the data root.\n        info_prefix (str): Prefix of the info file to be generated.\n        version (str): Version of the data.",
        "detail": "tools.data_converter.lyft_converter",
        "documentation": {}
    },
    {
        "label": "export_2d_annotation",
        "kind": 2,
        "importPath": "tools.data_converter.lyft_converter",
        "description": "tools.data_converter.lyft_converter",
        "peekOfCode": "def export_2d_annotation(root_path, info_path, version):\n    \"\"\"Export 2d annotation from the info file and raw data.\n    Args:\n        root_path (str): Root path of the raw data.\n        info_path (str): Path of the info file.\n        version (str): Dataset version.\n    \"\"\"\n    warning.warn('DeprecationWarning: 2D annotations are not used on the '\n                 'Lyft dataset. The function export_2d_annotation will be '\n                 'deprecated.')",
        "detail": "tools.data_converter.lyft_converter",
        "documentation": {}
    },
    {
        "label": "lyft_categories",
        "kind": 5,
        "importPath": "tools.data_converter.lyft_converter",
        "description": "tools.data_converter.lyft_converter",
        "peekOfCode": "lyft_categories = ('car', 'truck', 'bus', 'emergency_vehicle', 'other_vehicle',\n                   'motorcycle', 'bicycle', 'pedestrian', 'animal')\ndef create_lyft_infos(root_path,\n                      info_prefix,\n                      version='v1.01-train',\n                      max_sweeps=10):\n    \"\"\"Create info file of lyft dataset.\n    Given the raw data, generate its related info file in pkl format.\n    Args:\n        root_path (str): Path of the data root.",
        "detail": "tools.data_converter.lyft_converter",
        "documentation": {}
    },
    {
        "label": "fix_lyft",
        "kind": 2,
        "importPath": "tools.data_converter.lyft_data_fixer",
        "description": "tools.data_converter.lyft_data_fixer",
        "peekOfCode": "def fix_lyft(root_folder='./data/lyft', version='v1.01'):\n    # refer to https://www.kaggle.com/c/3d-object-detection-for-autonomous-vehicles/discussion/110000  # noqa\n    lidar_path = 'lidar/host-a011_lidar1_1233090652702363606.bin'\n    root_folder = os.path.join(root_folder, f'{version}-train')\n    lidar_path = os.path.join(root_folder, lidar_path)\n    assert os.path.isfile(lidar_path), f'Please download the complete Lyft ' \\\n        f'dataset and make sure {lidar_path} is present.'\n    points = np.fromfile(lidar_path, dtype=np.float32, count=-1)\n    try:\n        points.reshape([-1, 5])",
        "detail": "tools.data_converter.lyft_data_fixer",
        "documentation": {}
    },
    {
        "label": "parser",
        "kind": 5,
        "importPath": "tools.data_converter.lyft_data_fixer",
        "description": "tools.data_converter.lyft_data_fixer",
        "peekOfCode": "parser = argparse.ArgumentParser(description='Lyft dataset fixer arg parser')\nparser.add_argument(\n    '--root-folder',\n    type=str,\n    default='./data/lyft',\n    help='specify the root path of Lyft dataset')\nparser.add_argument(\n    '--version',\n    type=str,\n    default='v1.01',",
        "detail": "tools.data_converter.lyft_data_fixer",
        "documentation": {}
    },
    {
        "label": "args",
        "kind": 5,
        "importPath": "tools.data_converter.lyft_data_fixer",
        "description": "tools.data_converter.lyft_data_fixer",
        "peekOfCode": "args = parser.parse_args()\nif __name__ == '__main__':\n    fix_lyft(root_folder=args.root_folder, version=args.version)",
        "detail": "tools.data_converter.lyft_data_fixer",
        "documentation": {}
    },
    {
        "label": "parse_args",
        "kind": 2,
        "importPath": "tools.data_converter.nuimage_converter",
        "description": "tools.data_converter.nuimage_converter",
        "peekOfCode": "def parse_args():\n    parser = argparse.ArgumentParser(description='Data converter arg parser')\n    parser.add_argument(\n        '--data-root',\n        type=str,\n        default='./data/nuimages',\n        help='specify the root path of dataset')\n    parser.add_argument(\n        '--version',\n        type=str,",
        "detail": "tools.data_converter.nuimage_converter",
        "documentation": {}
    },
    {
        "label": "get_img_annos",
        "kind": 2,
        "importPath": "tools.data_converter.nuimage_converter",
        "description": "tools.data_converter.nuimage_converter",
        "peekOfCode": "def get_img_annos(nuim, img_info, cat2id, out_dir, data_root, seg_root):\n    \"\"\"Get semantic segmentation map for an image.\n    Args:\n        nuim (obj:`NuImages`): NuImages dataset object\n        img_info (dict): Meta information of img\n    Returns:\n        np.ndarray: Semantic segmentation map of the image\n    \"\"\"\n    sd_token = img_info['token']\n    image_id = img_info['id']",
        "detail": "tools.data_converter.nuimage_converter",
        "documentation": {}
    },
    {
        "label": "export_nuim_to_coco",
        "kind": 2,
        "importPath": "tools.data_converter.nuimage_converter",
        "description": "tools.data_converter.nuimage_converter",
        "peekOfCode": "def export_nuim_to_coco(nuim, data_root, out_dir, extra_tag, version, nproc):\n    print('Process category information')\n    categories = []\n    categories = [\n        dict(id=nus_categories.index(cat_name), name=cat_name)\n        for cat_name in nus_categories\n    ]\n    cat2id = {k_v['name']: k_v['id'] for k_v in categories}\n    images = []\n    print('Process image meta information...')",
        "detail": "tools.data_converter.nuimage_converter",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "tools.data_converter.nuimage_converter",
        "description": "tools.data_converter.nuimage_converter",
        "peekOfCode": "def main():\n    args = parse_args()\n    for version in args.version:\n        nuim = NuImages(\n            dataroot=args.data_root, version=version, verbose=True, lazy=True)\n        export_nuim_to_coco(nuim, args.data_root, args.out_dir, args.extra_tag,\n                            version, args.nproc)\nif __name__ == '__main__':\n    main()",
        "detail": "tools.data_converter.nuimage_converter",
        "documentation": {}
    },
    {
        "label": "nus_categories",
        "kind": 5,
        "importPath": "tools.data_converter.nuimage_converter",
        "description": "tools.data_converter.nuimage_converter",
        "peekOfCode": "nus_categories = ('car', 'truck', 'trailer', 'bus', 'construction_vehicle',\n                  'bicycle', 'motorcycle', 'pedestrian', 'traffic_cone',\n                  'barrier')\nNAME_MAPPING = {\n    'movable_object.barrier': 'barrier',\n    'vehicle.bicycle': 'bicycle',\n    'vehicle.bus.bendy': 'bus',\n    'vehicle.bus.rigid': 'bus',\n    'vehicle.car': 'car',\n    'vehicle.construction': 'construction_vehicle',",
        "detail": "tools.data_converter.nuimage_converter",
        "documentation": {}
    },
    {
        "label": "NAME_MAPPING",
        "kind": 5,
        "importPath": "tools.data_converter.nuimage_converter",
        "description": "tools.data_converter.nuimage_converter",
        "peekOfCode": "NAME_MAPPING = {\n    'movable_object.barrier': 'barrier',\n    'vehicle.bicycle': 'bicycle',\n    'vehicle.bus.bendy': 'bus',\n    'vehicle.bus.rigid': 'bus',\n    'vehicle.car': 'car',\n    'vehicle.construction': 'construction_vehicle',\n    'vehicle.motorcycle': 'motorcycle',\n    'human.pedestrian.adult': 'pedestrian',\n    'human.pedestrian.child': 'pedestrian',",
        "detail": "tools.data_converter.nuimage_converter",
        "documentation": {}
    },
    {
        "label": "create_nuscenes_infos",
        "kind": 2,
        "importPath": "tools.data_converter.nuscenes_converter",
        "description": "tools.data_converter.nuscenes_converter",
        "peekOfCode": "def create_nuscenes_infos(root_path,\n                          out_path,\n                          can_bus_root_path,\n                          info_prefix,\n                          version='v1.0-trainval',\n                          max_sweeps=10):\n    \"\"\"Create info file of nuscene dataset.\n    Given the raw data, generate its related info file in pkl format.\n    Args:\n        root_path (str): Path of the data root.",
        "detail": "tools.data_converter.nuscenes_converter",
        "documentation": {}
    },
    {
        "label": "get_available_scenes",
        "kind": 2,
        "importPath": "tools.data_converter.nuscenes_converter",
        "description": "tools.data_converter.nuscenes_converter",
        "peekOfCode": "def get_available_scenes(nusc):\n    \"\"\"Get available scenes from the input nuscenes class.\n    Given the raw data, get the information of available scenes for\n    further info generation.\n    Args:\n        nusc (class): Dataset class in the nuScenes dataset.\n    Returns:\n        available_scenes (list[dict]): List of basic information for the\n            available scenes.\n    \"\"\"",
        "detail": "tools.data_converter.nuscenes_converter",
        "documentation": {}
    },
    {
        "label": "obtain_sensor2top",
        "kind": 2,
        "importPath": "tools.data_converter.nuscenes_converter",
        "description": "tools.data_converter.nuscenes_converter",
        "peekOfCode": "def obtain_sensor2top(nusc,\n                      sensor_token,\n                      l2e_t,\n                      l2e_r_mat,\n                      e2g_t,\n                      e2g_r_mat,\n                      sensor_type='lidar'):\n    \"\"\"Obtain the info with RT matric from general sensor to Top LiDAR.\n    Args:\n        nusc (class): Dataset class in the nuScenes dataset.",
        "detail": "tools.data_converter.nuscenes_converter",
        "documentation": {}
    },
    {
        "label": "export_2d_annotation",
        "kind": 2,
        "importPath": "tools.data_converter.nuscenes_converter",
        "description": "tools.data_converter.nuscenes_converter",
        "peekOfCode": "def export_2d_annotation(root_path, info_path, version, mono3d=True):\n    \"\"\"Export 2d annotation from the info file and raw data.\n    Args:\n        root_path (str): Root path of the raw data.\n        info_path (str): Path of the info file.\n        version (str): Dataset version.\n        mono3d (bool): Whether to export mono3d annotation. Default: True.\n    \"\"\"\n    # get bbox annotations for camera\n    camera_types = [",
        "detail": "tools.data_converter.nuscenes_converter",
        "documentation": {}
    },
    {
        "label": "get_2d_boxes",
        "kind": 2,
        "importPath": "tools.data_converter.nuscenes_converter",
        "description": "tools.data_converter.nuscenes_converter",
        "peekOfCode": "def get_2d_boxes(nusc,\n                 sample_data_token: str,\n                 visibilities: List[str],\n                 mono3d=True):\n    \"\"\"Get the 2D annotation records for a given `sample_data_token`.\n    Args:\n        sample_data_token (str): Sample data token belonging to a camera \\\n            keyframe.\n        visibilities (list[str]): Visibility filter.\n        mono3d (bool): Whether to get boxes with mono3d annotation.",
        "detail": "tools.data_converter.nuscenes_converter",
        "documentation": {}
    },
    {
        "label": "post_process_coords",
        "kind": 2,
        "importPath": "tools.data_converter.nuscenes_converter",
        "description": "tools.data_converter.nuscenes_converter",
        "peekOfCode": "def post_process_coords(\n    corner_coords: List, imsize: Tuple[int, int] = (1600, 900)\n) -> Union[Tuple[float, float, float, float], None]:\n    \"\"\"Get the intersection of the convex hull of the reprojected bbox corners\n    and the image canvas, return None if no intersection.\n    Args:\n        corner_coords (list[int]): Corner coordinates of reprojected\n            bounding box.\n        imsize (tuple[int]): Size of the image canvas.\n    Return:",
        "detail": "tools.data_converter.nuscenes_converter",
        "documentation": {}
    },
    {
        "label": "generate_record",
        "kind": 2,
        "importPath": "tools.data_converter.nuscenes_converter",
        "description": "tools.data_converter.nuscenes_converter",
        "peekOfCode": "def generate_record(ann_rec: dict, x1: float, y1: float, x2: float, y2: float,\n                    sample_data_token: str, filename: str) -> OrderedDict:\n    \"\"\"Generate one 2D annotation record given various informations on top of\n    the 2D bounding box coordinates.\n    Args:\n        ann_rec (dict): Original 3d annotation record.\n        x1 (float): Minimum value of the x coordinate.\n        y1 (float): Minimum value of the y coordinate.\n        x2 (float): Maximum value of the x coordinate.\n        y2 (float): Maximum value of the y coordinate.",
        "detail": "tools.data_converter.nuscenes_converter",
        "documentation": {}
    },
    {
        "label": "nus_categories",
        "kind": 5,
        "importPath": "tools.data_converter.nuscenes_converter",
        "description": "tools.data_converter.nuscenes_converter",
        "peekOfCode": "nus_categories = ('car', 'truck', 'trailer', 'bus', 'construction_vehicle',\n                  'bicycle', 'motorcycle', 'pedestrian', 'traffic_cone',\n                  'barrier')\nnus_attributes = ('cycle.with_rider', 'cycle.without_rider',\n                  'pedestrian.moving', 'pedestrian.standing',\n                  'pedestrian.sitting_lying_down', 'vehicle.moving',\n                  'vehicle.parked', 'vehicle.stopped', 'None')\ndef create_nuscenes_infos(root_path,\n                          out_path,\n                          can_bus_root_path,",
        "detail": "tools.data_converter.nuscenes_converter",
        "documentation": {}
    },
    {
        "label": "nus_attributes",
        "kind": 5,
        "importPath": "tools.data_converter.nuscenes_converter",
        "description": "tools.data_converter.nuscenes_converter",
        "peekOfCode": "nus_attributes = ('cycle.with_rider', 'cycle.without_rider',\n                  'pedestrian.moving', 'pedestrian.standing',\n                  'pedestrian.sitting_lying_down', 'vehicle.moving',\n                  'vehicle.parked', 'vehicle.stopped', 'None')\ndef create_nuscenes_infos(root_path,\n                          out_path,\n                          can_bus_root_path,\n                          info_prefix,\n                          version='v1.0-trainval',\n                          max_sweeps=10):",
        "detail": "tools.data_converter.nuscenes_converter",
        "documentation": {}
    },
    {
        "label": "S3DISData",
        "kind": 6,
        "importPath": "tools.data_converter.s3dis_data_utils",
        "description": "tools.data_converter.s3dis_data_utils",
        "peekOfCode": "class S3DISData(object):\n    \"\"\"S3DIS data.\n    Generate s3dis infos for s3dis_converter.\n    Args:\n        root_path (str): Root path of the raw data.\n        split (str): Set split type of the data. Default: 'Area_1'.\n    \"\"\"\n    def __init__(self, root_path, split='Area_1'):\n        self.root_dir = root_path\n        self.split = split",
        "detail": "tools.data_converter.s3dis_data_utils",
        "documentation": {}
    },
    {
        "label": "S3DISSegData",
        "kind": 6,
        "importPath": "tools.data_converter.s3dis_data_utils",
        "description": "tools.data_converter.s3dis_data_utils",
        "peekOfCode": "class S3DISSegData(object):\n    \"\"\"S3DIS dataset used to generate infos for semantic segmentation task.\n    Args:\n        data_root (str): Root path of the raw data.\n        ann_file (str): The generated scannet infos.\n        split (str): Set split type of the data. Default: 'train'.\n        num_points (int): Number of points in each data input. Default: 8192.\n        label_weight_func (function): Function to compute the label weight.\n            Default: None.\n    \"\"\"",
        "detail": "tools.data_converter.s3dis_data_utils",
        "documentation": {}
    },
    {
        "label": "ScanNetData",
        "kind": 6,
        "importPath": "tools.data_converter.scannet_data_utils",
        "description": "tools.data_converter.scannet_data_utils",
        "peekOfCode": "class ScanNetData(object):\n    \"\"\"ScanNet data.\n    Generate scannet infos for scannet_converter.\n    Args:\n        root_path (str): Root path of the raw data.\n        split (str): Set split type of the data. Default: 'train'.\n    \"\"\"\n    def __init__(self, root_path, split='train'):\n        self.root_dir = root_path\n        self.split = split",
        "detail": "tools.data_converter.scannet_data_utils",
        "documentation": {}
    },
    {
        "label": "ScanNetSegData",
        "kind": 6,
        "importPath": "tools.data_converter.scannet_data_utils",
        "description": "tools.data_converter.scannet_data_utils",
        "peekOfCode": "class ScanNetSegData(object):\n    \"\"\"ScanNet dataset used to generate infos for semantic segmentation task.\n    Args:\n        data_root (str): Root path of the raw data.\n        ann_file (str): The generated scannet infos.\n        split (str): Set split type of the data. Default: 'train'.\n        num_points (int): Number of points in each data input. Default: 8192.\n        label_weight_func (function): Function to compute the label weight.\n            Default: None.\n    \"\"\"",
        "detail": "tools.data_converter.scannet_data_utils",
        "documentation": {}
    },
    {
        "label": "SUNRGBDInstance",
        "kind": 6,
        "importPath": "tools.data_converter.sunrgbd_data_utils",
        "description": "tools.data_converter.sunrgbd_data_utils",
        "peekOfCode": "class SUNRGBDInstance(object):\n    def __init__(self, line):\n        data = line.split(' ')\n        data[1:] = [float(x) for x in data[1:]]\n        self.classname = data[0]\n        self.xmin = data[1]\n        self.ymin = data[2]\n        self.xmax = data[1] + data[3]\n        self.ymax = data[2] + data[4]\n        self.box2d = np.array([self.xmin, self.ymin, self.xmax, self.ymax])",
        "detail": "tools.data_converter.sunrgbd_data_utils",
        "documentation": {}
    },
    {
        "label": "SUNRGBDData",
        "kind": 6,
        "importPath": "tools.data_converter.sunrgbd_data_utils",
        "description": "tools.data_converter.sunrgbd_data_utils",
        "peekOfCode": "class SUNRGBDData(object):\n    \"\"\"SUNRGBD data.\n    Generate scannet infos for sunrgbd_converter.\n    Args:\n        root_path (str): Root path of the raw data.\n        split (str): Set split type of the data. Default: 'train'.\n        use_v1 (bool): Whether to use v1. Default: False.\n    \"\"\"\n    def __init__(self, root_path, split='train', use_v1=False):\n        self.root_dir = root_path",
        "detail": "tools.data_converter.sunrgbd_data_utils",
        "documentation": {}
    },
    {
        "label": "random_sampling",
        "kind": 2,
        "importPath": "tools.data_converter.sunrgbd_data_utils",
        "description": "tools.data_converter.sunrgbd_data_utils",
        "peekOfCode": "def random_sampling(points, num_points, replace=None, return_choices=False):\n    \"\"\"Random sampling.\n    Sampling point cloud to a certain number of points.\n    Args:\n        points (ndarray): Point cloud.\n        num_points (int): The number of samples.\n        replace (bool): Whether the sample is with or without replacement.\n        return_choices (bool): Whether to return choices.\n    Returns:\n        points (ndarray): Point cloud after sampling.",
        "detail": "tools.data_converter.sunrgbd_data_utils",
        "documentation": {}
    },
    {
        "label": "Waymo2KITTI",
        "kind": 6,
        "importPath": "tools.data_converter.waymo_converter",
        "description": "tools.data_converter.waymo_converter",
        "peekOfCode": "class Waymo2KITTI(object):\n    \"\"\"Waymo to KITTI converter.\n    This class serves as the converter to change the waymo raw data to KITTI\n    format.\n    Args:\n        load_dir (str): Directory to load waymo raw data.\n        save_dir (str): Directory to save data in KITTI format.\n        prefix (str): Prefix of filename. In general, 0 for training, 1 for\n            validation and 2 for testing.\n        workers (str): Number of workers for the parallel process.",
        "detail": "tools.data_converter.waymo_converter",
        "documentation": {}
    },
    {
        "label": "parse_args",
        "kind": 2,
        "importPath": "tools.fp16.train",
        "description": "tools.fp16.train",
        "peekOfCode": "def parse_args():\n    parser = argparse.ArgumentParser(description='Train a detector')\n    parser.add_argument('config', help='train config file path')\n    parser.add_argument('--work-dir', help='the dir to save logs and models')\n    parser.add_argument(\n        '--resume-from', help='the checkpoint file to resume from')\n    parser.add_argument(\n        '--no-validate',\n        action='store_true',\n        help='whether not to evaluate the checkpoint during training')",
        "detail": "tools.fp16.train",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "tools.fp16.train",
        "description": "tools.fp16.train",
        "peekOfCode": "def main():\n    args = parse_args()\n    cfg = Config.fromfile(args.config)\n    if args.cfg_options is not None:\n        cfg.merge_from_dict(args.cfg_options)\n    # import modules from string list.\n    if cfg.get('custom_imports', None):\n        from mmcv.utils import import_modules_from_strings\n        import_modules_from_strings(**cfg['custom_imports'])\n    # import modules from plguin/xx, registry will be updated",
        "detail": "tools.fp16.train",
        "documentation": {}
    },
    {
        "label": "parse_args",
        "kind": 2,
        "importPath": "tools.misc.browse_dataset",
        "description": "tools.misc.browse_dataset",
        "peekOfCode": "def parse_args():\n    parser = argparse.ArgumentParser(description='Browse a dataset')\n    parser.add_argument('config', help='train config file path')\n    parser.add_argument(\n        '--skip-type',\n        type=str,\n        nargs='+',\n        default=['Normalize'],\n        help='skip some useless pipeline')\n    parser.add_argument(",
        "detail": "tools.misc.browse_dataset",
        "documentation": {}
    },
    {
        "label": "build_data_cfg",
        "kind": 2,
        "importPath": "tools.misc.browse_dataset",
        "description": "tools.misc.browse_dataset",
        "peekOfCode": "def build_data_cfg(config_path, skip_type, cfg_options):\n    \"\"\"Build data config for loading visualization data.\"\"\"\n    cfg = Config.fromfile(config_path)\n    if cfg_options is not None:\n        cfg.merge_from_dict(cfg_options)\n    # import modules from string list.\n    if cfg.get('custom_imports', None):\n        from mmcv.utils import import_modules_from_strings\n        import_modules_from_strings(**cfg['custom_imports'])\n    # extract inner dataset of `RepeatDataset` as `cfg.data.train`",
        "detail": "tools.misc.browse_dataset",
        "documentation": {}
    },
    {
        "label": "to_depth_mode",
        "kind": 2,
        "importPath": "tools.misc.browse_dataset",
        "description": "tools.misc.browse_dataset",
        "peekOfCode": "def to_depth_mode(points, bboxes):\n    \"\"\"Convert points and bboxes to Depth Coord and Depth Box mode.\"\"\"\n    if points is not None:\n        points = Coord3DMode.convert_point(points.copy(), Coord3DMode.LIDAR,\n                                           Coord3DMode.DEPTH)\n    if bboxes is not None:\n        bboxes = Box3DMode.convert(bboxes.clone(), Box3DMode.LIDAR,\n                                   Box3DMode.DEPTH)\n    return points, bboxes\ndef show_det_data(idx, dataset, out_dir, filename, show=False):",
        "detail": "tools.misc.browse_dataset",
        "documentation": {}
    },
    {
        "label": "show_det_data",
        "kind": 2,
        "importPath": "tools.misc.browse_dataset",
        "description": "tools.misc.browse_dataset",
        "peekOfCode": "def show_det_data(idx, dataset, out_dir, filename, show=False):\n    \"\"\"Visualize 3D point cloud and 3D bboxes.\"\"\"\n    example = dataset.prepare_train_data(idx)\n    points = example['points']._data.numpy()\n    gt_bboxes = dataset.get_ann_info(idx)['gt_bboxes_3d'].tensor\n    if dataset.box_mode_3d != Box3DMode.DEPTH:\n        points, gt_bboxes = to_depth_mode(points, gt_bboxes)\n    show_result(\n        points,\n        gt_bboxes.clone(),",
        "detail": "tools.misc.browse_dataset",
        "documentation": {}
    },
    {
        "label": "show_seg_data",
        "kind": 2,
        "importPath": "tools.misc.browse_dataset",
        "description": "tools.misc.browse_dataset",
        "peekOfCode": "def show_seg_data(idx, dataset, out_dir, filename, show=False):\n    \"\"\"Visualize 3D point cloud and segmentation mask.\"\"\"\n    example = dataset.prepare_train_data(idx)\n    points = example['points']._data.numpy()\n    gt_seg = example['pts_semantic_mask']._data.numpy()\n    show_seg_result(\n        points,\n        gt_seg.copy(),\n        None,\n        out_dir,",
        "detail": "tools.misc.browse_dataset",
        "documentation": {}
    },
    {
        "label": "show_proj_bbox_img",
        "kind": 2,
        "importPath": "tools.misc.browse_dataset",
        "description": "tools.misc.browse_dataset",
        "peekOfCode": "def show_proj_bbox_img(idx,\n                       dataset,\n                       out_dir,\n                       filename,\n                       show=False,\n                       is_nus_mono=False):\n    \"\"\"Visualize 3D bboxes on 2D image by projection.\"\"\"\n    try:\n        example = dataset.prepare_train_data(idx)\n    except AttributeError:  # for Mono-3D datasets",
        "detail": "tools.misc.browse_dataset",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "tools.misc.browse_dataset",
        "description": "tools.misc.browse_dataset",
        "peekOfCode": "def main():\n    args = parse_args()\n    if args.output_dir is not None:\n        mkdir_or_exist(args.output_dir)\n    cfg = build_data_cfg(args.config, args.skip_type, args.cfg_options)\n    try:\n        dataset = build_dataset(\n            cfg.data.train, default_args=dict(filter_empty_gt=False))\n    except TypeError:  # seg dataset doesn't have `filter_empty_gt` key\n        dataset = build_dataset(cfg.data.train)",
        "detail": "tools.misc.browse_dataset",
        "documentation": {}
    },
    {
        "label": "fuse_conv_bn",
        "kind": 2,
        "importPath": "tools.misc.fuse_conv_bn",
        "description": "tools.misc.fuse_conv_bn",
        "peekOfCode": "def fuse_conv_bn(conv, bn):\n    \"\"\"During inference, the functionary of batch norm layers is turned off but\n    only the mean and var alone channels are used, which exposes the chance to\n    fuse it with the preceding conv layers to save computations and simplify\n    network structures.\"\"\"\n    conv_w = conv.weight\n    conv_b = conv.bias if conv.bias is not None else torch.zeros_like(\n        bn.running_mean)\n    factor = bn.weight / torch.sqrt(bn.running_var + bn.eps)\n    conv.weight = nn.Parameter(conv_w *",
        "detail": "tools.misc.fuse_conv_bn",
        "documentation": {}
    },
    {
        "label": "fuse_module",
        "kind": 2,
        "importPath": "tools.misc.fuse_conv_bn",
        "description": "tools.misc.fuse_conv_bn",
        "peekOfCode": "def fuse_module(m):\n    last_conv = None\n    last_conv_name = None\n    for name, child in m.named_children():\n        if isinstance(child, (nn.BatchNorm2d, nn.SyncBatchNorm)):\n            if last_conv is None:  # only fuse BN that is after Conv\n                continue\n            fused_conv = fuse_conv_bn(last_conv, child)\n            m._modules[last_conv_name] = fused_conv\n            # To reduce changes, set BN as Identity instead of deleting it.",
        "detail": "tools.misc.fuse_conv_bn",
        "documentation": {}
    },
    {
        "label": "parse_args",
        "kind": 2,
        "importPath": "tools.misc.fuse_conv_bn",
        "description": "tools.misc.fuse_conv_bn",
        "peekOfCode": "def parse_args():\n    parser = argparse.ArgumentParser(\n        description='fuse Conv and BN layers in a model')\n    parser.add_argument('config', help='config file path')\n    parser.add_argument('checkpoint', help='checkpoint file path')\n    parser.add_argument('out', help='output path of the converted model')\n    args = parser.parse_args()\n    return args\ndef main():\n    args = parse_args()",
        "detail": "tools.misc.fuse_conv_bn",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "tools.misc.fuse_conv_bn",
        "description": "tools.misc.fuse_conv_bn",
        "peekOfCode": "def main():\n    args = parse_args()\n    # build the model from a config file and a checkpoint file\n    model = init_model(args.config, args.checkpoint)\n    # fuse conv and bn layers of the model\n    fused_model = fuse_module(model)\n    save_checkpoint(fused_model, args.out)\nif __name__ == '__main__':\n    main()",
        "detail": "tools.misc.fuse_conv_bn",
        "documentation": {}
    },
    {
        "label": "parse_args",
        "kind": 2,
        "importPath": "tools.misc.print_config",
        "description": "tools.misc.print_config",
        "peekOfCode": "def parse_args():\n    parser = argparse.ArgumentParser(description='Print the whole config')\n    parser.add_argument('config', help='config file path')\n    parser.add_argument(\n        '--options', nargs='+', action=DictAction, help='arguments in dict')\n    args = parser.parse_args()\n    return args\ndef main():\n    args = parse_args()\n    cfg = Config.fromfile(args.config)",
        "detail": "tools.misc.print_config",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "tools.misc.print_config",
        "description": "tools.misc.print_config",
        "peekOfCode": "def main():\n    args = parse_args()\n    cfg = Config.fromfile(args.config)\n    if args.options is not None:\n        cfg.merge_from_dict(args.options)\n    print(f'Config:\\n{cfg.pretty_text}')\nif __name__ == '__main__':\n    main()",
        "detail": "tools.misc.print_config",
        "documentation": {}
    },
    {
        "label": "parse_args",
        "kind": 2,
        "importPath": "tools.misc.visualize_results",
        "description": "tools.misc.visualize_results",
        "peekOfCode": "def parse_args():\n    parser = argparse.ArgumentParser(\n        description='MMDet3D visualize the results')\n    parser.add_argument('config', help='test config file path')\n    parser.add_argument('--result', help='results file in pickle format')\n    parser.add_argument(\n        '--show-dir', help='directory where visualize results will be saved')\n    args = parser.parse_args()\n    return args\ndef main():",
        "detail": "tools.misc.visualize_results",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "tools.misc.visualize_results",
        "description": "tools.misc.visualize_results",
        "peekOfCode": "def main():\n    args = parse_args()\n    if args.result is not None and \\\n            not args.result.endswith(('.pkl', '.pickle')):\n        raise ValueError('The results file must be a pkl file.')\n    cfg = Config.fromfile(args.config)\n    cfg.data.test.test_mode = True\n    # build the dataset\n    dataset = build_dataset(cfg.data.test)\n    results = mmcv.load(args.result)",
        "detail": "tools.misc.visualize_results",
        "documentation": {}
    },
    {
        "label": "parse_args",
        "kind": 2,
        "importPath": "tools.model_converters.convert_votenet_checkpoints",
        "description": "tools.model_converters.convert_votenet_checkpoints",
        "peekOfCode": "def parse_args():\n    parser = argparse.ArgumentParser(\n        description='MMDet3D upgrade model version(before v0.6.0) of VoteNet')\n    parser.add_argument('checkpoint', help='checkpoint file')\n    parser.add_argument('--out', help='path of the output checkpoint file')\n    args = parser.parse_args()\n    return args\ndef parse_config(config_strings):\n    \"\"\"Parse config from strings.\n    Args:",
        "detail": "tools.model_converters.convert_votenet_checkpoints",
        "documentation": {}
    },
    {
        "label": "parse_config",
        "kind": 2,
        "importPath": "tools.model_converters.convert_votenet_checkpoints",
        "description": "tools.model_converters.convert_votenet_checkpoints",
        "peekOfCode": "def parse_config(config_strings):\n    \"\"\"Parse config from strings.\n    Args:\n        config_strings (string): strings of model config.\n    Returns:\n        Config: model config\n    \"\"\"\n    temp_file = tempfile.NamedTemporaryFile()\n    config_path = f'{temp_file.name}.py'\n    with open(config_path, 'w') as f:",
        "detail": "tools.model_converters.convert_votenet_checkpoints",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "tools.model_converters.convert_votenet_checkpoints",
        "description": "tools.model_converters.convert_votenet_checkpoints",
        "peekOfCode": "def main():\n    \"\"\"Convert keys in checkpoints for VoteNet.\n    There can be some breaking changes during the development of mmdetection3d,\n    and this tool is used for upgrading checkpoints trained with old versions\n    (before v0.6.0) to the latest one.\n    \"\"\"\n    args = parse_args()\n    checkpoint = torch.load(args.checkpoint)\n    cfg = parse_config(checkpoint['meta']['config'])\n    # Build the model and load checkpoint",
        "detail": "tools.model_converters.convert_votenet_checkpoints",
        "documentation": {}
    },
    {
        "label": "parse_args",
        "kind": 2,
        "importPath": "tools.model_converters.publish_model",
        "description": "tools.model_converters.publish_model",
        "peekOfCode": "def parse_args():\n    parser = argparse.ArgumentParser(\n        description='Process a checkpoint to be published')\n    parser.add_argument('in_file', help='input checkpoint filename')\n    parser.add_argument('out_file', help='output checkpoint filename')\n    args = parser.parse_args()\n    return args\ndef process_checkpoint(in_file, out_file):\n    checkpoint = torch.load(in_file, map_location='cpu')\n    # remove optimizer for smaller file size",
        "detail": "tools.model_converters.publish_model",
        "documentation": {}
    },
    {
        "label": "process_checkpoint",
        "kind": 2,
        "importPath": "tools.model_converters.publish_model",
        "description": "tools.model_converters.publish_model",
        "peekOfCode": "def process_checkpoint(in_file, out_file):\n    checkpoint = torch.load(in_file, map_location='cpu')\n    # remove optimizer for smaller file size\n    if 'optimizer' in checkpoint:\n        del checkpoint['optimizer']\n    # if it is necessary to remove some sensitive data in checkpoint['meta'],\n    # add the code here.\n    torch.save(checkpoint, out_file)\n    sha = subprocess.check_output(['sha256sum', out_file]).decode()\n    final_file = out_file.rstrip('.pth') + '-{}.pth'.format(sha[:8])",
        "detail": "tools.model_converters.publish_model",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "tools.model_converters.publish_model",
        "description": "tools.model_converters.publish_model",
        "peekOfCode": "def main():\n    args = parse_args()\n    process_checkpoint(args.in_file, args.out_file)\nif __name__ == '__main__':\n    main()",
        "detail": "tools.model_converters.publish_model",
        "documentation": {}
    },
    {
        "label": "convert_stem",
        "kind": 2,
        "importPath": "tools.model_converters.regnet2mmdet",
        "description": "tools.model_converters.regnet2mmdet",
        "peekOfCode": "def convert_stem(model_key, model_weight, state_dict, converted_names):\n    new_key = model_key.replace('stem.conv', 'conv1')\n    new_key = new_key.replace('stem.bn', 'bn1')\n    state_dict[new_key] = model_weight\n    converted_names.add(model_key)\n    print(f'Convert {model_key} to {new_key}')\ndef convert_head(model_key, model_weight, state_dict, converted_names):\n    new_key = model_key.replace('head.fc', 'fc')\n    state_dict[new_key] = model_weight\n    converted_names.add(model_key)",
        "detail": "tools.model_converters.regnet2mmdet",
        "documentation": {}
    },
    {
        "label": "convert_head",
        "kind": 2,
        "importPath": "tools.model_converters.regnet2mmdet",
        "description": "tools.model_converters.regnet2mmdet",
        "peekOfCode": "def convert_head(model_key, model_weight, state_dict, converted_names):\n    new_key = model_key.replace('head.fc', 'fc')\n    state_dict[new_key] = model_weight\n    converted_names.add(model_key)\n    print(f'Convert {model_key} to {new_key}')\ndef convert_reslayer(model_key, model_weight, state_dict, converted_names):\n    split_keys = model_key.split('.')\n    layer, block, module = split_keys[:3]\n    block_id = int(block[1:])\n    layer_name = f'layer{int(layer[1:])}'",
        "detail": "tools.model_converters.regnet2mmdet",
        "documentation": {}
    },
    {
        "label": "convert_reslayer",
        "kind": 2,
        "importPath": "tools.model_converters.regnet2mmdet",
        "description": "tools.model_converters.regnet2mmdet",
        "peekOfCode": "def convert_reslayer(model_key, model_weight, state_dict, converted_names):\n    split_keys = model_key.split('.')\n    layer, block, module = split_keys[:3]\n    block_id = int(block[1:])\n    layer_name = f'layer{int(layer[1:])}'\n    block_name = f'{block_id - 1}'\n    if block_id == 1 and module == 'bn':\n        new_key = f'{layer_name}.{block_name}.downsample.1.{split_keys[-1]}'\n    elif block_id == 1 and module == 'proj':\n        new_key = f'{layer_name}.{block_name}.downsample.0.{split_keys[-1]}'",
        "detail": "tools.model_converters.regnet2mmdet",
        "documentation": {}
    },
    {
        "label": "convert",
        "kind": 2,
        "importPath": "tools.model_converters.regnet2mmdet",
        "description": "tools.model_converters.regnet2mmdet",
        "peekOfCode": "def convert(src, dst):\n    \"\"\"Convert keys in pycls pretrained RegNet models to mmdet style.\"\"\"\n    # load caffe model\n    regnet_model = torch.load(src)\n    blobs = regnet_model['model_state']\n    # convert to pytorch style\n    state_dict = OrderedDict()\n    converted_names = set()\n    for key, weight in blobs.items():\n        if 'stem' in key:",
        "detail": "tools.model_converters.regnet2mmdet",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "tools.model_converters.regnet2mmdet",
        "description": "tools.model_converters.regnet2mmdet",
        "peekOfCode": "def main():\n    parser = argparse.ArgumentParser(description='Convert model keys')\n    parser.add_argument('src', help='src detectron model path')\n    parser.add_argument('dst', help='save path')\n    args = parser.parse_args()\n    convert(args.src, args.dst)\nif __name__ == '__main__':\n    main()",
        "detail": "tools.model_converters.regnet2mmdet",
        "documentation": {}
    },
    {
        "label": "kitti_data_prep",
        "kind": 2,
        "importPath": "tools.create_data",
        "description": "tools.create_data",
        "peekOfCode": "def kitti_data_prep(root_path, info_prefix, version, out_dir):\n    \"\"\"Prepare data related to Kitti dataset.\n    Related data consists of '.pkl' files recording basic infos,\n    2D annotations and groundtruth database.\n    Args:\n        root_path (str): Path of dataset root.\n        info_prefix (str): The prefix of info filenames.\n        version (str): Dataset version.\n        out_dir (str): Output directory of the groundtruth database info.\n    \"\"\"",
        "detail": "tools.create_data",
        "documentation": {}
    },
    {
        "label": "nuscenes_data_prep",
        "kind": 2,
        "importPath": "tools.create_data",
        "description": "tools.create_data",
        "peekOfCode": "def nuscenes_data_prep(root_path,\n                       can_bus_root_path,\n                       info_prefix,\n                       version,\n                       dataset_name,\n                       out_dir,\n                       max_sweeps=10):\n    \"\"\"Prepare data related to nuScenes dataset.\n    Related data consists of '.pkl' files recording basic infos,\n    2D annotations and groundtruth database.",
        "detail": "tools.create_data",
        "documentation": {}
    },
    {
        "label": "lyft_data_prep",
        "kind": 2,
        "importPath": "tools.create_data",
        "description": "tools.create_data",
        "peekOfCode": "def lyft_data_prep(root_path, info_prefix, version, max_sweeps=10):\n    \"\"\"Prepare data related to Lyft dataset.\n    Related data consists of '.pkl' files recording basic infos.\n    Although the ground truth database and 2D annotations are not used in\n    Lyft, it can also be generated like nuScenes.\n    Args:\n        root_path (str): Path of dataset root.\n        info_prefix (str): The prefix of info filenames.\n        version (str): Dataset version.\n        max_sweeps (int, optional): Number of input consecutive frames.",
        "detail": "tools.create_data",
        "documentation": {}
    },
    {
        "label": "scannet_data_prep",
        "kind": 2,
        "importPath": "tools.create_data",
        "description": "tools.create_data",
        "peekOfCode": "def scannet_data_prep(root_path, info_prefix, out_dir, workers):\n    \"\"\"Prepare the info file for scannet dataset.\n    Args:\n        root_path (str): Path of dataset root.\n        info_prefix (str): The prefix of info filenames.\n        out_dir (str): Output directory of the generated info file.\n        workers (int): Number of threads to be used.\n    \"\"\"\n    indoor.create_indoor_info_file(\n        root_path, info_prefix, out_dir, workers=workers)",
        "detail": "tools.create_data",
        "documentation": {}
    },
    {
        "label": "s3dis_data_prep",
        "kind": 2,
        "importPath": "tools.create_data",
        "description": "tools.create_data",
        "peekOfCode": "def s3dis_data_prep(root_path, info_prefix, out_dir, workers):\n    \"\"\"Prepare the info file for s3dis dataset.\n    Args:\n        root_path (str): Path of dataset root.\n        info_prefix (str): The prefix of info filenames.\n        out_dir (str): Output directory of the generated info file.\n        workers (int): Number of threads to be used.\n    \"\"\"\n    indoor.create_indoor_info_file(\n        root_path, info_prefix, out_dir, workers=workers)",
        "detail": "tools.create_data",
        "documentation": {}
    },
    {
        "label": "sunrgbd_data_prep",
        "kind": 2,
        "importPath": "tools.create_data",
        "description": "tools.create_data",
        "peekOfCode": "def sunrgbd_data_prep(root_path, info_prefix, out_dir, workers):\n    \"\"\"Prepare the info file for sunrgbd dataset.\n    Args:\n        root_path (str): Path of dataset root.\n        info_prefix (str): The prefix of info filenames.\n        out_dir (str): Output directory of the generated info file.\n        workers (int): Number of threads to be used.\n    \"\"\"\n    indoor.create_indoor_info_file(\n        root_path, info_prefix, out_dir, workers=workers)",
        "detail": "tools.create_data",
        "documentation": {}
    },
    {
        "label": "waymo_data_prep",
        "kind": 2,
        "importPath": "tools.create_data",
        "description": "tools.create_data",
        "peekOfCode": "def waymo_data_prep(root_path,\n                    info_prefix,\n                    version,\n                    out_dir,\n                    workers,\n                    max_sweeps=5):\n    \"\"\"Prepare the info file for waymo dataset.\n    Args:\n        root_path (str): Path of dataset root.\n        info_prefix (str): The prefix of info filenames.",
        "detail": "tools.create_data",
        "documentation": {}
    },
    {
        "label": "parser",
        "kind": 5,
        "importPath": "tools.create_data",
        "description": "tools.create_data",
        "peekOfCode": "parser = argparse.ArgumentParser(description='Data converter arg parser')\nparser.add_argument('dataset', metavar='kitti', help='name of the dataset')\nparser.add_argument(\n    '--root-path',\n    type=str,\n    default='./data/kitti',\n    help='specify the root path of dataset')\nparser.add_argument(\n    '--canbus',\n    type=str,",
        "detail": "tools.create_data",
        "documentation": {}
    },
    {
        "label": "args",
        "kind": 5,
        "importPath": "tools.create_data",
        "description": "tools.create_data",
        "peekOfCode": "args = parser.parse_args()\nif __name__ == '__main__':\n    if args.dataset == 'kitti':\n        kitti_data_prep(\n            root_path=args.root_path,\n            info_prefix=args.extra_tag,\n            version=args.version,\n            out_dir=args.out_dir)\n    elif args.dataset == 'nuscenes' and args.version != 'v1.0-mini':\n        train_version = f'{args.version}-trainval'",
        "detail": "tools.create_data",
        "documentation": {}
    },
    {
        "label": "parse_args",
        "kind": 2,
        "importPath": "tools.test",
        "description": "tools.test",
        "peekOfCode": "def parse_args():\n    parser = argparse.ArgumentParser(\n        description='MMDet test (and eval) a model')\n    parser.add_argument('config', help='test config file path')\n    parser.add_argument('checkpoint', help='checkpoint file')\n    parser.add_argument('--out', help='output result file in pickle format')\n    parser.add_argument(\n        '--fuse-conv-bn',\n        action='store_true',\n        help='Whether to fuse conv and bn, this will slightly increase'",
        "detail": "tools.test",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "tools.test",
        "description": "tools.test",
        "peekOfCode": "def main():\n    args = parse_args()\n    assert args.out or args.eval or args.format_only or args.show \\\n        or args.show_dir, \\\n        ('Please specify at least one operation (save/eval/format/show the '\n         'results / save the results) with the argument \"--out\", \"--eval\"'\n         ', \"--format-only\", \"--show\" or \"--show-dir\"')\n    if args.eval and args.format_only:\n        raise ValueError('--eval and --format_only cannot be both specified')\n    if args.out is not None and not args.out.endswith(('.pkl', '.pickle')):",
        "detail": "tools.test",
        "documentation": {}
    },
    {
        "label": "parse_args",
        "kind": 2,
        "importPath": "tools.train",
        "description": "tools.train",
        "peekOfCode": "def parse_args():\n    parser = argparse.ArgumentParser(description='Train a detector')\n    parser.add_argument('config', help='train config file path')\n    parser.add_argument('--work-dir', help='the dir to save logs and models')\n    parser.add_argument(\n        '--resume-from', help='the checkpoint file to resume from')\n    parser.add_argument(\n        '--no-validate',\n        action='store_true',\n        help='whether not to evaluate the checkpoint during training')",
        "detail": "tools.train",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "tools.train",
        "description": "tools.train",
        "peekOfCode": "def main():\n    args = parse_args()\n    cfg = Config.fromfile(args.config)\n    if args.cfg_options is not None:\n        cfg.merge_from_dict(args.cfg_options)\n    # import modules from string list.\n    if cfg.get('custom_imports', None):\n        from mmcv.utils import import_modules_from_strings\n        import_modules_from_strings(**cfg['custom_imports'])\n    # import modules from plguin/xx, registry will be updated",
        "detail": "tools.train",
        "documentation": {}
    }
]