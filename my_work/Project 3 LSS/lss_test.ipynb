{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "依次执行下面的cells，通过可视化验证你的实现是否正确"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from PIL import Image\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "from exercises.tool import gen_dx_bx, denormalize_img, add_ego\n",
    "from exercises.models import compile_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H=900\n",
    "W=1600\n",
    "resize_lim=(0.193, 0.225)\n",
    "final_dim=(128, 352)\n",
    "bot_pct_lim=(0.0, 0.22)\n",
    "rot_lim=(-5.4, 5.4)\n",
    "rand_flip=True\n",
    "\n",
    "xbound=[-50.0, 50.0, 0.5]\n",
    "ybound=[-50.0, 50.0, 0.5]\n",
    "zbound=[-10.0, 10.0, 20.0]\n",
    "dbound=[4.0, 45.0, 1.0]\n",
    "\n",
    "grid_conf = {\n",
    "    'xbound': xbound,\n",
    "    'ybound': ybound,\n",
    "    'zbound': zbound,\n",
    "    'dbound': dbound,\n",
    "}\n",
    "cams = ['CAM_FRONT_LEFT', 'CAM_FRONT', 'CAM_FRONT_RIGHT',\n",
    "    'CAM_BACK_LEFT', 'CAM_BACK', 'CAM_BACK_RIGHT']\n",
    "\n",
    "data_aug_conf = {\n",
    "                'resize_lim': resize_lim,\n",
    "                'final_dim': final_dim,\n",
    "                'rot_lim': rot_lim,\n",
    "                'H': H, 'W': W,\n",
    "                'rand_flip': rand_flip,\n",
    "                'bot_pct_lim': bot_pct_lim,\n",
    "                'cams': cams,\n",
    "                'Ncams': 5,\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize lss model\n",
    "model = compile_model(grid_conf, data_aug_conf, outC=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`model525000.pt`为我们提供的预训练好的BEV车辆分割模型权重，加载模型权重："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path='model525000.pt'\n",
    "print('loading', model_path)\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "gpuid=0\n",
    "device = torch.device('cpu') if gpuid < 0 else torch.device(f'cuda:{gpuid}')\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们提供了一张图片，以.npy格式存储，`sample_imgs.npy`，以及\n",
    "\n",
    "`model_parameters.pkl`: 包含该图片对应的模型入参，具体包括：\n",
    "- rots：由相机坐标系->车身坐标系的旋转矩阵，rots = (bs, N, 3, 3)；\n",
    "- trans：由相机坐标系->车身坐标系的平移矩阵，trans=(bs, N, 3)；\n",
    "- intrinsic：相机内参，intrinsic = (bs, N, 3, 3)；\n",
    "- post_rots：由图像增强引起的旋转矩阵，post_rots = (bs, N, 3, 3)；\n",
    "- post_trans：由图像增强引起的平移矩阵，post_trans = (bs, N, 3)；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载.npy文件\n",
    "loaded_array = np.load('sample_imgs.npy')\n",
    "\n",
    "# 将NumPy数组转换回PyTorch张量\n",
    "imgs = torch.from_numpy(loaded_array)\n",
    "imgs = imgs.unsqueeze(0)\n",
    "\n",
    "with open('model_parameters.pkl', 'rb') as f:\n",
    "    loaded_parameters_dict = pickle.load(f)\n",
    "\n",
    "# 从加载的字典中获取张量\n",
    "rots = loaded_parameters_dict['rots'].unsqueeze(0)\n",
    "trans = loaded_parameters_dict['trans'].unsqueeze(0)\n",
    "intrins = loaded_parameters_dict['intrins'].unsqueeze(0)\n",
    "post_rots = loaded_parameters_dict['post_rots'].unsqueeze(0)\n",
    "post_trans = loaded_parameters_dict['post_trans'].unsqueeze(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对加载的图片进行可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize\n",
    "%matplotlib inline\n",
    "val = 0.01\n",
    "final_dim=(128, 352)\n",
    "fH, fW = final_dim\n",
    "\n",
    "# fig = plt.figure(figsize=(3*fW*val, (1.5*fW + 2*fH)*val))\n",
    "# gs = gridspec.GridSpec(3, 3, height_ratios=(1.5*fW, fH, fH))\n",
    "fig = plt.figure(figsize=(3*fW*val, (2*fH)*val))\n",
    "gs = gridspec.GridSpec(2, 3, height_ratios=(fH, fH))\n",
    "gs.update(wspace=0.0, hspace=0.0, left=0.0, right=1.0, top=1.0, bottom=0.0)\n",
    "for imgi, img in enumerate(imgs[0]):\n",
    "    ax = plt.subplot(gs[imgi // 3, imgi % 3])\n",
    "    showimg = denormalize_img(img)\n",
    "    # flip the bottom images\n",
    "    if imgi > 2:\n",
    "        showimg = showimg.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "    ax.imshow(showimg)\n",
    "    ax.axis('off')\n",
    "    ax.annotate(cams[imgi].replace('_', ' '), (0.01, 0.92), xycoords='axes fraction')\n",
    "\n",
    "plt.savefig(\"raw_image.jpg\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用`get_geometry()`，将视锥点由图像坐标系向ego坐标系进行坐标转化，并可视化："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geom = model.get_geometry(rots.to(device), trans.to(device), intrins.to(device), post_rots.to(device), post_trans.to(device))\n",
    "print(geom.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize\n",
    "img_pts = geom.cpu()\n",
    "\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "\n",
    "for imgi, img in enumerate(imgs[0]):\n",
    "    plt.plot(img_pts[0, imgi, :, :, :, 0].view(-1), img_pts[0, imgi, :, :, :, 1].view(-1), '.', label=cams[imgi].replace('_', ' '))\n",
    "\n",
    "plt.savefig(\"geom.jpg\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "调用`get_cam_feats`构建图像特征点云，再调用`voxel_pooling`构建BEV特征："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = model.get_cam_feats(imgs.to(device))\n",
    "bev_feat = model.voxel_pooling(geom, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对得到的BEV特征可视化：\n",
    "\n",
    "BEV特征的通道数为64，这里我们采取先对特征值求绝对值，再沿通道维度求平均的方法将BEV特征压缩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bev_feat_np = bev_feat.detach().cpu().numpy()\n",
    "\n",
    "# Take the absolute values\n",
    "bev_feat_abs = np.abs(bev_feat_np)\n",
    "\n",
    "# Calculate the mean across all channels\n",
    "bev_feat_mean = np.mean(bev_feat_abs, axis=1)\n",
    "bev_feat_mean = np.clip(bev_feat_mean,0,1.0)\n",
    "\n",
    "# Visualize the result\n",
    "plt.imshow(bev_feat_mean[0], cmap='jet')\n",
    "\n",
    "plt.colorbar()\n",
    "plt.axis('off')\n",
    "plt.savefig(\"bev.jpg\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面我们通过构建好的LSS模型，对输入数据进行前向传播，做car segmentation，得到最终的增强BEV特征："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with torch.no_grad():\n",
    "    out = model(imgs.to(device),\n",
    "            rots.to(device),\n",
    "            trans.to(device),\n",
    "            intrins.to(device),\n",
    "            post_rots.to(device),\n",
    "            post_trans.to(device),\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对得到的BEV特征可视化，方法如前："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the absolute values\n",
    "out_np = out.detach().cpu().numpy()\n",
    "\n",
    "out_abs = np.abs(out_np)\n",
    "\n",
    "# Calculate the mean across all channels\n",
    "out_mean = np.mean(out_abs, axis=1)\n",
    "# Visualize the result\n",
    "plt.xlim((out.shape[3], 0))\n",
    "plt.ylim((0, out.shape[3]))\n",
    "plt.imshow(out_mean[0], cmap='viridis')\n",
    "\n",
    "plt.colorbar()\n",
    "plt.axis('off')\n",
    "plt.savefig(\"out.jpg\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对输出进行 sigmoid 操作，模型的输出转为概率值，并将结果移动到 CPU 上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = out.sigmoid().cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对模型预测的车辆分割结果进行可视化："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize\n",
    "fig = plt.figure(figsize=(1.5*fW*val, (1.5*fW)*val))\n",
    "dx, bx, _ = gen_dx_bx(grid_conf['xbound'], grid_conf['ybound'], grid_conf['zbound'])\n",
    "dx, bx = dx[:2].numpy(), bx[:2].numpy()\n",
    "\n",
    "plt.legend(handles=[\n",
    "    mpatches.Patch(color=(0.0, 0.0, 1.0, 1.0), label='Output Vehicle Segmentation'),\n",
    "    mpatches.Patch(color='#76b900', label='Ego Vehicle'),\n",
    "], loc=(0.01, 0.86))\n",
    "plt.imshow(out[0].squeeze(0), vmin=0, vmax=1, cmap='Blues')\n",
    "\n",
    "plt.xlim((out.shape[3], 0))\n",
    "plt.ylim((0, out.shape[3]))\n",
    "add_ego(bx, dx)\n",
    "plt.axis('off')\n",
    "\n",
    "plt.savefig(\"car_seg.jpg\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
